{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IA_DNN_ImageClassification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPO7va0u73vCivUtwXxR9Hi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MedicalImageAnalysisTutorials/DeepLearning4All/blob/main/IA_DNN_ImageClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "figzmLKBxWC8"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "In this notebook, I will try to provide a practical tutorial for deep learning using simple examples. I will try to use simple implementation and avoid using built-in functions to give clear idea about the concept. You need basic programming knowledge. \n",
        "\n",
        "**The Classification Problem:**\n",
        "\n",
        "We have data represented usually by an array (could be 1D, 2D, or ND). Note the images usually are 3D arrays e.g. with size hight,width,channels.\n",
        "\n",
        "We also have \"labels\" or \"classes\" so for each sample in our data we have its class or label. \n",
        "\n",
        "An example:\n",
        "\n",
        "                 index     sample (X)     label (Y)  \n",
        "                  1         image1          car                      \n",
        "                  2         image2          car                      \n",
        "                  3         image3          dog                               \n",
        "                  4         image4          bike                      \n",
        "                  5         image5          bike                             \n",
        "                  6         image6          dog                      \n",
        "                  .\n",
        "                  .\n",
        "                  . \n",
        "\n",
        "\n",
        "Another example:\n",
        "\n",
        "                 index         sample (X)         label (Y)  \n",
        "                  1         [20 24 25 ... 23]        1                      \n",
        "                  2         [10 20 8  ... 50]        2\n",
        "                  3         [40 24 12 ... 11]        1                      \n",
        "                  4         [12 15 30 ... 60]        1\n",
        "                  5         [19 70 25 ... 22]        1                      \n",
        "                  6         [0  90 23 ... 10]        2\n",
        "                  .\n",
        "                  .\n",
        "                  . \n",
        "\n",
        "\n",
        "We want to find a way to predict the class or the label for new samples that we do not know. \n",
        "\n",
        "There are many machine learning algorithms available e.g. [K-nearest_neighbors  (KNN)](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) algorithm or [support vector machine (SVM)](https://en.wikipedia.org/wiki/Support-vector_machine)\n",
        "\n",
        "Here we will investigate the [neural network (NN)](http://neuralnetworksanddeeplearning.com/chap1.html) and the [convolution neural networks (CNN)](https://www.analyticsvidhya.com/blog/2018/12/guide-convolutional-neural-network-cnn/) approaches. \n",
        "\n",
        "I made the code flexible so one can try different approaches, datsaets, optimisers, loss functions based on if else statements. \n",
        "\n",
        "The general code structure:\n",
        "\n",
        "    1. Read and pre-process the data\n",
        "    2. Create the model, optimiser, loss function, and metrics\n",
        "    3. Start the training loop\n",
        "    4. Evaluate the final model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NooQ5tm85ZDb"
      },
      "source": [
        "# Setup \n",
        "doInstall =0\n",
        "if doInstall:\n",
        "  !pip install SimpleITK\n",
        "\n",
        "import os, random, time, math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 \n",
        "import SimpleITK as sitk \n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "# to reproduce the same results given same input\n",
        "np.random.seed(1)               \n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7WAn3WH3Lpr"
      },
      "source": [
        "# Image classification using NN\n",
        "\n",
        "First let's try a simple [Neural Network (NN)](https://towardsdatascience.com/coding-neural-network-forward-propagation-and-backpropagtion-ccf8cf369f76) with two hidden layers. It looks similar to this:  \n",
        "\n",
        "![](https://miro.medium.com/max/2400/0*hzIQ5Fs-g8iBpVWq.jpg)\n",
        "\n",
        "The input layer is our image sample (after converted to 1D), each pixel is represented by a neuron. The output layer contains neurons represent the classes (in our case 10 neurons) \n",
        "\n",
        "\n",
        "I will use two popular public datasets [MINST](http://yann.lecun.com/exdb/mnist/) and [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html). Both have 10 classes. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoTv78FC4P_J"
      },
      "source": [
        "## Reading and exploring the datasets\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dzj-Tvek4V8s",
        "outputId": "a9bad7cb-5b21-4a8b-c968-fef8c96e9c63"
      },
      "source": [
        "datasetID = 2  # 1:minst is selected by default, for cifar10 use 2\n",
        "NNID      = 4  # 1:NN is by default, for DNN use 2,or 3, for 3D use 4  \n",
        "number_of_classes = 10  # each datasets have 10 classes\n",
        "showSamples = 1\n",
        "# if you have large GPU memory you can combine the images to batches \n",
        "# for faster training.\n",
        "# It is good to try different values\n",
        "batch_size = 2 # you can try larger batch size e.g. 1024 * 6\n",
        "\n",
        "# minst dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "class_names = range(10)\n",
        "if datasetID==2:\n",
        "    # cifar10 dataset\n",
        "    # The CIFAR10 dataset contains 60,000 color images in 10 classes, \n",
        "    # with 6,000 images in each class.\n",
        "    # The dataset is divided into 50,000 training images and 10,000 testing images.\n",
        "    # The classes are mutually exclusive and there is no overlap between them.\n",
        "\n",
        "    (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "    if NNID==4:\n",
        "        #TODO: fix this \n",
        "        showSamples =0\n",
        "        \n",
        "        x_train = x_train.reshape(-1,32*32*3) # (32 * 32 * 3)        \n",
        "        x_train = np.resize(x_train,(x_train.shape[0],15,15,15))        \n",
        "        x_train = x_train.reshape(-1,15,15,15)\n",
        "        x_test = x_test.reshape(-1,32*32*3) # (32 * 32 * 3)\n",
        "        x_test = np.resize(x_test,(x_test.shape[0],15,15,15))\n",
        "        x_test = x_test.reshape(-1,15,15,15)\n",
        "        x_train  =  x_train[..., np.newaxis] # np.reshape(x_train, (-1, h,w,1))\n",
        "        y_train  =  y_train[..., np.newaxis] # np.reshape(y_train, (-1, h,w,1))\n",
        "        x_test   =  x_test[..., np.newaxis]  # np.reshape(x_test,  (-1, h,w,1))\n",
        "        y_test   =  y_test[..., np.newaxis]  # np.reshape(y_test,  (-1, h,w,1))\n",
        "\n",
        "\n",
        "        print(x_train.shape)\n",
        "        print(x_test.shape)\n",
        "\n",
        "\n",
        "# get size \n",
        "h = x_train.shape[1] # image height\n",
        "w = x_train.shape[2] # image width\n",
        "# check for rgb \n",
        "try:\n",
        "    # number of channels\n",
        "    c =  x_train.shape[3]\n",
        "except:\n",
        "    # number of channels\n",
        "    c =  1\n",
        "    # if there is no number of channels, add 1\n",
        "    x_train  =  x_train[..., np.newaxis] # np.reshape(x_train, (-1, h,w,1))\n",
        "    y_train  =  y_train[..., np.newaxis] # np.reshape(y_train, (-1, h,w,1))\n",
        "    x_test   =  x_test[..., np.newaxis]  # np.reshape(x_test,  (-1, h,w,1))\n",
        "    y_test   =  y_test[..., np.newaxis]  # np.reshape(y_test,  (-1, h,w,1))\n",
        "\n",
        "\n",
        "# Reserve 10,000 samples for validation.\n",
        "x_val = x_train[-10000:]\n",
        "y_val = y_train[-10000:]\n",
        "x_train = x_train[:-10000]\n",
        "y_train = y_train[:-10000]\n",
        "\n",
        "number_of_pixels = h * w * c\n",
        "\n",
        "\n",
        "print(\"dataset shape   : \",x_train.shape)\n",
        "print(\"number of images: \",x_train.shape[0])\n",
        "print(\"image size      : \",x_train[0].shape)\n",
        "print(\"image data type : \",type(x_train[0][0][0][0]))\n",
        "print(\"image max  value: \",np.max(x_train[0]))\n",
        "print(\"image min  value: \",np.min(x_train[0]))\n",
        "if c==1:\n",
        "   print(\"gray or binary image (not color image)\")\n",
        "elif c==3:\n",
        "   print(\"rgb color image (or probably non-color image represented with 3 channels)\")\n",
        "\n",
        "\n",
        "# display sample images \n",
        "if showSamples:\n",
        "    plt.figure(figsize=(10,10))\n",
        "    for i in range(25):\n",
        "        plt.subplot(5,5,i+1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "        #plt.imshow(x_train[i])\n",
        "        plt.imshow(cv2.cvtColor(x_train[i], cv2.COLOR_BGR2RGB))\n",
        "\n",
        "        # The CIFAR labels happen to be arrays, \n",
        "        # which is why you need the extra index\n",
        "        if datasetID==1:\n",
        "            plt.xlabel(y_train[i])\n",
        "        elif datasetID==2:\n",
        "            plt.xlabel(class_names[y_train[i][0]])\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# normalisation\n",
        "x_train = np.array([ x/255.0 for x in x_train])\n",
        "x_val   = np.array([ x/255.0 for x in x_val])\n",
        "x_test  = np.array([ x/255.0 for x in x_test])\n",
        "#y_train = y_train.astype(np.float32)\n",
        "\n",
        "# for NN we need 1D \n",
        "if NNID ==1:\n",
        "   x_train = np.reshape(x_train, (-1, number_of_pixels))\n",
        "   x_val   = np.reshape(x_val,  (-1, number_of_pixels))\n",
        "   x_test  = np.reshape(x_test , (-1, number_of_pixels))\n",
        "\n",
        "# Prepare the training dataset.\n",
        "print(x_train.shape,y_train.shape)\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "#train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n",
        "\n",
        "# Prepare the validation dataset.\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "val_dataset = val_dataset.batch(batch_size)\n",
        "\n",
        "# Prepare the test dataset.\n",
        "tst_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "tst_dataset = tst_dataset.batch(batch_size)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 15, 15, 15, 1)\n",
            "(10000, 15, 15, 15, 1)\n",
            "dataset shape   :  (40000, 15, 15, 15, 1)\n",
            "number of images:  40000\n",
            "image size      :  (15, 15, 15, 1)\n",
            "image data type :  <class 'numpy.ndarray'>\n",
            "image max  value:  255\n",
            "image min  value:  0\n",
            "(40000, 15, 15, 15, 1) (40000, 1, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bP0E_Pzs04y_"
      },
      "source": [
        "## Dataset augmentation\n",
        "\n",
        "It is important to train the model on different variations of the dataset. It is also important to have large datset for training.\n",
        "\n",
        "Using dataset augmentation helps to achieve both of the above goals. From one image, one can generate hundred thousands of images using image transformation.\n",
        "\n",
        "The image transformation could be [spatial transform]() or point transform where we move the points of the image to new locations e.g. shifting, flipping, and/or rotating the imag. \n",
        "\n",
        "Another type of transformation is intensity transform or pixel transform where we change the color values of the pixels in the image e.g. invert the color, add more brightness or darkness. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb2KdoTR07L2"
      },
      "source": [
        "# TODO\n",
        "doAug = 1\n",
        "\n",
        "def imagePixelTransforms(img):    \n",
        "    images = []\n",
        "    # let's make 3 simple transformations\n",
        "    img1   = 1.0- img # invert color\n",
        "    img2   = img +0.3 # more brightness\n",
        "    img3   = img -0.3 # more darkness\n",
        "    images = np.array([img1,img2,img3])\n",
        "    images = [ img.reshape(img.shape) for img in images]\n",
        "\n",
        "    # plt.figure() ;    plt.imshow(img)\n",
        "    # plt.figure() ;    plt.imshow(img1)\n",
        "    # plt.figure() ;    plt.imshow(img2)\n",
        "    # plt.figure() ;    plt.imshow(img3)    \n",
        "    return images\n",
        "\n",
        "def imagePointTransforms(img):\n",
        "    images = []\n",
        "    # let's make 3 simple transformations\n",
        "    # Perform the rotation\n",
        "    center  = (img.shape[0] / 2, img.shape[1] / 2)\n",
        "    sz      = (img.shape[1], img.shape[0])\n",
        "    tMatrix = cv2.getRotationMatrix2D(center, 45, 1)\n",
        "    img1 = cv2.warpAffine(img, tMatrix, sz)\n",
        "    img1 = img1[...,np.newaxis] if img1.shape !=img.shape else img1\n",
        "    tMatrix = cv2.getRotationMatrix2D(center, 90, 1)\n",
        "    img2 = cv2.warpAffine(img, tMatrix, sz)\n",
        "    img2 = img2[...,np.newaxis] if img2.shape !=img.shape else img2\n",
        "    tMatrix = cv2.getRotationMatrix2D(center, 270, 1)\n",
        "    img3 = cv2.warpAffine(img, tMatrix, sz)\n",
        "    img3 = img3[...,np.newaxis] if img3.shape !=img.shape else img3\n",
        "\n",
        "    images = np.array([img1,img2,img3])\n",
        "    # plt.figure() ;    plt.imshow(img)\n",
        "    # plt.figure() ;    plt.imshow(img1)\n",
        "    # plt.figure() ;    plt.imshow(img2)\n",
        "    # plt.figure() ;    plt.imshow(img3)    \n",
        "    #plt.figure() ;    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    # plt.figure() ;    plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n",
        "    return images\n",
        "\n",
        "\n",
        "# define a function for sitk transform\n",
        "def resample(img_array, transform):\n",
        "    # Output image Origin, Spacing, Size, Direction are taken from the reference\n",
        "    # image in this call to Resample\n",
        "    image = sitk.GetImageFromArray(img_array)\n",
        "    reference_image = image\n",
        "    interpolator = sitk.sitkCosineWindowedSinc\n",
        "    default_value = 100.0\n",
        "    resampled_img = sitk.Resample(image, reference_image, transform,\n",
        "                         interpolator, default_value)\n",
        "    resampled_array = sitk.GetArrayFromImage(resampled_img)\n",
        "    return resampled_array\n",
        "\n",
        "def affine_rotate(transform, degrees):\n",
        "    parameters = np.array(transform.GetParameters())\n",
        "    new_transform = sitk.AffineTransform(transform)\n",
        "    dimension =3 \n",
        "    matrix = np.array(transform.GetMatrix()).reshape((dimension,dimension))\n",
        "    radians = -np.pi * degrees / 180.\n",
        "    rotation = np.array([[1  ,0,0], \n",
        "                         [0, np.cos(radians), -np.sin(radians)],\n",
        "                         [0, np.sin(radians), np.cos(radians)]]\n",
        "                        )\n",
        "    new_matrix = np.dot(rotation, matrix)\n",
        "    new_transform.SetMatrix(new_matrix.ravel())\n",
        "    return new_transform\n",
        "\n",
        "\n",
        "def imagePoint3DTransforms(img):\n",
        "    #print(\"imagePoint3DTransforms\")\n",
        "    images = []\n",
        "    # let's make 3 simple transformations\n",
        "    # Perform the rotation\n",
        "    # In SimpleITK resampling convention, the transformation maps points \n",
        "    # from the fixed image to the moving image,\n",
        "    # so inverse of the transform is applied\n",
        "\n",
        "    center = (img.shape[0] /2, img.shape[1] /2,img.shape[1] /2)\n",
        "    rotation_around_center = sitk.AffineTransform(3)\n",
        "    rotation_around_center.SetCenter(center)\n",
        "    \n",
        "    rotation_around_center = affine_rotate(rotation_around_center, -45)\n",
        "    img1 = resample(img, rotation_around_center)\n",
        "\n",
        "    rotation_around_center = affine_rotate(rotation_around_center, -90)\n",
        "    img2 = resample(img, rotation_around_center)\n",
        "\n",
        "    rotation_around_center = affine_rotate(rotation_around_center, -90)\n",
        "    img3 = resample(img, rotation_around_center)\n",
        "\n",
        "    images = np.array([img1,img2,img3])\n",
        "    # plt.figure() ;    plt.imshow(img)\n",
        "    # plt.figure() ;    plt.imshow(img1)\n",
        "    # plt.figure() ;    plt.imshow(img2)\n",
        "    # plt.figure() ;    plt.imshow(img3)    \n",
        "    #plt.figure() ;    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    # plt.figure() ;    plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n",
        "    return images\n",
        "\n",
        "def doAugmentation(images,labels,batch_size):\n",
        "    # input is an image or a batch e.g. list of images \n",
        "    # get numpy arrays from the tensor    \n",
        "    images = images.numpy()\n",
        "    labels = labels.numpy()\n",
        "    # if 1d convert back to 2d\n",
        "    #print(images.shape)\n",
        "    rgb = 0 ; is3d = 0\n",
        "    if len(images.shape) == 2:\n",
        "       try: \n",
        "          img2d_shape = int(math.sqrt(images.shape[1])) # gray or binary image\n",
        "          images =images.reshape(-1,img2d_shape,img2d_shape)\n",
        "       except:\n",
        "          try: \n",
        "            img2d_shape = int(math.sqrt(images.shape[1]/3)) # rgb image\n",
        "            images =images.reshape(-1,img2d_shape,img2d_shape,3)\n",
        "            rgb = 1  \n",
        "          except:\n",
        "            pass  \n",
        "            # img3d_shape = int(math.sqrt(images.shape[1]/3)) # rgb image\n",
        "            # images =images.reshape(-1,img2d_shape,img2d_shape,3)\n",
        "            # is3d = 1  \n",
        "\n",
        "\n",
        "\n",
        "    x_outputs = [] ; y_outputs = []\n",
        "    i = 0\n",
        "    for img in images:\n",
        "        #print(\"-------------------------\", i ,\"--------------------\")\n",
        "        if NNID==4:\n",
        "           img = img.squeeze() \n",
        "        # from each images we generate 6 images\n",
        "        # 64 batch will generate 448\n",
        "        x_outputs.extend([img])\n",
        "        imgs1 = imagePoint3DTransforms(img)\n",
        "        imgs2 = imagePixelTransforms(img)\n",
        "        #if not rgb:\n",
        "           #imgs1 = np.array( x[...,np.newaxis] for x in imgs1 if len(x.shape)<3) \n",
        "           #imgs2 = np.array( x[...,np.newaxis] for x in imgs2 if len(x.shape)<3)\n",
        "        x_outputs.extend(imgs1) # 3 images\n",
        "        x_outputs.extend(imgs2) # 3 images\n",
        "        # print(img.shape)\n",
        "        # print(imgs1[0].shape)\n",
        "        # print(imgs2[0].shape)\n",
        "        # assign the same label to all transformed images\n",
        "        for j in range ( len(imgs1) +len(imgs2)+1):\n",
        "            y_outputs.extend([labels[i]])\n",
        "\n",
        "        i = i +1\n",
        "    x_outputs = np.array(x_outputs)\n",
        "    if NNID==4:\n",
        "       x_outputs = np.array([x[...,np.newaxis] for x in x_outputs])\n",
        "    y_outputs = np.array(y_outputs)\n",
        "\n",
        "    if (not rgb) and (NNID==1):\n",
        "       x_outputs = np.reshape(x_outputs, (-1,img2d_shape*img2d_shape,1))\n",
        "    elif (rgb) and (NNID==1):\n",
        "       x_outputs = np.reshape(x_outputs, (-1,img2d_shape*img2d_shape*3))   \n",
        "\n",
        "    new_train_dataset = tf.data.Dataset.from_tensor_slices((x_outputs, y_outputs))\n",
        "    new_train_dataset = new_train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "    return new_train_dataset"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZY4NXWJ4Xoq"
      },
      "source": [
        "## Creating NN model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmSF08Oq4ae6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecb647db-da2b-484f-9df3-0e7aff2eec17"
      },
      "source": [
        "# NN TensorFlow\n",
        "def getNNModel(number_of_pixels,number_of_classes):\n",
        "    inputs = keras.Input(shape=(number_of_pixels,), name=\"digits\")\n",
        "    x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
        "    x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
        "    outputs = layers.Dense(number_of_classes, name=\"predictions\")(x)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "print(\"NN model is defined ...\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NN model is defined ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpxH1ntsqfuZ"
      },
      "source": [
        "# TODO\n",
        "# NN pytorch\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtEO2ORyBFeu"
      },
      "source": [
        "## Define optimiser and loss function for NN and CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2CBVAaABKU4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4962358-336b-48e3-ad90-21d6af21c0d0"
      },
      "source": [
        "# Instantiate an optimizer to train the model.\n",
        "\n",
        "optimiserID = 1 # SGD by default for ADAM use 2 \n",
        "optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n",
        "if optimiserID ==2:\n",
        "   optimizer = keras.optimizers.Adam()#learning_rate=0.0001\n",
        "# Instantiate a loss function.\n",
        "\n",
        "lossFunctionID = 1 # SparseCategoricalCrossentropy by default for MSE use 2 \n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# Prepare the metrics.\n",
        "train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
        "val_acc_metric   = keras.metrics.SparseCategoricalAccuracy()\n",
        "tst_acc_metric   = keras.metrics.SparseCategoricalAccuracy()\n",
        "if lossFunctionID==2:\n",
        "   loss_fn = keras.losses.MeanSquaredError()\n",
        "   # Prepare the metrics.\n",
        "   train_acc_metric = keras.metrics.MeanSquaredError()\n",
        "   val_acc_metric   = keras.metrics.MeanSquaredError()\n",
        "   tst_acc_metric   = keras.metrics.MeanSquaredError()\n",
        "\n",
        "elif  lossFunctionID==3:\n",
        "   loss_fn = keras.losses.CategoricalCrossentropy()\n",
        "   # Prepare the metrics.\n",
        "   train_acc_metric = keras.metrics.CategoricalCrossentropy()\n",
        "   val_acc_metric   = keras.metrics.CategoricalCrossentropy()\n",
        "   tst_acc_metric   = keras.metrics.CategoricalCrossentropy()\n",
        "print(\"optimiser, loss, and metrics are defined .... \")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "optimiser, loss, and metrics are defined .... \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmAbPxuDqrVV"
      },
      "source": [
        "# TODO\n",
        "# Pytorch\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dxyj5W7P4d2M"
      },
      "source": [
        "\n",
        "## Define training functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8dFra_t4i8d"
      },
      "source": [
        "\n",
        "# define training parameters and file paths \n",
        "\n",
        "# model log files path\n",
        "modelPath   = \"./modelClassification.h5\"\n",
        "logFilePath = \"./training_log.csv\"\n",
        "figPath     = \"./training_log.png\"\n",
        "\n",
        "logFile = open(logFilePath,'w')\n",
        "logFile.write(\"epoch \\t trnLoss \\t valLoss \\t trnAcc \\t valAcc \\t time \\n\" )\n",
        "logFile.close()\n",
        "# Using optimised tensorflow functions provides more speed\n",
        "\n",
        "@tf.function\n",
        "def train_step(model,x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        #print(\"get result\")\n",
        "        logits = model(x, training=True)\n",
        "        #print(\"get loss value \")\n",
        "        #y = keras.utils.to_categorical(y)\n",
        "        loss_value = loss_fn(y, logits)\n",
        "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    train_acc_metric.update_state(y, logits)\n",
        "    return loss_value\n",
        "\n",
        "@tf.function\n",
        "def val_step(model,x, y):\n",
        "    val_logits = model(x, training=False)\n",
        "    #y = keras.utils.to_categorical(y)\n",
        "    loss_value = loss_fn(y, val_logits)\n",
        "    val_acc_metric.update_state(y, val_logits)\n",
        "    return loss_value\n",
        "\n",
        "# plotting function to monitor the curves\n",
        "def iaPlotLoss(logPath,figPath=None):\n",
        "    f = open(logPath,'r')\n",
        "    lst = f.readlines()\n",
        "    # first line is labels:\n",
        "    labels = lst[0].split()[1:-2]\n",
        "    x  = [ int(  ln.split()[0]) for ln in lst[1:]] # epoch\n",
        "    y1 = [ float(ln.split()[1]) for ln in lst[1:]] # lossTrain\n",
        "    y2 = [ float(ln.split()[2]) for ln in lst[1:]] # lossValidation\n",
        "    y3 = [ float(ln.split()[3]) for ln in lst[1:]] # accTrain\n",
        "    y4 = [ float(ln.split()[4]) for ln in lst[1:]] # accValidation\n",
        "    #plotting    \n",
        "    plt.clf()\n",
        "    fig, ax = plt.subplots()    \n",
        "    l1, = ax.plot(x, y1) ;     l2, = ax.plot(x, y2) ;\n",
        "    l3, = ax.plot(x, y3) ;     l4, = ax.plot(x, y4) ;\n",
        "    ax.legend((l1, l2,l3,l4), labels, loc='upper right', shadow=True)\n",
        "    plt.xlabel('epoch')\n",
        "    if figPath:\n",
        "        plt.savefig(figPath, bbox_inches='tight')\n",
        "    else:\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8q6L-lY4GN2"
      },
      "source": [
        "## Training NN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbudB2v04GbI"
      },
      "source": [
        "epochs = 50 # number of iterations \n",
        "\n",
        "\n",
        "if NNID==1:\n",
        "    model = getNNModel(number_of_pixels,number_of_classes)\n",
        "    print(\"===================================================\")\n",
        "    print(\"               Training Loop           \")\n",
        "    print(\"===================================================\")\n",
        "\n",
        "    total_time_start = time.time()\n",
        "    # we loop number of iterations\n",
        "    # for each iteration, we loop through all the training samples\n",
        "    for epoch in range(epochs):\n",
        "        #print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "        start_time = time.time()\n",
        "\n",
        "        #TODO:\n",
        "        # replace this part\n",
        "        \n",
        "        # Iterate over the batches of the dataset.\n",
        "        for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "            #print(train_dataset.shape)\n",
        "            #print(x_batch_train.shape,y_batch_train.shape)\n",
        "            if doAugmentation: \n",
        "                #do augmentation\n",
        "                new_train_batch = doAugmentation(x_batch_train , y_batch_train , batch_size)\n",
        "                for stp, (new_x_batch_train, new_y_batch_train) in enumerate(new_train_batch):\n",
        "                    #print(new_train_batch.shape)\n",
        "                    #print(new_x_batch_train.shape,new_y_batch_train.shape)\n",
        "                    #model.summary()\n",
        "                    loss_value = train_step(model,new_x_batch_train, new_y_batch_train)\n",
        "                    train_acc = train_acc_metric.result()\n",
        "                    train_acc_metric.reset_states()\n",
        "            else:                    \n",
        "                loss_value = train_step(model,x_batch_train, y_batch_train)                    \n",
        "                train_acc = train_acc_metric.result()\n",
        "                train_acc_metric.reset_states()\n",
        "\n",
        "        # Run a validation loop at the end of each epoch.\n",
        "        for x_batch_val, y_batch_val in val_dataset:\n",
        "            val_loss_value = val_step(model,x_batch_val, y_batch_val)\n",
        "\n",
        "        val_acc = val_acc_metric.result()\n",
        "        val_acc_metric.reset_states()\n",
        "        \n",
        "        # compute time required for each epoch\n",
        "        end_time = time.time() - start_time\n",
        "\n",
        "        print(\"epoch:%d \\t trnLoss: %.4f \\t valLoss: %.4f \\t trnAcc: %.4f \\t valAcc: %.4f \\t time:  %.2f\" % (epoch, float(loss_value),float(val_loss_value), float(train_acc), float(val_acc), end_time))\n",
        "        logFile = open(logFilePath,'a')\n",
        "        logFile.write(\"%d \\t %.4f \\t  %.4f \\t %.4f \\t  %.4f \\t  %.2f \\n\" % (epoch, float(loss_value),float(val_loss_value), float(train_acc), float(val_acc), end_time))\n",
        "        logFile.close()\n",
        "        # plot the result\n",
        "        if epoch % 10 ==0:\n",
        "           # plot the result        \n",
        "           iaPlotLoss(logFilePath)\n",
        "\n",
        "    # save the final model\n",
        "    model.save(modelPath)     \n",
        "\n",
        "    # plot the result        \n",
        "    iaPlotLoss(logFilePath)\n",
        "    total_time_end = time.time() - total_time_start\n",
        "    print(\"Training this dataset took \", total_time_end,\" seconds!\") \n",
        "    print(\"Training this dataset took \", total_time_end/60.0,\" minutes!\")   "
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mox2km11qyqY"
      },
      "source": [
        "##TODO pytorch"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKk2JgFo4lgd"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlx1hVMQGAbR"
      },
      "source": [
        "if NNID==1:\n",
        "    # Load the saved model \n",
        "    model = keras.models.load_model(modelPath, compile=False)\n",
        "\n",
        "    start_time = time.time() \n",
        "    # Run a validation loop at the end of each epoch.\n",
        "    for x_batch_tst, y_batch_tst in tst_dataset:\n",
        "        output = model.predict(x_batch_tst)\n",
        "        #y = keras.utils.to_categorical(y_batch_tst)\n",
        "        tst_acc_metric.update_state(y_batch_tst, output)\n",
        "\n",
        "    tst_acc = tst_acc_metric.result()\n",
        "\n",
        "    # compute time required for each epoch\n",
        "    end_time = time.time() - start_time\n",
        "\n",
        "    print(\"test accuracy : %.4f \\t time:  %.2f\" % (  float(tst_acc), end_time))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpZmXOUfrDho"
      },
      "source": [
        "# TODO Pytorch\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8X6Da244p-r"
      },
      "source": [
        "# Image classification using CNN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPkWBAJP47f1"
      },
      "source": [
        "## Creating CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2a1zuKu4_ZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "668e4323-a956-48a0-d0b8-52e862f03c6c"
      },
      "source": [
        "# Simple DNN\n",
        "# just two conolution layers followed by dense layer\n",
        "def getSimpleDNNModel(input_shape,number_of_pixels,number_of_classes):\n",
        "    nF        = 16 # number of filters\n",
        "    inputs = keras.Input(shape=input_shape, name=\"images\") \n",
        "    # Create CNN model\n",
        "    x11  = layers.Conv2D(nF, (3, 3), activation='relu', input_shape=input_shape) (inputs)\n",
        "    x13  = layers.MaxPooling2D((2, 2)) (x11)\n",
        "    x21  = layers.Conv2D(2*nF, (3, 3), activation='relu') (x13)\n",
        "    x23  = layers.MaxPooling2D((2, 2))(x21)\n",
        "    #dense layer for classification\n",
        "    x31 = layers.Flatten()(x23)# convert from 3d to 1d\n",
        "    outputs = layers.Dense(number_of_classes, name=\"predictions\")(x31)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# this is a better model for CIFAR10\n",
        "def getDNNModel(input_shape,number_of_pixels,number_of_classes):\n",
        "    nF        = 64 # number of filters\n",
        "    inputs = keras.Input(shape=input_shape, name=\"images\") \n",
        "    # Create CNN model\n",
        "    x11  = layers.Conv2D(nF, (3, 3), activation='relu', input_shape=input_shape) (inputs)\n",
        "    x12  = layers.BatchNormalization()(x11)\n",
        "    x13  = layers.MaxPooling2D((2, 2)) (x12)\n",
        "    x14  = layers.Dropout(0.25)(x13)\n",
        "    x21  = layers.Conv2D(2*nF, (3, 3), activation='relu') (x14)\n",
        "    x22  = layers.BatchNormalization()(x21)\n",
        "    x23  = layers.MaxPooling2D((2, 2))(x22)\n",
        "    x24  = layers.Dropout(0.25)(x23)\n",
        "    x31  = layers.Conv2D(2*nF, (3, 3), activation='relu')(x24)\n",
        "    #dense layer for classification\n",
        "    x41 = layers.Flatten()(x31)# convert from 3d to 1d\n",
        "    #x7 = layers.Dense(2*nF, activation='relu')(x6)\n",
        "    #x8 = layers.Dense(2*nF, activation='relu')(x7)\n",
        "    x42  = layers.Dropout(0.50)(x41)\n",
        "    outputs = layers.Dense(number_of_classes, name=\"predictions\")(x42)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "print(\"DNN model is defined ...\")    \n",
        "\n",
        "def getSimpleDNN3DModel(input_shape,number_of_pixels,number_of_classes):\n",
        "    nF        = 16 # number of filters\n",
        "    inputs = keras.Input(shape=input_shape, name=\"images\") \n",
        "    # Create CNN model\n",
        "    x11  = layers.Conv3D(nF, (3, 3, 3), activation='relu', input_shape=input_shape) (inputs)\n",
        "    x13  = layers.MaxPooling3D((2, 2, 2)) (x11)\n",
        "    x21  = layers.Conv3D(2*nF, (3, 3, 3), activation='relu') (x13)\n",
        "    x23  = layers.MaxPooling3D((2, 2 ,2))(x21)\n",
        "    #dense layer for classification\n",
        "    x31 = layers.Flatten()(x23)# convert from 3d to 1d\n",
        "    outputs = layers.Dense(number_of_classes, name=\"predictions\")(x31)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DNN model is defined ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oD_BI-0C4_kr"
      },
      "source": [
        "## Training CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKpCUhIT5EWp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c966466c-ffc3-46db-95da-20cea7c8a356"
      },
      "source": [
        "# Same code as above \n",
        "\n",
        "epochs = 500 # number of iterations \n",
        "\n",
        "if NNID>=2:\n",
        "    input_shape = [h,w,c] \n",
        "\n",
        "    if NNID==2:\n",
        "       model = getSimpleDNNModel(input_shape, number_of_pixels,number_of_classes)\n",
        "    elif NNID==3: # advanced \n",
        "       model = getDNNModel(input_shape, number_of_pixels,number_of_classes)\n",
        "    elif NNID==4: # 3D \n",
        "       input_shape = [h,w,c,1] \n",
        "       model = getSimpleDNN3DModel(input_shape, number_of_pixels,number_of_classes)\n",
        "\n",
        "    print(\"===================================================\")\n",
        "    print(\"               Training Loop           \")\n",
        "    print(\"===================================================\")\n",
        "    total_time_start = time.time()\n",
        "    # we loop number of iterations\n",
        "    # for each iteration, we loop through all the training samples\n",
        "    for epoch in range(epochs):\n",
        "        #print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Iterate over the batches of the dataset.\n",
        "        for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "            #print(train_dataset.shape)\n",
        "            #print(x_batch_train.shape,y_batch_train.shape)\n",
        "            if doAug: \n",
        "                #do augmentation\n",
        "                new_train_batch = doAugmentation(x_batch_train , y_batch_train , batch_size)                \n",
        "                for stp, (new_x_batch_train, new_y_batch_train) in enumerate(new_train_batch):\n",
        "                    #print(stp)\n",
        "                    #print(new_train_batch.shape)\n",
        "                    #print(new_x_batch_train.shape,new_y_batch_train.shape)\n",
        "                    #model.summary()\n",
        "                    loss_value = train_step(model,new_x_batch_train, new_y_batch_train)\n",
        "                    train_acc = train_acc_metric.result()\n",
        "                    train_acc_metric.reset_states()\n",
        "                    print(\"   epoch:%d \\t stp %d trnLoss: %.4f \" % (epoch, stp, float(loss_value)))\n",
        "            else:                    \n",
        "                loss_value = train_step(model,x_batch_train, y_batch_train)                    \n",
        "                train_acc = train_acc_metric.result()\n",
        "                train_acc_metric.reset_states()\n",
        "\n",
        "        # Run a validation loop at the end of each epoch.\n",
        "        for x_batch_val, y_batch_val in val_dataset:\n",
        "            val_loss_value = val_step(model,x_batch_val, y_batch_val)\n",
        "\n",
        "        val_acc = val_acc_metric.result()\n",
        "        val_acc_metric.reset_states()\n",
        "        \n",
        "        # compute time required for each epoch\n",
        "        end_time = time.time() - start_time\n",
        "\n",
        "        print(\"epoch:%d \\t trnLoss: %.4f \\t valLoss: %.4f \\t trnAcc: %.4f \\t valAcc: %.4f \\t time:  %.2f\" % (epoch, float(loss_value),float(val_loss_value), float(train_acc), float(val_acc), end_time))\n",
        "        logFile = open(logFilePath,'a')\n",
        "        logFile.write(\"%d \\t %.4f \\t  %.4f \\t %.4f \\t  %.4f \\t  %.2f \\n\" % (epoch, float(loss_value),float(val_loss_value), float(train_acc), float(val_acc), end_time))\n",
        "        logFile.close()\n",
        "        if epoch % 5 ==0:\n",
        "           # plot the result        \n",
        "           iaPlotLoss(logFilePath)\n",
        "           model.save(modelPath)      \n",
        "    # save the final model\n",
        "    model.save(modelPath)     \n",
        "\n",
        "    # plot the result        \n",
        "    iaPlotLoss(logFilePath)\n",
        "    total_time_end = time.time() - total_time_start\n",
        "    print(\"Training this dataset took \", total_time_end,\" seconds!\") \n",
        "    print(\"Training this dataset took \", total_time_end/60.0,\" minutes!\") \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===================================================\n",
            "               Training Loop           \n",
            "===================================================\n",
            "   epoch:0 \t stp 0 trnLoss: 19.3712 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2801 \n",
            "   epoch:0 \t stp 2 trnLoss: 11.9822 \n",
            "   epoch:0 \t stp 3 trnLoss: 1.1037 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.1455 \n",
            "   epoch:0 \t stp 5 trnLoss: 8.6938 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2091 \n",
            "   epoch:0 \t stp 0 trnLoss: 1.1515 \n",
            "   epoch:0 \t stp 1 trnLoss: 1.1315 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2464 \n",
            "   epoch:0 \t stp 3 trnLoss: 6.4666 \n",
            "   epoch:0 \t stp 4 trnLoss: 1.5967 \n",
            "   epoch:0 \t stp 5 trnLoss: 1.1204 \n",
            "   epoch:0 \t stp 6 trnLoss: 4.0115 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2391 \n",
            "   epoch:0 \t stp 1 trnLoss: 3.6634 \n",
            "   epoch:0 \t stp 2 trnLoss: 1.1243 \n",
            "   epoch:0 \t stp 3 trnLoss: 6.1534 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2052 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2249 \n",
            "   epoch:0 \t stp 6 trnLoss: 0.3717 \n",
            "   epoch:0 \t stp 0 trnLoss: 4.9336 \n",
            "   epoch:0 \t stp 1 trnLoss: 7.0246 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.3228 \n",
            "   epoch:0 \t stp 3 trnLoss: 3.2798 \n",
            "   epoch:0 \t stp 4 trnLoss: 1.8662 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.3132 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2879 \n",
            "   epoch:0 \t stp 0 trnLoss: 3.0968 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.3384 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2934 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.9065 \n",
            "   epoch:0 \t stp 4 trnLoss: 1.4332 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2814 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.7150 \n",
            "   epoch:0 \t stp 0 trnLoss: 4.4081 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.9138 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.6327 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2987 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.0509 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2956 \n",
            "   epoch:0 \t stp 6 trnLoss: 3.6467 \n",
            "   epoch:0 \t stp 0 trnLoss: 3.9111 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.1993 \n",
            "   epoch:0 \t stp 2 trnLoss: 1.4757 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.3092 \n",
            "   epoch:0 \t stp 4 trnLoss: 1.4707 \n",
            "   epoch:0 \t stp 5 trnLoss: 5.0683 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.3016 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2764 \n",
            "   epoch:0 \t stp 1 trnLoss: 1.8447 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.8557 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.9068 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2948 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.1420 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.3108 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.4943 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.3012 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2105 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2487 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2772 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.1993 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.3053 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2331 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.6454 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2904 \n",
            "   epoch:0 \t stp 3 trnLoss: 1.7238 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.6839 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.0269 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.3494 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.0688 \n",
            "   epoch:0 \t stp 1 trnLoss: 1.2583 \n",
            "   epoch:0 \t stp 2 trnLoss: 1.8393 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2896 \n",
            "   epoch:0 \t stp 4 trnLoss: 0.7469 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2700 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2741 \n",
            "   epoch:0 \t stp 0 trnLoss: 3.1411 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.4984 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.0393 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.1271 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2989 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2935 \n",
            "   epoch:0 \t stp 6 trnLoss: 1.8489 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2818 \n",
            "   epoch:0 \t stp 1 trnLoss: 1.7000 \n",
            "   epoch:0 \t stp 2 trnLoss: 1.4801 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2869 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.0664 \n",
            "   epoch:0 \t stp 5 trnLoss: 1.2197 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2882 \n",
            "   epoch:0 \t stp 0 trnLoss: 1.6317 \n",
            "   epoch:0 \t stp 1 trnLoss: 3.9292 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2851 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2886 \n",
            "   epoch:0 \t stp 4 trnLoss: 1.7016 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.0535 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2843 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2570 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.1539 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.0176 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2687 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.0764 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2686 \n",
            "   epoch:0 \t stp 6 trnLoss: 1.8577 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.5363 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.9013 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2850 \n",
            "   epoch:0 \t stp 3 trnLoss: 3.0057 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.3082 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2831 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.4554 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2932 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.3086 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.8462 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2666 \n",
            "   epoch:0 \t stp 4 trnLoss: 1.7397 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2732 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.4208 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.3540 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.5711 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.3155 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.4369 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.1669 \n",
            "   epoch:0 \t stp 5 trnLoss: 1.9865 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2711 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2687 \n",
            "   epoch:0 \t stp 1 trnLoss: 1.7245 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2718 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.1533 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.0028 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.8276 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2788 \n",
            "   epoch:0 \t stp 0 trnLoss: 3.2460 \n",
            "   epoch:0 \t stp 1 trnLoss: 1.9312 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.4117 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.3292 \n",
            "   epoch:0 \t stp 4 trnLoss: 3.0999 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2912 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.7495 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.3213 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.3251 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.4802 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.5143 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.3454 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.3137 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.0907 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.7583 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2656 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.7446 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2797 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.4246 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.3790 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.0485 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2809 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2337 \n",
            "   epoch:0 \t stp 2 trnLoss: 1.9424 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.3774 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2858 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2271 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.0228 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.3192 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.4349 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.3843 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.6756 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2910 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.3000 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.0476 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.4080 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.3327 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2989 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.0158 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.7908 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.3107 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.0549 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2694 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2603 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.3129 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.3212 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2681 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.1465 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.0140 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2881 \n",
            "   epoch:0 \t stp 1 trnLoss: 3.2917 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.4983 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2836 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.8294 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.4913 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.3939 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2956 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.1659 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2059 \n",
            "   epoch:0 \t stp 3 trnLoss: 1.9994 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.0814 \n",
            "   epoch:0 \t stp 5 trnLoss: 1.8414 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2467 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2984 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2949 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.4267 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2738 \n",
            "   epoch:0 \t stp 4 trnLoss: 1.9054 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2660 \n",
            "   epoch:0 \t stp 6 trnLoss: 1.9040 \n",
            "   epoch:0 \t stp 0 trnLoss: 1.8945 \n",
            "   epoch:0 \t stp 1 trnLoss: 1.8842 \n",
            "   epoch:0 \t stp 2 trnLoss: 1.8272 \n",
            "   epoch:0 \t stp 3 trnLoss: 1.6698 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2201 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2589 \n",
            "   epoch:0 \t stp 6 trnLoss: 1.8748 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.6235 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.3002 \n",
            "   epoch:0 \t stp 2 trnLoss: 3.0256 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.3095 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.3204 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2719 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2775 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.3400 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.3426 \n",
            "   epoch:0 \t stp 2 trnLoss: 3.8729 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.9396 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.5616 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.3319 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.4617 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2367 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.3261 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.3896 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2813 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.1943 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.3424 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2824 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.4595 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2928 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.0774 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.3173 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.3018 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.3542 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.4046 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.1882 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.1500 \n",
            "   epoch:0 \t stp 2 trnLoss: 1.9602 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2703 \n",
            "   epoch:0 \t stp 4 trnLoss: 1.8184 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2672 \n",
            "   epoch:0 \t stp 6 trnLoss: 1.9294 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.3693 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.0852 \n",
            "   epoch:0 \t stp 2 trnLoss: 1.7447 \n",
            "   epoch:0 \t stp 3 trnLoss: 1.5207 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2694 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.1054 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2724 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.3012 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2998 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.6125 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.4278 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.3766 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.7862 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.6453 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.3498 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2111 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.9978 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.3128 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.4095 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.3248 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.3968 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.3678 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.1164 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.5398 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2573 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2916 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2959 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2449 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.3092 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.3246 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.7912 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.3457 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.3967 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.3371 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.3172 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.4381 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2855 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2880 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.1230 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.3297 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2381 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2829 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.1745 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2598 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.0841 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2540 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.0481 \n",
            "   epoch:0 \t stp 5 trnLoss: 1.7816 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2563 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2966 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2817 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.1071 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2737 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2103 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.3480 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2696 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2133 \n",
            "   epoch:0 \t stp 1 trnLoss: 1.9029 \n",
            "   epoch:0 \t stp 2 trnLoss: 1.7193 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2638 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.0677 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.0481 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2631 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2774 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.3027 \n",
            "   epoch:0 \t stp 2 trnLoss: 1.7143 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.1851 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2637 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.0000 \n",
            "   epoch:0 \t stp 6 trnLoss: 1.9867 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2979 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.8678 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2024 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.4067 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.3517 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.1193 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.3485 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.0148 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.1778 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2331 \n",
            "   epoch:0 \t stp 3 trnLoss: 1.7013 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2461 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2538 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.3413 \n",
            "   epoch:0 \t stp 0 trnLoss: 1.9489 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2972 \n",
            "   epoch:0 \t stp 2 trnLoss: 1.9523 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2418 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2717 \n",
            "   epoch:0 \t stp 5 trnLoss: 1.8941 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.6886 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2821 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.6639 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2764 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.1737 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.5822 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2841 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2335 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2548 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.1826 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.9178 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2788 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.3272 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.4337 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.5760 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.5508 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2769 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.3084 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.0355 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2481 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.1275 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.5486 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.0296 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.6281 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.3343 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2829 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.0729 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.0461 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.4979 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2035 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2478 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2599 \n",
            "   epoch:0 \t stp 3 trnLoss: 1.9600 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.0475 \n",
            "   epoch:0 \t stp 5 trnLoss: 1.6335 \n",
            "   epoch:0 \t stp 6 trnLoss: 1.9360 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2544 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2375 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.1535 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2761 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.0445 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.0081 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.1676 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.5105 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.3935 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2932 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2420 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2707 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.3369 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2519 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.3296 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.3925 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.4598 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.8096 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.4743 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.5814 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.7100 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.0518 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.1117 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2589 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.3913 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2624 \n",
            "   epoch:0 \t stp 5 trnLoss: 1.8435 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2972 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.9021 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.1941 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.6446 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.3973 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2779 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.3352 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.7061 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.3356 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.1280 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.3269 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.5445 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.5129 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.1656 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.3711 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.0447 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.1469 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.0997 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.5823 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.4894 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2952 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2742 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.3511 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.3625 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.3350 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.4948 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2651 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.3427 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.4031 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.4641 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.3117 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.4108 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.3453 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.3103 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.4432 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.3056 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2146 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2965 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.3134 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.0491 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2845 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.1962 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2404 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.4064 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.4448 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2208 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2378 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.1140 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.4642 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2904 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.4239 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.3646 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.5939 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.3261 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.3322 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2913 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.4056 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2481 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2967 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.1884 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.4269 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.3090 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2212 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.4369 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.5217 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2679 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2657 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2955 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.3445 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.3438 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2202 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2275 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2978 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.1576 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.3141 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2101 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2802 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2964 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.3292 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2495 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.5271 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.3093 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2229 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.0952 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.4588 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2204 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.3919 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.6650 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.3501 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2977 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.4416 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.3303 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2636 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2118 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.3097 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2799 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2660 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2737 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.5662 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2653 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2602 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2715 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.1857 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2376 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.0850 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.3059 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.1823 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.1655 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.1243 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.4299 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.4362 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.5191 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.3084 \n",
            "   epoch:0 \t stp 0 trnLoss: 1.9588 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2861 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2653 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.3327 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2375 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2086 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2002 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.3799 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2639 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2376 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.1438 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2521 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.1382 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2442 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.5370 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.3499 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.4093 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2051 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2793 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.3675 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2846 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.3307 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.1745 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.1743 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.3335 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.5825 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.7010 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.3513 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2853 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.3260 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.4495 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.3354 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.0591 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2043 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.4444 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.4012 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.5184 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.4828 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.5075 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.3124 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.3666 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2167 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.5689 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.3084 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.3050 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.3299 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.4488 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2884 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2580 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.1859 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.4790 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.0898 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.4955 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.3395 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.3047 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2616 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2853 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2368 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2099 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2722 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2710 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2809 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2185 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2319 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.1059 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.1870 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.1832 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.1763 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.3002 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.1410 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.3013 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.5134 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.3313 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.4856 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.4556 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.3140 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.3307 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2934 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2360 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2083 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.4225 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.4118 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.4012 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.3407 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.5000 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.3043 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2293 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.3509 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.3034 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.1272 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.3164 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.3118 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.3566 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.3900 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.3997 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.3107 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.4690 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2617 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2325 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.3886 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.3460 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.4538 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2372 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.3093 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.3349 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.0829 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2594 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.4184 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2209 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2942 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2846 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2901 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.3452 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.3310 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.3059 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.1846 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2457 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2999 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2597 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.4433 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.4431 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.3012 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.3655 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.3560 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.3589 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.3380 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2220 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.3819 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2156 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2440 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2468 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2681 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2548 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.3608 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.4051 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2335 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.4218 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2190 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.3049 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2269 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.3308 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.4355 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.3287 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.3497 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.3247 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.3290 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2546 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.1249 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2634 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2531 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2453 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2884 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2883 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.4157 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2494 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.3347 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.3357 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2704 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.3035 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2860 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2737 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.3382 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.3225 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.3484 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.3435 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2273 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.3698 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.3566 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.3242 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2485 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.4616 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.3111 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2869 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.3392 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2974 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2790 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2238 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2173 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2505 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.3044 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2625 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.1731 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.3260 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.3227 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.3020 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.3959 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.1572 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2911 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2929 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2925 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.4694 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.3077 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2460 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2684 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.3313 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2788 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.3202 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.1987 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.3033 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.3269 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.3246 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2106 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.3863 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2509 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2701 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2765 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2963 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2911 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2903 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.5704 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2777 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.1307 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2909 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2623 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.3025 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.3562 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2193 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.3411 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2774 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.3011 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2833 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2720 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2580 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2897 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.3370 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.6007 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2358 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.3390 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.3324 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.3353 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.3304 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2674 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2775 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.3103 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.4788 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2773 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.1786 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2706 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2612 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2747 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2825 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.1789 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.3033 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2596 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.4507 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2786 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2782 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2787 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2676 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.1197 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2971 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2780 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.3239 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.3207 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.3304 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.3555 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.3417 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.3009 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.1918 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2662 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2247 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2753 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2749 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.1954 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2760 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2775 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.3026 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.5175 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2640 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.3517 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2725 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.1695 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2871 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.1612 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2881 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2915 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2712 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.0977 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2901 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2839 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.0359 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2750 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2854 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.5134 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.3195 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2859 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2878 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.3183 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2854 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.3100 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.3262 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.1824 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2890 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2890 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.4247 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.4580 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2792 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.4620 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.3325 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.3677 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.1389 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2817 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2820 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2570 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.2478 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.2696 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2592 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.3670 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.4137 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.4141 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.1647 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.3320 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.3632 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.3476 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2762 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2508 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.2786 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2521 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.3618 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.4403 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2642 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.2596 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2891 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.4134 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.2511 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.3584 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.3189 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.3674 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.3272 \n",
            "   epoch:0 \t stp 0 trnLoss: 2.2919 \n",
            "   epoch:0 \t stp 1 trnLoss: 2.3531 \n",
            "   epoch:0 \t stp 2 trnLoss: 2.5467 \n",
            "   epoch:0 \t stp 3 trnLoss: 2.3174 \n",
            "   epoch:0 \t stp 4 trnLoss: 2.3732 \n",
            "   epoch:0 \t stp 5 trnLoss: 2.2602 \n",
            "   epoch:0 \t stp 6 trnLoss: 2.3084 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deIAKC2E5HcT"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwUVTMeg5Ks5"
      },
      "source": [
        "if NNID==2:\n",
        "    # Load the saved model \n",
        "    model = keras.models.load_model(modelPath, compile=False)\n",
        "\n",
        "    start_time = time.time() \n",
        "    # Run a validation loop at the end of each epoch.\n",
        "    for x_batch_tst, y_batch_tst in tst_dataset:\n",
        "        output = model.predict(x_batch_tst)\n",
        "        #y = keras.utils.to_categorical(y_batch_tst)\n",
        "        tst_acc_metric.update_state(y_batch_tst, output)\n",
        "\n",
        "    tst_acc = tst_acc_metric.result()\n",
        "\n",
        "    # compute time required for each epoch\n",
        "    end_time = time.time() - start_time\n",
        "\n",
        "    print(\"test accuracy : %.4f \\t time:  %.2f\" % (  float(tst_acc), end_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dne9y6mbMW0V"
      },
      "source": [
        "# Understanding traning curves\n",
        "\n",
        "Training large datsets takes hours. It is good to check the [training curves](https://en.wikipedia.org/wiki/Learning_curve) and stop the training if it is a waste of time and resources. To do this one should check the training curves and identify specific problems.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-YaiYcJP028"
      },
      "source": [
        "#TODO: show examples using the above datasets\n",
        "# https://machinelearningmastery.com/diagnose-overfitting-underfitting-lstm-models/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-j-OqIpdOlJf"
      },
      "source": [
        "## Model underfitting, overfitting, and good fitting:\n",
        "\n",
        "\n",
        "Source for this part is taken from [here](https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/).\n",
        "\n",
        "**Underfitting:**\n",
        "\n",
        "* No learning: Training loss is a line or a noisy line\n",
        "* Need more training: Traning loss is decreasing.\n",
        "\n",
        "<div>\n",
        "<img src=\"\" width=\"500\"/>\n",
        "</div>\n",
        "\n",
        "<div>\n",
        "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2019/02/Example-of-Training-Learning-Curve-Showing-An-Underfit-Model-That-Does-Not-Have-Sufficient-Capacity.png\" width=\"500\"/>\n",
        "</div>\n",
        "\n",
        "<!-- ![](https://machinelearningmastery.com/wp-content/uploads/2019/02/Example-of-Training-Learning-Curve-Showing-An-Underfit-Model-That-Does-Not-Have-Sufficient-Capacity.png) -->\n",
        "\n",
        "<div>\n",
        "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2018/12/Example-of-Training-Learning-Curve-Showing-An-Underfit-Model-That-Requires-Further-Training.png\" width=\"500\"/>\n",
        "</div>\n",
        "\n",
        "\n",
        "<!-- ![](https://machinelearningmastery.com/wp-content/uploads/2018/12/Example-of-Training-Learning-Curve-Showing-An-Underfit-Model-That-Requires-Further-Training.png) -->\n",
        "\n",
        "**Overfitting:**\n",
        "\n",
        "* Training loss is decreasing \n",
        "* Validation loss is decreasing then increasing.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2018/12/Example-of-Train-and-Validation-Learning-Curves-Showing-An-Overfit-Model.png\" width=\"500\"/>\n",
        "</div>\n",
        "\n",
        "<!-- ![](https://machinelearningmastery.com/wp-content/uploads/2018/12/Example-of-Train-and-Validation-Learning-Curves-Showing-An-Overfit-Model.png) -->\n",
        "\n",
        "**Good fitting:**\n",
        "\n",
        "* Training loss is decreasing to a point of stability.\n",
        "* Validation loss is decreasing to a point of stability and has a small gap with the training loss.\n",
        "\n",
        "\n",
        "<div>\n",
        "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2018/12/Example-of-Train-and-Validation-Learning-Curves-Showing-A-Good-Fit.png\" width=\"500\"/>\n",
        "</div>\n",
        "\n",
        "<!-- ![](https://machinelearningmastery.com/wp-content/uploads/2018/12/Example-of-Train-and-Validation-Learning-Curves-Showing-A-Good-Fit.png) -->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ojw1-BrOrzb"
      },
      "source": [
        "## Bad Datasets\n",
        "\n",
        "**Bad Training Dataset:**\n",
        "\n",
        "* Training dataset has too few examples as compared to the validation dataset.\n",
        "* Training loss is decreasing and validation loss is decreasing with a large gap.\n",
        "\n",
        "\n",
        "<div>\n",
        "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2018/12/Example-of-Train-and-Validation-Learning-Curves-Showing-a-Training-Dataset-the-May-be-too-Small-Relative-to-the-Validation-Dataset.png\" width=\"500\"/>\n",
        "</div>\n",
        "\n",
        "<!-- ![](https://machinelearningmastery.com/wp-content/uploads/2018/12/Example-of-Train-and-Validation-Learning-Curves-Showing-a-Training-Dataset-the-May-be-too-Small-Relative-to-the-Validation-Dataset.png) -->\n",
        "\n",
        "\n",
        "**Bad validation Dataset:**\n",
        "\n",
        "* Training loss is decreasing and validation loss with noisy movements around the training loss.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2018/12/Example-of-Train-and-Validation-Learning-Curves-Showing-a-Validation-Dataset-the-May-be-too-Small-Relative-to-the-Training-Dataset.png\" width=\"500\"/>\n",
        "</div>\n",
        "\n",
        "\n",
        "* Validation loss is lower than the training loss (Use validation dataset for training)\n",
        "\n",
        "<div>\n",
        "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2018/12/Example-of-Train-and-Validation-Learning-Curves-Showing-a-Validation-Dataset-that-is-Easier-to-Predict-than-the-Training-Dataset.png\" width=\"500\"/>\n",
        "</div>\n",
        "\n",
        "\n",
        "<!-- ![](https://machinelearningmastery.com/wp-content/uploads/2018/12/Example-of-Train-and-Validation-Learning-Curves-Showing-a-Validation-Dataset-the-May-be-too-Small-Relative-to-the-Training-Dataset.png)\n",
        "![](https://machinelearningmastery.com/wp-content/uploads/2018/12/Example-of-Train-and-Validation-Learning-Curves-Showing-a-Validation-Dataset-that-is-Easier-to-Predict-than-the-Training-Dataset.png) -->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeRdRNJF2kwU"
      },
      "source": [
        "# More resources:\n",
        "\n",
        "* 3Blue1Brown Neural Network [video tutorials](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) \n",
        "* Deep Learning Video Lectures by Prof. Andreas Maier [Winter 20/21](https://www.youtube.com/watch?v=SCFToE1vM2U&list=PLpOGQvPCDQzvJEPFUQ3mJz72GJ95jyZTh)\n",
        "* Some of the code in this notebook is taken from [here](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch)\n",
        "* Calculating number of parameters in [CNN](https://towardsdatascience.com/understanding-and-calculating-the-number-of-parameters-in-convolution-neural-networks-cnns-fc88790d530d)\n",
        "* Some of the code in this notebook is taken from [here](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/cnn.ipynb)\n",
        "* https://imerit.net/blog/top-13-machine-learning-image-classification-datasets-all-pbm/\n",
        "* https://nihcc.app.box.com/v/ChestXray-NIHCC\n",
        "* https://www.kaggle.com/xhlulu/recursion-cellular-image-classification-224-jpg\n",
        "* https://www.tensorflow.org/datasets/catalog/patch_camelyon\n"
      ]
    }
  ]
}