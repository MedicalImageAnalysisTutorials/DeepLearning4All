{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IA_DNN_ImageClassification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNf4I8f8YnDAuuZnw+gCQnY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MedicalImageAnalysisTutorials/DeepLearning4All/blob/main/IA_DNN_ImageClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NooQ5tm85ZDb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f6ee118-7137-4b97-8ec5-8a95bbaa46f7"
      },
      "source": [
        "# Setup \n",
        "doInstall =1\n",
        "if doInstall:\n",
        "  !pip install SimpleITK\n",
        "\n",
        "import os, random, time, math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 \n",
        "\n",
        "try:   \n",
        "  import SimpleITK as sitk \n",
        "except:\n",
        "  print(\"please install simpleitk\") \n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "# to reproduce the same results given same input\n",
        "np.random.seed(1)               "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SimpleITK in /usr/local/lib/python3.7/dist-packages (2.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7WAn3WH3Lpr"
      },
      "source": [
        "# Image classification using NN\n",
        "\n",
        "First let's try a simple [Neural Network (NN)](https://towardsdatascience.com/coding-neural-network-forward-propagation-and-backpropagtion-ccf8cf369f76) with two hidden layers. It looks similar to this:  \n",
        "\n",
        "![](https://miro.medium.com/max/2400/0*hzIQ5Fs-g8iBpVWq.jpg)\n",
        "\n",
        "The input layer is our image sample (after converted to 1D), each pixel is represented by a neuron. The output layer contains neurons represent the classes (in our case 10 neurons) \n",
        "\n",
        "\n",
        "I will use two popular public datasets [MINST](http://yann.lecun.com/exdb/mnist/) and [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html). Both have 10 classes. \n",
        "\n",
        "\n",
        "Usually number of the classes , i.e. 10 neurons, is used for the outoutput but one can used one neuron which is [not a good idea](https://stackoverflow.com/questions/45861547/neural-network-predict-mnist-digits-only-with-one-neuron-in-the-output-layer).. Digit recognition is a classification problem. By only using a single output neuron we are proposing to treat it as a regression problem. The implicit assumption we are making is that numbers that are close to each other numerically also look similar. This is obviously not the case. For instance, 3 and 5 look more similar than 3 and 4 as the bottom part is the same. Also, regression models assume that the input is ordered (one can use any order, for example 1,2,3.... or 1,3,2,5,4 or any other and the model will have different parameters). Some good ideas can be found in [Introduction to Statistical Learning free book](http://www-bcf.usc.edu/~gareth/ISL/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoTv78FC4P_J"
      },
      "source": [
        "## Reading and exploring the datasets\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "id": "Dzj-Tvek4V8s",
        "outputId": "205fd7a0-c202-48ec-a886-d0608b48dd5a"
      },
      "source": [
        "datasetID = 1  # 1:minst is selected by default, for cifar10 use 2\n",
        "NNID      = 1  # 1:NN is by default, for DNN use 2,or 3, for 3D use 4  \n",
        "number_of_classes = 10  # each datasets have 10 classes\n",
        "showSamples = 1\n",
        "# if you have large GPU memory you can combine the images to batches \n",
        "# for faster training.\n",
        "# It is good to try different values\n",
        "batch_size = 2 # you can try larger batch size e.g. 1024 * 6\n",
        "\n",
        "doAug = 0\n",
        "\n",
        "# minst dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "class_names = range(10)\n",
        "if datasetID==2:\n",
        "    # cifar10 dataset\n",
        "    # The CIFAR10 dataset contains 60,000 color images in 10 classes, \n",
        "    # with 6,000 images in each class.\n",
        "    # The dataset is divided into 50,000 training images and 10,000 testing images.\n",
        "    # The classes are mutually exclusive and there is no overlap between them.\n",
        "\n",
        "    (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "    if NNID==4:\n",
        "        #TODO: fix this \n",
        "        showSamples =0\n",
        "        \n",
        "        x_train = x_train.reshape(-1,32*32*3) # (32 * 32 * 3)        \n",
        "        x_train = np.resize(x_train,(x_train.shape[0],15,15,15))        \n",
        "        x_train = x_train.reshape(-1,15,15,15)\n",
        "        x_test = x_test.reshape(-1,32*32*3) # (32 * 32 * 3)\n",
        "        x_test = np.resize(x_test,(x_test.shape[0],15,15,15))\n",
        "        x_test = x_test.reshape(-1,15,15,15)\n",
        "        x_train  =  x_train[..., np.newaxis] # np.reshape(x_train, (-1, h,w,1))\n",
        "        y_train  =  y_train[..., np.newaxis] # np.reshape(y_train, (-1, h,w,1))\n",
        "        x_test   =  x_test[..., np.newaxis]  # np.reshape(x_test,  (-1, h,w,1))\n",
        "        y_test   =  y_test[..., np.newaxis]  # np.reshape(y_test,  (-1, h,w,1))\n",
        "\n",
        "\n",
        "        print(x_train.shape)\n",
        "        print(x_test.shape)\n",
        "\n",
        "\n",
        "# get size \n",
        "h = x_train.shape[1] # image height\n",
        "w = x_train.shape[2] # image width\n",
        "# check for rgb \n",
        "try:\n",
        "    # number of channels\n",
        "    c =  x_train.shape[3]\n",
        "except:\n",
        "    # number of channels\n",
        "    c =  1\n",
        "    # if there is no number of channels, add 1\n",
        "    x_train  =  x_train[..., np.newaxis] # np.reshape(x_train, (-1, h,w,1))\n",
        "    y_train  =  y_train[..., np.newaxis] # np.reshape(y_train, (-1, h,w,1))\n",
        "    x_test   =  x_test[..., np.newaxis]  # np.reshape(x_test,  (-1, h,w,1))\n",
        "    y_test   =  y_test[..., np.newaxis]  # np.reshape(y_test,  (-1, h,w,1))\n",
        "\n",
        "\n",
        "# Reserve 10,000 samples for validation.\n",
        "x_val = x_train[-10000:]\n",
        "y_val = y_train[-10000:]\n",
        "x_train = x_train[:-10000]\n",
        "y_train = y_train[:-10000]\n",
        "\n",
        "number_of_pixels = h * w * c\n",
        "\n",
        "\n",
        "print(\"dataset shape   : \",x_train.shape)\n",
        "print(\"number of images: \",x_train.shape[0])\n",
        "print(\"image size      : \",x_train[0].shape)\n",
        "print(\"image data type : \",type(x_train[0][0][0][0]))\n",
        "print(\"image max  value: \",np.max(x_train[0]))\n",
        "print(\"image min  value: \",np.min(x_train[0]))\n",
        "if c==1:\n",
        "   print(\"gray or binary image (not color image)\")\n",
        "elif c==3:\n",
        "   print(\"rgb color image (or probably non-color image represented with 3 channels)\")\n",
        "\n",
        "\n",
        "# display sample images \n",
        "if showSamples:\n",
        "    plt.figure(figsize=(10,10))\n",
        "    for i in range(25):\n",
        "        plt.subplot(5,5,i+1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "        #plt.imshow(x_train[i])\n",
        "        plt.imshow(cv2.cvtColor(x_train[i], cv2.COLOR_BGR2RGB))\n",
        "\n",
        "        # The CIFAR labels happen to be arrays, \n",
        "        # which is why you need the extra index\n",
        "        if datasetID==1:\n",
        "            plt.xlabel(y_train[i])\n",
        "        elif datasetID==2:\n",
        "            plt.xlabel(class_names[y_train[i][0]])\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# normalisation\n",
        "x_train = np.array([ x/255.0 for x in x_train])\n",
        "x_val   = np.array([ x/255.0 for x in x_val])\n",
        "x_test  = np.array([ x/255.0 for x in x_test])\n",
        "#y_train = y_train.astype(np.float32)\n",
        "\n",
        "# for NN we need 1D \n",
        "if NNID ==1:\n",
        "   x_train = np.reshape(x_train, (-1, number_of_pixels))\n",
        "   x_val   = np.reshape(x_val,  (-1, number_of_pixels))\n",
        "   x_test  = np.reshape(x_test , (-1, number_of_pixels))\n",
        "\n",
        "# Prepare the training dataset.\n",
        "print(x_train.shape,y_train.shape)\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "#train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n",
        "\n",
        "# Prepare the validation dataset.\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "val_dataset = val_dataset.batch(batch_size)\n",
        "\n",
        "# Prepare the test dataset.\n",
        "tst_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "tst_dataset = tst_dataset.batch(batch_size)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset shape   :  (50000, 28, 28, 1)\n",
            "number of images:  50000\n",
            "image size      :  (28, 28, 1)\n",
            "image data type :  <class 'numpy.uint8'>\n",
            "image max  value:  255\n",
            "image min  value:  0\n",
            "gray or binary image (not color image)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/matplotlib/text.py:1165: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  if s != self._text:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj0AAAI8CAYAAAAazRqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdebxV8/7H8c9XhDQgyVghilDJUIbqIkPINZfKLfNYhkKGZCZ1SSKEDKmbQriGXMmsH1G3NEiIEpVKUaT6/v4oH5/vumcf++yz915n7/V6Ph73cd+r9d1rf1mtc77Wd3LeewEAACh2G8RdAQAAgHyg0QMAABKBRg8AAEgEGj0AACARaPQAAIBEoNEDAAASYcOyFHbOMb89Bt57l+1rci9js8h7XyvbF+V+xoNns6hk/dnkXsYm5b3kTQ+QX3PirgCAEvFsFo+U95JGDwAASAQaPQAAIBFo9AAAgESg0QMAABKBRg8AAEgEGj0AACARaPQAAIBEoNEDAAASgUYPAABIBBo9AAAgEWj0AACARCjThqNARdOsWbPg+OKLL9Z8xhlnaH7iiSeCcgMHDtT8ySef5Kh2AICKhDc9AAAgEWj0AACARKDRAwAAEsF579Mv7Fz6hWNQqVKl4LhGjRppfc6OA6lSpYrmBg0aBOUuuugizf369dPcoUOHoNyvv/6q+Y477gjO3XjjjWnVyfLeuzJ/6C9U9HtZmiZNmmgeN25ccK569eppXeOnn37SXLNmzexULD0Tvff7ZvuihXw/s+2www7TPGzYsOBcq1atNM+cObPc38WzWX7XXXddcGx/Rm6wwZ//Xd66deug3FtvvZXtqmT92UzavaxAUt5L3vQAAIBEoNEDAAASocJOWa9Tp47mypUrB+cOPPBAzQcffLDmzTffPCh30kknlasOc+fODY7vvfdezSeccILm5cuXB+UmT56sOQevYBNp//331zx69GjN0S5M211r78uqVauCcrZLq0WLFponTpwYlIt+rpi0bNkyOLb/Tp577rl8Vydr9ttvP80ff/xxjDVBKl26dNF89dVXB+fWrl1b4mfKMhQDSIU3PQAAIBFo9AAAgESoMN1bTZs2DY7feOMNzenOwsoG+2o1Oqvgl19+0fz0009r/u6774JyS5Ys0ZyNGSJJYWfO7bPPPsG5p556SvO2226b1vVmzZqluW/fvsG5ESNGaH733Xc1X3/99UG52267La3vKkTR2TC77rqr5kLr3rKzfHbaaSfNtptcRMS5rE+2Qgbq1q2reeONN46xJsl2wAEHBMedO3fWbLu/GzVqlPIaPXr00Bz9XXjIIYdofvLJJzVPmDCh7JXNEt70AACARKDRAwAAEoFGDwAASIQKM6Znzpw5wfGPP/6oORtjemwf4tKlS4Nzf/vb3zTbKcq2DxK59+CDD2qOrnKdCTsuqGrVqsE5u5SAHduy1157lft7C4XdhV5E5IMPPoipJuVnx3mdc845mu1YMBGRGTNm5K1OCB1++OGaL7nkkpTl7D069thjNf/www+5qVjCnHbaaZoHDBgQnNtqq6002/Fv48ePD8rVqlVL81133ZXyu+w17LXbt2+ffoWzjDc9AAAgEWj0AACARKgw3VuLFy8Ojnv27KnZvuIUEfn0008121WSoyZNmqS5TZs2mu3Uc5FwOl737t3TrDGyoVmzZpqPOeYYzaVNLbZdUy+99FJwzr5qnT9/vmb7d0YkXFbg0EMPTet7i42d5l3ohgwZUuKf22ULkF92tXwRkaFDh2oubciCfYajwx6Qng03DH+121XKH374Yc12mRARkbffflvzzTffrNku6yESLjMwcuRIzUcccUTKOlWU1dGL56ceAABAKWj0AACARKDRAwAAEqHCjOmJev755zWPGzcuOGd3z27cuLHms846KyjXv39/zdFxPNZnn32m+dxzzy17ZZG2Jk2aBMevv/665urVq2uO7qj8yiuvaLbT2Vu1ahWUs1uH2HEeCxcuDMpNnjxZs916xI4rEgmnvX/yySdS6Pbee2/NtWvXjrEm2ZVqjIj9+4X8+sc//hEcp9o+Jjod+oknnshVlRKjU6dOwXGqMW/R58NOZ1+2bFnK69typY3jmTt3rubHH388Zbl84k0PAABIBBo9AAAgESps95ZV2mu2n376KeW5s88+W7PdVdt2ZyD3dtttN812KQKRsFti0aJFmu10c5Hw1ejPP/+s+d///ndQLnpcVptuumlwfMUVV2ju2LFjua5dEbRt21Zz9J+1kES75uzO6ta8efPyUR2sZ1fdPfPMM4Nz9ueuXRX/1ltvzX3FEuCWW27R3KtXr+CcHS5w//33a7bDAURK/11rXXvttWmV69atm+boEIO48KYHAAAkAo0eAACQCAXRvVWaPn36aLar+4qEM3vsZndjx47Neb2SzK7WKSLSr18/zbZ7RSSciWc3wIyu3hlXV0ydOnVi+d5cadCgQcpzdhZjRWf/TomE3V2ff/65Zvv3C7lRr149zaNHj07rMwMHDtQcnZ2L9PTu3Ts4tl1aduNsEZHXXntN81VXXaV55cqVKa+/ySabaI7O0LI/F+0q9raLTURkzJgxKa8fF970AACARKDRAwAAEoFGDwAASISCH9NjV1o+55xzgnN2BV27s+ybb74ZlLPjRwYNGqQ5uiow0mNXMRb533E81vHHH6/Z7p6O/Pvoo4/irkKwKreIyFFHHaXZrjJb2iqwdndoOzUauWHvkV3xO+qNN97QPGDAgJzWqVhtvvnmmi+88MLgnP19ZcfwiIj8/e9/T+v69evX1zxs2DDN0fGy1qhRozT37ds3re+JE296AABAItDoAQAAiVDw3VvW7Nmzg+MuXbpofuyxxzR37tw5KGePN9tsM83Rje+iqwSjZHajV5FwSmO0C6sidGltsMGfbf/oat227sVuyy23LPNn7Ia/IuG/y8MOO0zzDjvsEJSrXLmyZrvStf28SDildsKECZp/++23oNyGG/75o2zixIlp1R2ZiXaV3HHHHSWWe/fdd4NjuwFpaSvpIzX73NjVr6PsSsgiIltvvbXmrl27am7Xrl1Qbs8999RctWpVzdGhHvb4qaee0lzaxt4VBW96AABAItDoAQAAiVBU3VtRzz33nOYvvvhCc7T7xb6Gv+222zTXrVs3KGc3xmMjw9Cxxx6ruUmTJsE5+yr0hRdeyFud0mW7tKKvcSdNmpTv6uSU7S6K/rMOHjxY8zXXXJPW9aKzdWx34OrVqzWvWLEiKDdt2jTNjz76qOboSty2+/OHH37QPHfu3KCcXbF7xowZadUd6ctk1eUvv/wyOLb3D5mxKy1HN/CsVauW5q+++io4l+5M5O+++06z3Xx02223DcrZzaFffPHFtK5dUfCmBwAAJAKNHgAAkAg0egAAQCIU9Zgea8qUKZpPPfXU4Nxxxx2n2U5tP++884Jyu+66q+Y2bdpku4oFzY6psNMqRUQWLFig+V//+lfe6mRFd37v06dPieWiOz5fffXVuapSLOwqrnPmzAnOHXjggWW+3jfffBMc212V7bidDz/8sMzXjjr33HM12/ELIv87fgTZZXfmji7rkEqqqezInF1hPLp0wEsvvaQ5uvyEXc7FPqNDhw4Nyi1evFjziBEjNEfH9NhzhYY3PQAAIBFo9AAAgERITPeWFd2E8Mknn9Q8ZMgQzXaVVxGRli1bam7durXm8ePHZ7eCRcaunpvPVa1tl9Z1110XnOvZs6dmO/05upzBzz//nKPaxe/OO++MuwplYpeWiEp3GjXSZ5eeKG2DV8t2ncycOTPrdcKf7ArlIv/b5ZsJ+zuuVatWmqNdmoXcncybHgAAkAg0egAAQCIkpnvLrhx78sknB+f2228/zdEuLcvORnn77bezWLvils9VmO0reduFddpppwXl7Gv4k046KfcVQ049//zzcVeh6IwdO1bzFltskbKc7Waxmzyj8NhZuKWtVM/sLQAAgAqORg8AAEgEGj0AACARimpMT4MGDYLjSy65RPMJJ5ygeZtttknremvWrAmO7XTrdFclTQq7u7bNIuHKod27d8/q915++eXBsZ2aXqNGDc3Dhg0Lyp1xxhlZrQdQbGrWrKm5tJ93gwYN0lzMSzwkwWuvvRZ3FXKONz0AACARaPQAAIBEKMjuLds9dfrpp2u+6KKLgnL16tUr87U//vhjzbfeemtwLp9TrwuNndIYnd5o79e9994bnHv00Uc1//jjj5qbN28elOvcubPmxo0ba95hhx2CcnYDTPuq9v777y/9HwAFJdqFajcD/uCDD/JdnaJgN1sWEdlgg/T+m/j999/PRXUQgyOPPDLuKuQcb3oAAEAi0OgBAACJUGG7t2rXrq25UaNGwbmBAwdqbtiwYZmvHd2o7a677tJsV+plhlZ2VKpUSfOFF14YnLOrIS9btkyz7a4oTbQrY9y4cZp79+5dpnqicES7UNPtikHIrmDepk2b4Jz9+bdq1SrNdraWiMgPP/yQo9oh33bZZZe4q5Bz/KQAAACJQKMHAAAkAo0eAACQCLGO6dlyyy01P/jgg8E529e88847Z3R9O5Wyf//+mqOrTq5cuTKj6+NPdmzNRx99FJyzu9hH2ensdhxXlJ3Obnf4zfYKzyhMLVq00Dx06ND4KlJgNt98c82lPX/z5s3T3KNHj5zWCfF55513NNtxcsU0vpU3PQAAIBFo9AAAgETIeffWAQccEBz37NlT8/777695++23z+j6tmtqwIABwbnbbrtN8y+//JLR9ZGeuXPnaj7xxBODc+edd55muyFoaaL3cvDgwZpnzZqVSRVRRKIrMgMovylTpmi2P2ejQ0zs1PaFCxfmvmJZxJseAACQCDR6AABAItDoAQAAiZDzMT0nnHBCqcepTJ8+XfOLL74YnFuzZo3mfv36aV66dGkmVUSWzZ8/Pzju06dPiRkoi1deeUXzKaecEmNNiseMGTM0R3dLP/jgg/NdHVQgdkzskCFDgnO33nqr5ksuuUTztGnTcl+xcuJNDwAASAQaPQAAIBFcdLfiUgs7l35hZI33Puvzc7mXsZnovd832xflfsaDZ7OoZP3ZLOR7Wb16dc0jR44Mzh1++OGan332Wc1du3YNysW4VEzKe8mbHgAAkAg0egAAQCLQvVUAeIVeVOjeKiI8m0WF7q0UbFeXSDh764ILLtC89957B+VinM1F9xYAAEg2Gj0AACARaPQAAIBEYExPAWDcQFFhTE8R4dksKozpKR6M6QEAAMlGowcAACRCWTccXSQic3JREaRUN0fX5V7Gg/tZPLiXxSUX95N7GY+U97JMY3oAAAAKFd1bAAAgEWj0AACARKDRAwAAEqGoGj3OuXrOuZXOuUnrj792zk1xzk1yzn1syt3lnPveOdcjvtrir5RwP49yzs10zn3hnLvalBvmnFvsnDs5vtqiNNF7uf7PKjnnPnXOvWT+jHtZAEp4Nh91zi1wzk2NlONnbQVXwr3s7pyb6pz7zDl3qSlXFPeyrLO3CsFs730Tc/w37/0iW8B739M590ue64XMzPbeN3HOVRKRQSLSRkTmishHzrkXvPfTvPcdnXNDY60l0hF9NruLyHQR0d0MuZcFxd7PoSJyn4g8YQvws7Zg/PFzdk8ROUdE9heRVSLyqnPuJe/9F8VyL4vqTQ+K2v4i8oX3/kvv/SoRGSEix8dcJ2TIObeDiBwjIkPirgvKz3v/togsjrseKLfdRWSC936F9361iLwlIifGXKesKvZGjxeRsc65ic65c+OuDMplexH51hzPXf9nKEz3iMiVIrI27ooAUFNF5BDnXE3nXBURaSsiO8Zcp6wqxu4t62Dv/Tzn3NYi8rpzbsb6/yIBEBPn3LEissB7P9E51zru+gBYx3s/3Tl3p4iMFZFfRGSSiKyJt1bZVdRverz389b//wIReU7WdZGgMM2T8L84dlj/Zyg8B4lIO+fc17Kum/JQ59xT8VYJgIiI9/4R730z731LEVkiIp/HXadsKtpGj3NuM+dctT+yiBwh617doTB9JCK7Oud2cs5VFpH2IvJCzHVCBrz3vbz3O3jv68m6+zjOe98p5moBEJH1PSPinKsj68bzPB1vjbKrmLu3aovIc845kXX/nE9771+Nt0rIlPd+tXPuYhF5TUQqicij3vvPYq4WABFxzg0XkdYispVzbq6I3OC9fyTeWiFDo51zNUXkdxG5yHu/NO4KZVPRNnq891+KSOO464Hs8d6/LCIvx10PZI/3fryIjI+5Gign732HuOuA7PDeHxJ3HXKp2Lq31ohIDbsAWkmcc3eJSCdZN1ALFVe693OYiLQSkV/zUitkgntZXPhZWzwSdS/ZZR0AACRCsb3pAQAAKBGNHgAAkAg0egAAQCKUafaWc44BQDHw3rtsX5N7GZtF3vta2b4o9zMePJtFJevPJvcyNinvJW96gPyaE3cFAJSIZ7N4pLyXNHoAAEAi0OgBAACJQKMHAAAkAo0eAACQCDR6AABAItDoAQAAiUCjBwAAJAKNHgAAkAg0egAAQCLQ6AEAAIlQpr23gHwZMGBAcNytWzfNU6dO1XzssccG5ebMYSV5ACgkb7zxhmbnwu3sDj300Kx+F296AABAItDoAQAAiUCjBwAAJEIix/RUq1YtOK5atarmY445RvPWW28dlOvfv7/m3377LUe1S6569epp7tSpU3Bu7dq1mnfffXfNDRs2DMoxpqfi2G233TRvtNFGwbmWLVtqvv/++zXb+5ypMWPGaG7fvn1wbtWqVeW+ftJF7+WBBx6o+bbbbtN80EEH5a1OKCx33313cGz/Dj3xxBM5/W7e9AAAgESg0QMAABKhqLu3dtppJ81XXnml5hYtWgTl9txzz7Sut80222i2U6iRHQsXLtT89ttvB+fatWuX7+ogDY0aNQqOu3TpovmUU07RvMEG4X9fbbfddpptl5b3vtx1sn9XBg8eHJy79NJLNS9btqzc35VENWrUCI7ffPNNzd9//71m+/Myeg7Jc8cdd2g+//zzg3O///67Zjt9PRd40wMAABKBRg8AAEiEgu/esrN37KtrkXAG0CabbKI5uuLjt99+q3n58uWa7SwhEZFTTz1Vs51xMmPGjLJWGyX45ZdfNDMLqzDcfvvtwXHbtm1jqknJzjjjjOD4kUce0fzee+/luzpFz3Zp0b0Fq3nz5pqjMwDfffddzSNHjsxpPXjTAwAAEoFGDwAASAQaPQAAIBEKYkxPdIrknXfeqfm0007THF1pOZVZs2YFx0ceeaTmypUra54+fXpQbquttioxIzs233xzzY0bN46xJkjX66+/HhynGtOzYMGC4PjRRx/VbMfYlTZl3S410apVqzLVE/kRHS+Jis2ujC4icu2112ru0KGD5sWLF2d0fXsNuzTM7Nmzg3I9evTI6PqZ4E0PAABIBBo9AAAgEQqie+uEE04Ijs8+++wyX8O+TmvTpk1wzk5Z33XXXct8bWRHlSpVNNepUyetz+y3337BsV0+gGnvuffAAw8Ex88//3yJ5eyKqyKZTV+uXr265qlTpwbn7ArPpdXn448/LvP3In22e3LTTTeNsSZIx0MPPRQc299/e+yxh2Y7pbwsbHdZzZo1NZ9zzjlBucmTJ2d0/UzwpgcAACQCjR4AAJAINHoAAEAiFMSYHrtbc2m+/vrr4Pijjz7SfNVVV2m2Y3ii7LYWyK/vvvtO89ChQ4Nzffr0KfEz0T9funSp5vvuuy9bVUMKq1evDo5Le7bKyy4tscUWW6T1mblz5wbHv/32W1brhNSaNWsWHH/wwQcx1QSprFixIji2Y7Ls1k3patKkSXBsx2auXbu2XNfOFt70AACARKDRAwAAEqEgurei09vOPfdczWPHjtX8xRdfBOWiq8Cmo3bt2mX+DLLv5ptvDo5TdW+huLVv316z/TmQ7nTo3r17Z71OSRft0vzpp58029Xzd9lll7zVCemzP1v32muv4Jxd8iPdaeSbbbaZZjuMRCRchuTDDz/UPGrUqPQqmwO86QEAAIlAowcAACRCQXRv2Vk9Irnt6rCbGqLi2GCDP9vndhYACl/Hjh019+rVKzhnu0g22mijtK43adIkzdGVoFF+doakiMg777yj+dhjj813dZCGHXfcUbPtJo52VV500UWaFy5cmNa1//nPf2qOzrS2v7sPOuig9CqbY7zpAQAAiUCjBwAAJAKNHgAAkAgFMaYnU926ddNsp9U554JydhXK6BQ+6/3339fM6qL5Zcfx2PuFeNWrVy847ty5s+bDDz88rWscfPDBmtO9t8uWLQuOr776as0vv/yy5pUrV6Z1PaCYRH+PPfvss5q32morzQMHDgzKvfXWW2ldv0ePHpq7dOmSstytt96a1vXyiTc9AAAgEWj0AACARCjI7i27ymOjRo00R1dfbdu2bYmft9OfRVJPgZ4/f35w3LVrV81r1qxJr7JAkbGvzseMGROcsxsM5pKdJi0i8tBDD+Xle5G+mjVrxl2ForbhhuGv706dOml+5JFHgnOplvyILtFyzTXXaO7fv7/mLbfcMihnp6bb4SJPPPFEUO7BBx9M/Q8QE970AACARKDRAwAAEqHCdm/Z1VebNm0anBs9erTmbbfdVnN0pobtnrIzr4466qignO0usypVqhQcn3jiiZoHDBigedWqVSV+Hih20ZmQ0eN0ZLLadnTlX9uVbWdvIT7t2rWLuwpFzW7GKyIyZMgQzdFZkPa5shtz77vvvkE5e2zv3/bbbx+Us7937crNZ555Zlp1jxNvegAAQCLQ6AEAAIlAowcAACRChRnTU7ly5eDYjruxq0lG3XjjjZrHjRsXnHvvvfc02yl30XJ77rlnideuVatWcHz77bdr/uabbzQ///zzQbnffvstZX2RmXTHfbRs2VLzfffdl9M6JdWUKVM0t27dOjhnp82+9tprmn/99deMvuuss87SfMkll2R0DeTWm2++qZld1nPrtNNO0/zYY48F537//XfNS5cuDc6dfvrpmpcsWaLZTksXEWnVqpVmO76ntF0M7ArP3377bVDO/nyYPXu2VAS86QEAAIlAowcAACSCK8vmjc65rO70aKel33TTTcG5nj17pvzcq6++qtm+To++0rPdU3Ya6z777BOUs1PO+/btqzna7XX88ceXWJ///Oc/wbG9hn2VGPXpp5+mPGd578s+D/gvZPte5ppdATvdv7N777235mnTpmW9Thma6L3f96+LlU2h3c901ahRQ/OPP/6YspydXpvPKes8myInnXSS5meeeUZzdAmRPfbYQ/OcOXNyX7Gyy/qzme17aYdm1K1bNzhnN/d89NFH07qevSci4crmzZs311xa95b19NNPB8dnnHFGWvXIgZT3kjc9AAAgEWj0AACARMj77C27yvHNN9+suUePHkG5X375RXOvXr2Cc8OHD9dsu7T222+/oNzAgQM121WdZ82aFZS74IILNNuZCNWrVw/KHXjggZo7duyoObry6NixYyUVO7p9p512SlkOocGDB2s+77zz0vrMueeeq/nSSy/Nep2Qe0ceeWTcVcBfWL16dYl/Hu0S2XjjjfNRnaJmN/iNzmqOzpxKh515JRJu4G116NAhOJ46dWqJ5ebOnVvmOuQbb3oAAEAi0OgBAACJQKMHAAAkQt7H9NhxFnYcz4oVK4JydtxGdIyMnUrXtWtXzXanZRGRTTbZRLOdEh9dyTJVX+iyZcuCYztV3uZof6cd7xN12WWXpTyH1GbMmBF3FRLFLidxxBFHBOfstNnotOTyiu7SfM8992T1+sg+O87EPqcNGzYMytlxdRdeeGHuK1aEBgwYUO5r2GUgTj311OCcHcdqV1AeOXJkub+3ouBNDwAASAQaPQAAIBHyviLz/PnzNdsVk6ObdNrXpJtttllwrn79+ml9V58+fTTbzULt6r6FgFVfQ59//rnmXXbZJWU5u0lp9O9MjJvfVdgVmQ855BDN11xzjeY2bdoE5exSC5lMkxUJNwC23dJ2mQkRkWrVqpX4+Wi3ml02wi47kWs8myHbHWmHHoiI1K5dW3OmG9DmWIVfkTkb7BIwdtkYEZGFCxdqtkvAFMJU9AhWZAYAAMlGowcAACRC3mdvff/995pt91Z0tc7GjRunvIbdUPDtt9/W/Pzzzwflvv76a82F1qWF1D777DPNO++8c8pya9euzUd1iobtWoputmtdeeWVmpcvX57Rd9kuM7sBcGnd7ePHj9f8wAMPBOfy2aWF9ETvpd3YGfllNyc9++yzNUfvkd1wtAC7tNLCmx4AAJAINHoAAEAi0OgBAACJkPcxPS1bttT897//XbPt1xcRWbBggeZHH300OLdkyRLN9BMnj+13Pu6442KsSTJdcMEFObu2fe5FRF588UXN3bt311xBpzzDsKv7ioQ/76M7hCO3Xn/9dc12fM9TTz0VlLvhhhvyVqe48KYHAAAkAo0eAACQCHnv3rJTXJ988skSM1CaadOmaZ4+fXpwbvfdd893dYqGXUH34osv1vyPf/yj3NeOroBtNxh+5513ND/88MNBuSlTppT7u5E/dgPL6Cr79rlFfg0dOlSz3Xz7hRdeiKE28eJNDwAASAQaPQAAIBFo9AAAgETI+y7rKDt2ci4qFXaXdctuC9OlS5fg3C233KJ5iy22CM7ZrWDsNNkxY8YE5ex2NIWMZzM0YsQIzdHxde3atdM8Z86cvNWpDBKxy3pCsMs6AABINho9AAAgEejeKgC8Qi8qBdG9hfTwbBYVureKB91bAAAg2Wj0AACARKDRAwAAEoFGDwAASAQaPQAAIBFo9AAAgESg0QMAABKBRg8AAEgEGj0AACARNixj+UUiUiF3iitidXN0Xe5lPLifxYN7WVxycT+5l/FIeS/LtA0FAABAoaJ7CwAAJAKNHgAAkAg0egAAQCIUVaPHOVfPObfSOTfJObejc+5N59w059xnzrnuptxdzrnvnXM94qwvSmfv5/rjR51zC5xzUyPluJ8VXOTZ3MQ593/Oucnrn80bTblhzrnFzrmT46wvSsezWTyi93L9n1Vyzn3qnHvJ/FlRPJtF1ehZb7b3vomIrBaRK7z3e4hIcxG5yDm3h4iI9wEt5lIAACAASURBVL6niAyOsY5I3x/3U0RkqIgcFS3A/SwYf9zL30TkUO99YxFpIiJHOeeai4h47zuKyAsx1hHp49ksHvZeioh0F5HptkCxPJvF2OgRERHv/Xzv/Sfr83JZdwO3j7dWKA/v/dsisjjueqB8/Do/rz/caP3/mEZawHg2i4dzbgcROUZEhsRdl1wo2kaP5ZyrJyJNRWRCvDUBIKKvzyeJyAIRed17z7MJVAz3iMiVIrI27orkQtE3epxzVUVktIhc6r1fFnd9AIh479esf52+g4js75zbM+46AUnnnDtWRBZ47yfGXZdcKepGj3NuI1nX4BnmvX827voACHnvl4rIm1LCeBAAeXeQiLRzzn0tIiNE5FDn3FPxVim7irbR45xzIvKIiEz33v8z7voAWMc5V8s5t/n6vKmItBGRGfHWCoD3vpf3fgfvfT0RaS8i47z3nWKuVlYVbaNH1rVYO8u6luqk9f9rG3elkDnn3HAR+UBEGjjn5jrnzoq7TsjItiLypnPuvyLykawb0/PSX3wGFRjPJgpFWTccLRje+3dFxMVdD2SP975D3HVA+Xnv/yvrJhagSPBsFh/v/XgRGR9zNbKu2N70rBGRGnaRpZI45+4SkU4i8kteaoVMcT+LR7r3cpiItBKRX/NSK2SKZ7N4JOrZZJd1AACQCMX2pgcAAKBENHoAAEAi0OgBAACJUKbZW845BgDFwHuf9Vlo3MvYLPLe18r2Rbmf8eDZLCpZfza5l7FJeS950wPk15y4KwCgRDybxSPlvaTRAwAAEoFGDwAASAQaPQAAIBFo9AAAgESg0QMAABKhaDccBQBUHLvttpvmV199VXOlSpWCcnXr1s1bnZA8vOkBAACJQKMHAAAkAt1bAICsGzhwYHB82mmnad5yyy01v/TSS3mrE8CbHgAAkAg0egAAQCIUfPfWHnvsofnYY48Nzp1zzjmaP/roI82TJk1Keb177rlH86pVq7JRRQAoWrVr19b87LPPam7evHlQzvs/996cOnWq5rPOOiuHtQNCvOkBAACJQKMHAAAkAo0eAACQCAU5pue8887TfNddd2muWrVqys/ssssumtu3b5+y3Mcff6x53LhxmVYRqJDsM2KnEIuI/Prrr5qbNWumuVq1akG5jh07ah4/fnxwbt68eWWu0/fff695zJgxwTn7PKJisCsri4j069dP8wEHHJDyc7169dJs7+uPP/6YxdrhrzjnNA8fPjw417ZtW812vOzcuXNzX7E84U0PAABIBBo9AAAgEZydRviXhZ1Lv3AO2dU8p02bpnnrrbcu97WXLl2qOdoNNnbs2HJfPxPee/fXpcqmotzLBJrovd832xdN93727dtXc48ePbJdjXJbu3ZtcGyf7xEjRmiOvpb/6quvcluxFJL4bLZo0SI4fuedd0osZ7tRREQ6deqkOXr/KoisP5sV8V5WqVJF8+effx6c22677TSfe+65mocMGZL7imVXynvJmx4AAJAINHoAAEAiFOTsrcWLF2vu06ePZjuLQCR8jffNN99orlOnTsprb7755pqPPPLI4Fxc3VvIrbp162redNNNg3MdOnTQfMEFF6S8xr///W/NXbt2zWLtsuvEE08s82eis2v++9//lvkaM2fODI4bNGig2T5zTZs2Dcrtueeemm+55RbNkydPDsrF1b2VFHbG1rBhw4Jz0W6sP0T/rkVn5iEeK1as0Fxa91Y2hotURLzpAQAAiUCjBwAAJAKNHgAAkAgFOabHGjx4sGa7UrOISOPGjTUvW7aszNceNGhQ5hVDhXL44YcHx3a8gR23U6NGjaBcuks6RHeUrqjsODU7rkbkf8fd/MGOARARmT9/flbrZFd8njJlSnAu1fi7du3aBcd2TBWyr3Pnzpqj9+Tll1/WfP7552vOZHVu5Ff0d1zr1q01N2zYMM+1yQ/e9AAAgESg0QMAABKhIFdkTuXkk08Ojq+55hrNTZo0KfP1GjVqFBxPnz49s4qVUxJXfc2UXTl0r7320rzffvul9fnly5cHx3Z6bnTzy6efflqz3azzL8S6InNFdPrpp2t+6qmnUpb77bffNLds2TI499FHH2W/Ymko5mfz/fff12x/fn733XdBuaOPPlrzrFmzcl+x3EnEiszWjjvuGBzPmTNH86pVqzTvtNNOQblsd3HnACsyAwCAZKPRAwAAEoFGDwAASISCn7JujRo1Kjh+9913Nb/22mua7ViP0tx0003B8SmnnFKO2iFbatasqfn2228Pzp155pma7XYlEydODMrdcccdmqdOnap55cqVQTm7fQkyV7ly5eD43nvv1XzGGWekdY0DDzxQ86effpqdikEdf/zxwfEBBxyg2Y79fOaZZ4Jy0WcGhctuKWKf2egSEQ8++GDe6pRtvOkBAACJQKMHAAAkQlF1b3Xs2DE43nvvvTXb3ZrT9d5775W7Tsi+66+/XvNZZ50VnBs4cKDma6+9VvPPP/+c+4ohcOihh2ru1KlTcK5Lly4lfub3338Pjrt166Y5riUjipnd4f6QQw5J6zNLliwJjufOnVvm7+3evbvm6LRpq0ePHmW+NjKXagmbaPd0IeNNDwAASAQaPQAAIBEKsnvLboT27LPPaq5fv35QbsMNy/eP98ILL5Tr8yibKlWqaL7qqquCc3bDw0svvVTzm2++GZSzs/TKsEoysmT//ffXbO9FpUqV0vp89PX6t99+q3nNmjXlrB2i7L/TZs2aBec22ODP/yZeu3at5rfffjuta19++eXBsb23l1xyiea6deumvMYVV1yheYcddgjOsaEpMsGbHgAAkAg0egAAQCLQ6AEAAIlQkGN6dt99d81299fyjuGJsmNHRMLps8i+6667TnN0TM/IkSM1jx07VjPjdiqWU089VXO643is6NTYl156SbPd5f7FF18Myj3//POap0yZUubvTapWrVppjk5Zt+N47MrkP/74Y8rr2d3YDz744OBcdFXfP/zyyy/BsZ0C36BBA83RFffbt2+v2e4ODpSGNz0AACARaPQAAIBEKMjureeee06z7Qaxm0iKiGyyySbl+p5tt922XJ9H2fTq1UtzdOry8OHDNdOlVXHZJSRsN/R+++0XlNtqq63KfO199923xCwicsMNN2i+5557NPft2zcot2DBgjJ/bzGpVq1acGyHB0TNnz9f85NPPql51qxZQbnddttNc8+ePTVHNzBdtGiR5tdff11z//79g3LVq1fXPG7cOM01atRIWVdkh91wNNXqzIWONz0AACARaPQAAIBEKMjuLevee+/VHH3tajfTs6KzvOwmlfbVKvLr//7v/zRHuy/uu+8+zStXrtRsX5Mjfu+//77mY445RnOdOnWCcrZ7q3bt2ppPPPHEoNyZZ56p2b56j7KrB9uVgKOrDB922GGa7eykpIjOqLr77rtTln3ooYc033TTTZrt/RIR6devn+a2bdtqXr58eVDumWee0WxXWt51112DcoMHDy7xGrarS4QZW7lQrF1aFm96AABAItDoAQAAiUCjBwAAJELBj+mxXnnllbTKRccG7LLLLpp79+6t2a4uKhLuBkx/cvoOOOAAzZ9++mlwbtWqVZqPPvpozdHVr6+//nrNdmXW5s2bB+WmT59evsoiJ+yKviUd/yH6DI8fP16z3Znb7uZeGrvisIhIjx49NEensyfB3nvvnXZZO47HsssSiITPtxWdsv7WW29pbtGiheZ33nknZR3s8gP23iG//vvf/8ZdhazhTQ8AAEgEGj0AACARiqp7K13RTQ1tl5b1+++/B8dr1qzJWZ0KnV292m4SKRJOV77sssuCc0899ZTmxYsXa7ZT1EXC7q2qVatq3mKLLTKsMQrBsGHDNP/rX//S/J///Cco17Jly7SuV79+/exUrEBFl/GwXf1jxoxJ+Tnb1V+vXr2U17BT0W13lki4crO9r9HhBvYatnsL8Zk9e3bcVcga3vQAAIBEoNEDAAASIZHdWzfffHNa5R599NHgeO7cubmoTlH45JNPNEdXtbabwtrurNJceumlKc/Zro2pU6emW0UUuNWrV2ueOHFicC7d7q3PP/88q3UqdHYF3nRX442uZG0/Z2eHRWfo2Q2gv/rqK82HHHJIUO6nn35Kqx5AJnjTAwAAEoFGDwAASAQaPQAAIBFiHdNTs2ZNzdHxM3Z66tNPP13u77JTqs8999y0PhNdeRSp2d3ur7vuupTnbI6aNWuW5ujOy3YF7F69emletmxZ2SuLcrHP0jnnnBOcmzFjhuaRI0dm9XsrVaqkuXHjxml9xo4DEhGZMGFCVutUaF544YXguGfPnpqjKyjbVZPtv+9q1aqlvP4ZZ5yhOToVfdGiRZpvvPFGzfPmzfuraiNmG2+8cdxVyBre9AAAgESg0QMAABIh1u6tAQMGaD7uuOOCc3b1zujrT3v8xRdfaG7WrFnKa9jXuNEp1Vb//v01f/fddynLIXT77bdrjq5k3bRpU82HH354ymvY1ZVffvnl4JxdpdXec+TeNttsExy/+uqrmvfaa6/gXLZXyK5du7bmyy+/XPOhhx6a1uejG9CWtrllEtgNfkVEVqxYoblKlSrBuXfffVdzutPZreXLlwfHzzzzjObo842KrW3btsHxwIEDY6pJ+fGmBwAAJAKNHgAAkAixdm8NGjRI80477RScszMH3nzzzeDc119/rXnatGmaoyt7ppplEH1Va2ec9OnTR/Ovv/6aouYoTb9+/eKuArIouuljtEvLss/xzJkzNa9cuTLlZzbddFPNV155ZXDOdmmVNmvIzhSy3SrdunVL+Zkkiq5k3aFDB83237WISOvWrdO65uOPP655ypQpmj/99NOgXHQDUsTvhx9+CI7t79M99tgj39XJC970AACARKDRAwAAEoFGDwAASARXlqmIzrmyz1tMU3QcyOzZszXbsT/ZsHjx4uB4q622yur1s8177/66VNnk8l6iVBO99/tm+6K5vJ/RVZcffPDBtD5nx3SUtnN2jRo1NNvlDcri559/1nzCCSdofuONNzK6Xrp4NotK1p/NQruXH330kWa7BMxLL70UlGvXrl3e6pShlPeSNz0AACARaPQAAIBEiHXKutWjR4/g2G5wVrVq1ZSfa9KkiWY7/TLKvl4/4ogjMqkikEj/+c9/guMRI0Zobt++fcrPZdpVlYrdPDQ6jX706NGak76pKJCpSZMmabbdW6X9Di40vOkBAACJQKMHAAAkAo0eAACQCBVmyjpSY1psUSm4KetRdrydnR4uEu5+/vnnn2subYqr3QYmaty4cZrtthbRLQ7iwrNZVBI/Zb1evXqahw8frtluNSIiMnjw4HxVKVNMWQcAAMlGowcAACQC3VsFgFfoRaXgu7fwJ57NopL47q0iQvcWAABINho9AAAgEWj0AACARKDRAwAAEoFGDwAASAQaPQAAIBFo9AAAgESg0QMAABKBRg8AAEiEDctYfpGIzMlFRZBS3Rxdl3sZD+5n8eBeFpdc3E/uZTxS3ssybUMBAABQqOjeAgAAiUCjBwAAJAKNHgAAkAhF1ehxztVzzq10zk1yzm3inPs/59xk59xnzrkbTblhzrnFzrmT46wvSmfv5/rjr51zU9bf349Nubucc98753rEV1uUhmezuJTwbG7unBvlnJvhnJvunGux/s95Niu4Eu7lo865Bc65qZFyRXEvyzp7qxDM9t43cc45ETnUe/+zc24jEXnXOfeK9/5D731H59zQmOuJ9Mz23jcxx3/z3i+yBbz3PZ1zv+S5Xig7ns3iYp/NASLyqvf+ZOdcZRGpIsKzWUDsvRwqIveJyBO2QLHcy2Js9IiIiF83Le3n9Ycbrf8fU9WAmPFsFhfnXA0RaSkiXUREvPerRGRVnHVC5rz3bzvn6sVdj1wpqu6tKOdcpfWv7BaIyOve+wlx1wnl4kVkrHNuonPu3Lgrg8zxbBaVnURkoYg85pz71Dk3xDm3WdyVAkpS1I0e7/2a9a/sdhCR/Z1ze8ZdJ5TLwd77fUTkaBG5yDnXMu4KITM8m0VlQxHZR0Qe8N43FZFfROTqeKsElKyoGz1/8N4vFZE3ReSouOuCzHnv563//wUi8pyI7B9vjVBePJtFYa6IzDVv60bJukYQUOEUbaPHOVfLObf5+rypiLQRkRnx1gqZcs5t5pyr9kcWkSNEZGrpn0JFxLNZXLz334vIt865Buv/6DARmRZjlYCUinYgs4hsKyKPO+cqybrG3Ujv/Usx1wmZqy0iz62b+CMbisjT3vtX460SMsSzWXwuEZFh62dufSkiXWOuDzLknBsuIq1FZCvn3FwRucF7/0i8tcqeom30eO//KyJN464HssN7/6WINI67Hig/ns3i472fJCL7xl0PlJ/3vkPcdcilYuveWiMiNf5YZCkV59wwEWklIr/mpVbIVLr38y4R6STrBlCiYuLZLC48m8UjUfeSXdYBAEAiFNubHgAAgBLR6AEAAIlAowcAACRCmWZvOecYABQD773L9jW5l7FZ5L2vle2Lcj/jwbNZVLL+bHIvY5PyXvKmB8ivOXFXAECJeDaLR8p7SaMHAAAkAo0eAACQCDR6AABAItDoAQAAiUCjBwAAJAKNHgAAkAg0egAAQCKUaXFCAAAysfPOO2u+/fbbNZ9wwglBub333lvzjBkzcl8xJApvegAAQCLQ6AEAAIlA9xYAIOsOPPDA4PjVV1/VvHDhQs2DBg0Kyv3www+5rRgSjTc9AAAgEWj0AACARKDRAwAAEoExPagwOnfurPnII48MzjVu3FhzgwYNUl7jww8/1Hzcccdp/umnn7JRRVRQm222mebx48dr3m677YJyBx10kOavv/4619VKnGOOOUbzqFGjgnODBw/WfO2112pesWJF7isGrMebHgAAkAg0egAAQCLQvYW82mqrrYLjIUOGaLbdUUuXLg3KffDBB5rnzJmjuVWrVkG5gw8+uMTP7LHHHhnWGPkU7Y6qVatWieWWLFkSHP/tb3/T3KxZM80zZ84Myv3444/lrSIidt11V80jR47U/NZbbwXlrrjiCs1r167NfcWAEvCmBwAAJAKNHgAAkAiJ7N6yr1lFRCpXrqx5991319yxY8eU17Ab4TVq1CiLtStudlVWEZF69epp7tu3r+a77rorKLd48eISr9ewYcPg+P/+7/8077bbbpp79+4dlLvpppvSqzAyttdee2m+5JJLgnN169Yt8TP2nomI1KlTp8Ryd9xxR3Bsuy+dc5rnzZsXlLPPOjKzySabBMcPP/yw5ilTpmg+9dRTg3J0aVV8W265pebTTjtN8zXXXBOUi3ZD/+H6668Pjm+77bYs1i47eNMDAAASgUYPAABIBBo9AAAgEZz3Pv3CzqVfOAbR6ct77rlniedOOOGEoJwdA5Au2z/9xRdfBOeyPT3ae1/2Cv6FfN7LNm3aaI6O6bFTXDt06FDu77Jjda677jrNdpq7iMhOO+1U7u/K0ETv/b7ZvmhFfDa7deum+e67707rM7/99ltw/Mwzz2g+7LDDNG+77bYpr2Gf5zPOOCM499RTT6VVj3QV+rOZieh4u4svvliznb4+d+7cvNUpS7L+bFb0e9miRYvg+J///Kfm/fffX3NZ2gnWk08+qblr164ZXSNDKe8lb3oAAEAi0OgBAACJUGGnrNvX18OHDw/O7bzzziV+pkaNGsGx3YTQvvKeOHFiUG6fffYpc/022ODP9qL9HvyvjTbaSHO0K3DEiBFZ/S67yaHt3opOs61evbrmZcuWZbUOSdanTx/NPXv2TFnu8ccf17xw4ULN/fr1C8rZc02aNNH82muvBeXsSt/2M9FNL5GZjTfeWHOnTp2Cc3aD1wLs0koc+6w89NBDwTm7ZIt9jp5//vmg3JgxYzTbLuRTTjklKNe8eXPNdrmIVatWlbXaWcObHgAAkAg0egAAQCLQ6AEAAIlQYcb0HH744cGxXdp8xx13LPf17TTyRYsWBedsH6ddXvuxxx4Lyu2www4lXnvatGnlrl8xGzdunOamTZsG51asWJHV74pOef5D7dq1g+PTTz9d8+DBg7NahySz49s23XRTzdElA6699lrN8+fPT3m9+vXra7ZL4Ud3X7d/j2688UbNv/76azrVxl+48sorNVetWjU4Z+8lKj47HseO4RERGTt2rOa2bdumdT07TjP6e9z+zrTfNXny5PQqmwO86QEAAIlAowcAACRChenesq9PRdLv0rLdGVdddVVwbsKECZpnzpyZ8ho//vij5u7du2tO1Z0lIvL1119r7ty5c1p1Tap8djF8+eWXmm23Y3SVbLtyLLLHThE/+uijNUdfo9td0i+88ELN0WUn7AqxxxxzjObFixcH5W699VbN999/f1mrjb9wxBFHaH7vvfeCc5988km+q4NyWLlyZcpztusrG+xyINFhJXHhTQ8AAEgEGj0AACARYu3esq9M7cqNf+Wbb77RbLuWoq9dM1Fal5ZlXwNWlNd2EPn9999LzMiPSZMmaf7ggw80R7u37OahdkPa6MakderUKfF77AwtEZGBAweWvbIo1SGHHKLZ/nzee++9M7pe69atNdvVfj/77LOMrofM2N0JopttL1myRLNdxX6XXXYJynXp0kVzs2bNNH///fdBOTtLdt68eZlVOMt40wMAABKBRg8AAEgEGj0AACARYh3Tc8UVV2iuUqVKynLvv/9+cGz78zMZx7PFFlsEx3ZqbcuWLdOqx8svv1zm70Xu2d2gozurW8uXL89HdRLHLiFR2u712267rebRo0drjo4x8N5rfuSRRzRHd31G9nXs2FHz9OnTNdtlIaLsWI/+/fsH5+zPXfv3pEePHkG5QYMGlbmuSF+jRo002+dLROTyyy/XbH8/23E7Ue3bt9dsl6yoqHjTAwAAEoFGDwAASIRYu7ceeughzXbTTxGRn376SbOd9ibyv9Piyur8888Pjm+++eYSy0WnUp566qlZqwNyo169epobNGiQstyrr76a1vXs38vGjRsH51q0aKH5mWee0Vza6t9JEt1kNBO2G7lfv36av/3223JfG6U788wzNdufwdFNfStXrqz5hhtu0HzeeecF5V577TXNdjPL6MbOs2fP1pzuc4r02R0IqlWrFpzbd999Nduu5mg3mN3gt9A23OZNDwAASAQaPQAAIBFi7d6yszZszoXjjjtOc+/evVOWW716teYHH3wwOEeXVsVgZ2hFV9A+6KCD0rrG4MGDNU+cOFHzPvvsE5TbcsstNUc3wbUzwOrXr6/ZzmBJmkqVKmm2K/pGZ2Wl8u9//zs4ts8tcsvO6hER2XDDP3892J+LUfaZsd1Rpc3k+de//qX54IMPDs716tWrxOshO+x9ju6EYH+e2nsU9eyzz2qmewsAAKACotEDAAASgUYPAABIhFjH9OSTXcE1Ov3O6tatm2Y7pR6Z23TTTTVvvfXWwTm70ucBBxyg+dBDD03renvssUdGdbL92jVq1EhZ7tFHH9UcHW9ip35+9dVXGdWj2IwYMULziSeeqLm0Z85Ktxyyb5tttkl5rrRlGOzSHtddd12Zv/eBBx4IjqdMmVLmayAzH374YXC81157pfW52267LRfVyQve9AAAgESg0QMAABKhqLu37Cu4DTb4s323du3alJ956623clqnYmW7nPr06ROcs9OOGzZsmNH17eaVP//8s+boVFo7zdYaMmRIcGynrH/yyScZ1SmptttuO81du3YNzp100kmabVdV9N/x5MmTS7xGtPsTFcPcuXNTnivv5r2lXRv5teeee2pO93dmoeFNDwAASAQaPQAAIBGKqnvLbnwnItK0aVPN9vVcdIZI9+7dNc+aNStHtStudnZcmzZtgnN2g8LoDCg762nMmDElfkZE5Ouvv9ZsX4fPmDEjKLfbbrtp/vLLLzVffvnlQTnbRYayOeywwzTfdNNNKcvZmTz33XdfcO7vf/+7Ztu9VWiruxaT6KrZ6a6iXV6tWrUKjsvbXYbMrVy5UrP9nTl+/Pig3KpVq/JVpazjTQ8AAEgEGj0AACARaPQAAIBEKPgxPVWqVNHcqVOn4Fx0bMkfhg8fHhwPGzZMczFNzcunI444QnN0dWI7jfnTTz/N6Pp2Kvqdd96pObrL+oIFCzSfeuqpmhnDk7nWrVsHx/fee2/Ksu3atdP8n//8R3N0td/evXuX+Hk7dgv5FR3rmMvVsTfaaCPN559/fnDuySefzNn3IrT77rsHx2eddZbmhQsXao6uml3IzylvegAAQCLQ6AEAAIlQkN1b1apV0/zwww9rPvnkk1N+5rLLLtMcnT5Ll1b52VfhS5cuDc5lsoHgJptsEhw/88wzmo855hjN0ant7du318xKy9kR7Sa2G7RGVzB/6aWXNNsujGOPPTblNezU6EWLFpWvsshYdLmA+fPna7ZDB6JdHemyfx/sNerVqxeU+8c//pHR9ZEe++y9+uqrwbntt99e81VXXaV51KhRua9YnvCmBwAAJAKNHgAAkAgF2b1lZ+yU1qU1e/ZszaXNOEH5ff7555qbNGkSnHvooYc016xZMzhnN560Kyj37NkzKNegQQPNEyZM0HzhhRcG5TKdHYbUSpvVEz1nuzDsqssDBgwIyi1ZskSz3Qz2/vvvL19lkTHbnSUSbtjcv3//lJ+zs1932WUXzXvvvXdQ7pprrtH866+/arYzP0Xo4sy1vn37arbdWSIiI0aM0FzaPS9kvOkBAACJQKMHAAAkAo0eAACQCAUxpqdhw4bBcXTH7D/YcSUiIkcffXTO6oSQvUc333xzcK5Hjx6aN9ggbGcfddRRJV7vhRdeCI6vuOIKzdFplsitWrVqpTxnV20VEXn99dc1H3LIISk/Z3dWf/HFF8tRO+TKoEGDSvzz6FiP6BIgf4julm7HVd5yyy2aC3nH7kJx+OGHa7bLD9hd1UXCpUGKFW96AABAYrkq1wAAFohJREFUItDoAQAAieDKsqmccy53O9CVwk6JFBE57bTTSizXrVu34LhYpr96791flyqbuO4lZKL3ft9sXzSX9/PSSy8NjkubympXV168eLHmaFfJHXfcoTn6ir2Q8GwWlaw/m3Hdy+gq1xMnTtRsV7vv3LlzUO7ZZ5/Nab3yKOW95E0PAABIBBo9AAAgEWj0AACARKiwU9YbNWqkuXr16inL2S0O3njjjZzWCUiixx9/PDiuXLmy5uuvvz449/HHH2u2yw7cfffdOaodABGRTTfdVLNdJkQk3Fl99OjRmotoDE/aeNMDAAASgUYPAABIhAo7Zf3OO+/UbFfjFRGZM2eO5rZt22qeOXNm7isWA6bFFpWCm7KO1Hg2i0pBT1m/8MILNQ8cODA498EHH2g+7LDDNP/222+5r1g8mLIOAACSjUYPAABIhAo7e2vs2LGao91bdsPRYu3SAgAglf333z84vuaaazTbDV1FRB5++GHNRdyllRbe9AAAgESg0QMAABKBRg8AAEiECjtlHX9iWmxRYcp6EeHZLCoFPWUdAaasAwCAZKPRAwAAEqGsU9YXicicvyyFbKqbo+tyL+PB/Swe3Mvikov7yb2MR8p7WaYxPQAAAIWK7i0AAJAINHoAAEAi0OgBAACJUFSNHudcPefcSufcJOdcg/X//8f/ljnnLl1f7i7n3PfOuR5x1xmpRe7njs65N51z05xznznnupty3M8Kzt7L9ceXrb+PU51zw51zm6z/82HOucXOuZPjrTFKU8L93Nw5N8o5N8M5N90512L9n/NsVnAl3Mvu65/Lz/74nbn+z4viXlbYDUfLYbb3vsn63ERExDlXSUTmichzIiLe+57OuV9iqh/KZrb3volzblsRucJ7/4lzrpqITHTOve69n8b9LBh/3MvtRaSbiOzhvV/pnBspIu1FZKj3vqNzbmistUS67M/aASLyqvf+ZOdcZRGpIsLP2gLyx7O5p4icIyL7i8gqEXnVOfeS9/6LYrmXRfWmpxSHybqbytTBAuW9n++9/2R9Xi4i00Vk+3hrhXLYUEQ2dc5tKOt+QX4Xc32QIedcDRFpKSKPiIh471d575fGWytkaHcRmeC9X+G9Xy0ib4nIiTHXKauS0uhpLyLD464EssM5V09EmorIhHhrgkx47+eJSD8R+UZE5ovIT977sfHWCuWwk4gsFJHHnHOfOueGOOc2i7tSyMhUETnEOVfTOVdFRNqKyI4x1ymrir7Rs/5VazsReSbuuqD8nHNVRWS0iFzqvV8Wd31Qds65LUTkeFn3y3I7EdnMOdcp3lqhHDYUkX1E5AHvfVMR+UVEro63SsiE9366iNwpImNF5FURmSQia2KtVJYVfaNHRI4WkU+89z/EXRGUj3NuI1nX4BnmvX827vogY4eLyFfe+4Xe+99F5FkROTDmOiFzc0Vkrvf+jzevo2RdIwgFyHv/iPe+mfe+pYgsEZHP465TNiWh0dNB6NoqeM45J+vGDEz33v8z7vqgXL4RkebOuSrr7+thsm6MFgqQ9/57EfnWOddg/R8dJiLTYqwSysE5t/X6/68j68bzPB1vjbKrGGdvqfX9ym1E5Ly464JyO0hEOovIlD+mVorINd77l2OsEzLgvZ/gnBslIp+IyGoR+VREHoq3ViinS0Rk2PrhBF+KSNeY64PMjXbO1RSR30XkomIblF7UjR7v/S8iUjPueqD8vPfvioiLux7IDu/9DSJyQ9z1QHZ47yeJyL5x1wPl570/JO465FKxdW+tEZEa5k1AiZxzd4lIJ1k34A4VF/ezeKR7L4eJSCsR+TUvtUKmeDaLR6LuJbusAwCARCi2Nz0AAAAlotEDAAASgUYPAABIhDLN3nLOMQAoBt77rM9a4l7GZpH3vla2L8r9jAfPZlHJ+rPJvYxNynvJmx4gv9j0FqiYeDaLR8p7SaMHAAAkAo0eAACQCDR6AABAItDoAQAAiUCjBwAAJAKNHgAAkAg0egAAQCLQ6AEAAIlQphWZAQBAsjz99NPBcfPmzTV36NBB84QJE/JWp0zxpgcAACQCjR4AAJAIdG9F7LbbbpoHDx4cnOvYsaPm+fPn561OyEzr1q01v/HGG8G5DTbYoMRyb731Vq6rBQAFpW7dusFxvXr1ND/55JOaGzVqFJT7/fffc1qvTPCmBwAAJAKNHgAAkAg0egAAQCLkZExPtWrVNFetWjU499NPP2lesWJFLr6+XNq2bau5ZcuWwbmzzz5b8+2336559erVua8Y0tKlSxfNl1xyiea1a9em/Mw///lPzU888URwbtCgQZq5z0D29erVKzi+9dZbNfft21fz1Vdfnbc6QWTHHXfUvO+++6YsV79+fc0bbhg2KRjTAwAAEBMaPQAAIBGc9z79ws6lVfiWW27RHH0l2bNnT81333132t+dL4cccojmN998M2W5hg0bav7iiy9yWifvvcv2NdO9lxWd7c4SEencubPmaPekZaesl9b1ZV/dzpkzJ4Ma/o+J3vvU74ozVCz3Mzo19rLLLtN84YUXao6+Rh8xYoTm008/PUe1+188m5mxQyBmzpwZnKtdu7Zm2z1y0UUXBeUeeeSRbFcr689mId/LvfbaS/PkyZNTlnv++ec1n3zyycG50n625ljKe8mbHgAAkAg0egAAQCLkfUXmG264QfOXX36pecyYMfmuSonsq1XEZ/PNNw+OmzRpovmxxx7TXKtWraDcxhtvXOL1ZsyYERzb7i27Cjfy78wzz9Qc7fKeNWuW5vPOO0+znVkiEv5cuemmmzRH7zviY7skL7jgAs2l/cz94YcfNH/wwQe5qRiUvUdXXXVVWp8ZPny45hi7s9LGmx4AAJAINHoAAEAi0OgBAACJkPcxPXaFZjs244gjjgjKffzxx7HU6fLLL0/rM6eeeqrm2267Let1SqK///3vms8555zgnP37ke50c+uuu+4Kju01Hn744TLVE2VXuXLl4PiKK67Q3Lt3b812dWyR8L4tXbpU8z777BOUs2N6li9fXr7KIidatGih2a5oXxo79mfatGlZrxNC9vnL59IP+cSbHgAAkAg0egAAQCLkpHvrq6++Sqtc9erVNd94443BuU6dOmlesmRJdiqWwq677qp5//33z+l3IWTv8+OPP57WZ2zXVLqcS71wbibXQ9l07do1OLartl966aWaBw4cmNb1ot3hCxYs0Dxv3rxMqogsq1evXnA8YMCAtD73xhtvaC5tVXyUX3QYwVlnnRVTTfKHn/YAACARaPQAAIBEoNEDAAASISdjeoYOHap5u+22C87ZqaXWkUceGRyfdNJJmocMGZK9ypXALnVut8bYeeedU35m5MiROa1TsbJjeERE7rnnHs12+vmvv/4alLP3yO7QvOWWW6b8LnuN6DRmO56sEJZOL0T23tx8883BuVGjRml+4IEH0rqe3YH97LPPLmftkGsvvvhicLzHHnuUWG7ZsmXBsV2mYOXKldmvWMLZ8XXRMXR2aYlPPvlEc3SJiELGmx4AAJAINHoAAEAi5KR7a82aNZrvvffe4FzHjh01169fP+U1LrroIs3PPfdccO7HH38sbxUDdpff0rq0kBm70nJ0WnqqrqUJEyYEx4cffrjmLl26aC5tNeVrrrlG87PPPhucs9dA9thdmt977z3Ndkq5SLjS7urVq9O69lNPPaU5+pz279+/TPVE7jVq1Cg49t6XWO7+++8Pjl9//fWc1anQ2d0DGjduHJxr0KCB5v322y84Z3cQ2GKLLVJev3v37ppffvllzbNmzSp7ZSso3vQAAIBEoNEDAAASIecbjv7000/BsX3lXVr31l577aV5xx13DM6l271lR6Kfd955KcudcsopaV0P6Yl2HdkZWlF2hpXt0urWrVta3zV58uTg2HaflTYryM4esquSsiJ3+Zx88smad9ttN82HHnpoUG7x4sVpXc9ueti8eXPNP//8c1CuX79+ZaoncsNuWBldBd12b9lVl6Mz+5Ca/V34yCOPBOfs8xZlfw/bIQHR58buprDDDjtkXM+KjDc9AAAgEWj0AACARKDRAwAAEiHnY3qiPvjgA83/+Mc/0vpMixYtguNJkyZpPvDAA0vMIuH0vuuuu65M9SzJjBkzNOd65/dCdv311wfHm222Wcqyt912m+bbb789reu/++67ml955ZXgnF25uTR2TMhvv/2W1mfw1+wzPXPmTM3vv/9+Wp/fZpttguO7775b8wYb/PnfaNGVZNO978i+QYMGabbLU0SnqP/3v//VbJcuia6+jtSmT5+uOTplfdddd035Obvq9TfffJPVOpX2870i4k0PAABIBBo9AAAgEfLevWU3D23durXmDh06pPzMfffdV+pxKvZ1eDY2ldx9990129e40amDSdSkSRPNdkNQkfA+VKpUqdzf9cUXX5T7GpadWmvrirKzGwf37t1b8++//57yM3bz19GjRwfnttpqK82DBw/WfOedd5arnshcdFkH+7Mw2j1pPfTQQ5oXLlyY/YolTLRbfurUqVm9vt2k+fvvvw/O2fvcrl07zXaz8YqKn/AAACARaPQAAIBEyHv3lmU3CWzfvn3Wr2+7tFJtdpcpuzpsUru39txzT822WyK6oV02uhazzc7ssyt3V8S6VmSHHXZYynNjxoxJec52gz344IOa69SpE5SzXZl2A1k7GwX5deaZZwbH2267bYnl7EwjkdL/PqDisTsf2JWaRcLurfHjx+erSlnBmx4AAJAINHoAAEAi0OgBAACJEOuYnlyz4wHsmJ5///vfQTm7A62dZovS3XvvvZqjYzEqOrsbODurZ27BggXBsV1d91//+pfm6DIGtWrV0myn3kZ35rar/drnFPl16aWXaj7rrLOCc6nGS7Zp0yY4/u6777JfMcRu/vz5cVehTHjTAwAAEoFGDwAASISC7N5avHixZrt5mp0CLyIyfPjwtK7XtGlTzXRvZd+VV14ZdxWkYcOGwXHfvn1LLPf1118Hx2yGWLopU6YEx+eff75m2w0yefLkoJx9Nu0K6x9//HFQzk5nR37tuOOOms8++2zN0VXL16xZo/nhhx/WTHdW8bJdmtEu7oqONz0AACARaPQAAIBEiLV7a/bs2ZqfeOKJ4NzOO++sObqy5/333685+no9X4444gjN0RWIlyxZku/qVGh2Zc98sl1a0dVga9asqdm+nrWzukREfvjhhxzVrjjZ59jm6Kyse+65R3Pt2rU1n3TSSUE5uhfzp379+sHxCy+8oLlBgwYpP3f33Xdrvuqqq7JfMZTbrrvuqjn6+8pauXKlZvtz295jkXDDXzsT02YRkSpVqmi++eabNY8aNSooZ/+u5RpvegAAQCLQ6AEAAIlAowcAACRCrGN67E7J0Z17K7rtt99es92lO0nsOI3oNFbrscce0xwdu1Vedrf06PWPP/74lJ/78ssvNR977LGaZ86cmcXa4Q+tWrUKji+++GLNt956q+aPPvoob3VCKDpup7RxPFY+x2PgT9HfO7vssotmu8SAiMh5552n2Y6ziVq1apXmn3/+WfOWW26Z8jMjR47UvHDhwpR1rFGjhubvv/8+KMeYHgAAgCyj0QPg/9u7nxCryjCO478HIUSQFkkMZDlBEangQP6DsCBBrKQgApPcSOSm0JSZKBBEESFm0yaYRUWLtAjGRaZUi5xJNCJFF85o4URDDoSEjQunzHGeFjMd33OYO965984995z3+9n4nDvnXh99uMPDe94/ABCFQu7I3Gijo6NJHA67tbW1VfX+gwcPpq7DocTx8fE6s2tdBw4cSOLwcMlwGDPrxIkTqetwZ89wWXn2MVO4q3P4WC07xBseHjo2NpbE2RodOXKk4t+Fxjt8+HDqOtytt9Lu2GiumR5hhPr6+lLXg4ODc5ANphNu7xBu+yBJmzdvnvXnZQ8LDX8fDwwMJHF2R/V6NXqaw2ww0gMAAKJA0wMAAKJg4XDWXW82q/7mglqzZk0Sh49ApPTQ4kzCxzs3btyoOyd3t7vfNTuNrmW4Oqe3tzf1s/D/I7vKa2JiYtZ/V/gZ2ff39/cncaXdgXN21t1XNvpDW/G7uXLlnX/m6dOnUz/bsWNHEvf09DQtp0YrwnezWtnDdsMDR0PZxyjZ3XULrOHfzUbXcteuXUmcPWB7JseOHZv2fadOnUrdd+vWrTqyaykVa8lIDwAAiAJNDwAAiAJNDwAAiAJzemawatWq1PXRo0eTeNGiRRXft379+iQO55jUqmjzBsLdqiVp+/btSbxnz57Uz2qZ0xOein7y5MnUz8LtAq5fvz7rz26CUs/pmT9/fhKH83iyJzsvX748iRsx7y0vRftuZi1btiyJs0vRwyXs+/btS+LwtGwpvcy54Fp+Tk97e3sSh1t8SOltIMJdkqX0rviRYE4PAACIG00PAACIAjsyzyB7+OHu3buTuLOzM4nD5YCSdObMmblNrMWNjIykrvfu3ZvE4UGfktTV1ZXE4QGHly5dSt3X3d2dxENDQ0mcXXKJfG3bti2JV6xYkcQdHR2p+4r8SKtM1q5dm8QLFy6seN/NmzeTuESPswon3FYg/H6heoz0AACAKND0AACAKND0AACAKLBkvQCKviwWKaVesh6euB3OA8lu/zA+Pt60nOZSmb6bw8PDqesFCxYk8YYNG5L43LlzTcupyVp+yTqqxpJ1AAAQN5oeAAAQBZasA2iYcBff/fv3J3FZHmeV2ZIlS/JOAZhzjPQAAIAo0PQAAIAo8HgLQMO0tbXlnQIAVMRIDwAAiAJNDwAAiAJNDwAAiAJNDwAAiAJNDwAAiAJNDwAAiMJsl6z/KWn4rnehkeZqm1RqmQ/qWR7Uslzmop7UMh8VazmrU9YBAACKisdbAAAgCjQ9AAAgCjQ9AAAgCqVqesys3cz+NrPzwWvzzOycmX0VvHbIzK6Z2cv5ZIpqZOtpZhvN7Gczu2xm7wT3Uc8WN00td5rZBTMbMLO3gvu6zewPM+vML1vczTT1/NjMrprZhcx91LPFxVbLUjU9U4bcvSO43inpYniDu78q6cumZoVaDbl7h5nNk/SBpGclLZW0xcyWStSzQP6v5XJJr0taLWmFpE1m9ogkuXuXpJ4cc0T1wt+1n0jamL2BehZGNLUsY9OTMLPFkp6X9GHeuaBuqyVddvdf3f1fSZ9LejHnnFCbxyX96O5j7j4uqV/SSznnhDq4+/eSruWdB+pX9lqWuumR9L6ktyVN5J0I6vaApN+D6ytTr6F4LkhaZ2b3mdkCSc9JejDnnABEoLRNj5ltknTV3c/mnQuAO9z9oqT3JH0r6WtJ5yXdzjUpAFEobdMj6UlJL5jZb5p8FPKMmX2ab0qow4jSowGLp15DAbn7R+7+hLs/JekvSb/knROA8itt0+Pu77r7Yndvl/SKpO/cfWvOaaF2P0l61MweNrN7NFlTJi8XlJndP/XnQ5qcz3M434wAxKC0TQ/KZWrC65uSvtHkarwv3H0g36xQh14zG5R0VNIb7j6ad0KonZl9JukHSY+Z2RUzey3vnFCbstdytgeOFpK790nqyzkN1Mndj0s6nnceqJ+7r8s7BzSOu2/JOwc0RtlrWbaRntuS7g03J5yOmR2S9LSkf5qSFWpFPcuj2lp2S9oq6UZTskKtqGd5RFVLTlkHAABRKNtIDwAAwLRoegAAQBRoegAAQBRoegAAQBRoegAAQBT+A3pQmK+O6YGEAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x720 with 25 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 784) (50000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bP0E_Pzs04y_"
      },
      "source": [
        "## Dataset augmentation\n",
        "\n",
        "It is important to train the model on different variations of the dataset. It is also important to have large datset for training.\n",
        "\n",
        "Using dataset augmentation helps to achieve both of the above goals. From one image, one can generate hundred thousands of images using image transformation.\n",
        "\n",
        "The image transformation could be [spatial transform]() or point transform where we move the points of the image to new locations e.g. shifting, flipping, and/or rotating the imag. \n",
        "\n",
        "Another type of transformation is intensity transform or pixel transform where we change the color values of the pixels in the image e.g. invert the color, add more brightness or darkness. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb2KdoTR07L2"
      },
      "source": [
        "def imagePixelTransforms(img):    \n",
        "    images = []\n",
        "    # let's make 3 simple transformations\n",
        "    img1   = 1.0- img # invert color\n",
        "    img2   = img +0.3 # more brightness\n",
        "    img3   = img -0.3 # more darkness\n",
        "    images = np.array([img1,img2,img3])\n",
        "    images = [ img.reshape(img.shape) for img in images]\n",
        "\n",
        "    # plt.figure() ;    plt.imshow(img)\n",
        "    # plt.figure() ;    plt.imshow(img1)\n",
        "    # plt.figure() ;    plt.imshow(img2)\n",
        "    # plt.figure() ;    plt.imshow(img3)    \n",
        "    return images\n",
        "\n",
        "def imagePointTransforms(img):\n",
        "    images = []\n",
        "    # let's make 3 simple transformations\n",
        "    # Perform the rotation\n",
        "    center  = (img.shape[0] / 2, img.shape[1] / 2)\n",
        "    sz      = (img.shape[1], img.shape[0])\n",
        "    tMatrix = cv2.getRotationMatrix2D(center, 45, 1)\n",
        "    img1 = cv2.warpAffine(img, tMatrix, sz)\n",
        "    img1 = img1[...,np.newaxis] if img1.shape !=img.shape else img1\n",
        "    tMatrix = cv2.getRotationMatrix2D(center, 90, 1)\n",
        "    img2 = cv2.warpAffine(img, tMatrix, sz)\n",
        "    img2 = img2[...,np.newaxis] if img2.shape !=img.shape else img2\n",
        "    tMatrix = cv2.getRotationMatrix2D(center, 270, 1)\n",
        "    img3 = cv2.warpAffine(img, tMatrix, sz)\n",
        "    img3 = img3[...,np.newaxis] if img3.shape !=img.shape else img3\n",
        "\n",
        "    images = np.array([img1,img2,img3])\n",
        "    # plt.figure() ;    plt.imshow(img)\n",
        "    # plt.figure() ;    plt.imshow(img1)\n",
        "    # plt.figure() ;    plt.imshow(img2)\n",
        "    # plt.figure() ;    plt.imshow(img3)    \n",
        "    #plt.figure() ;    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    # plt.figure() ;    plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n",
        "    return images\n",
        "\n",
        "\n",
        "# define a function for sitk transform\n",
        "def resample(img_array, transform):\n",
        "    # Output image Origin, Spacing, Size, Direction are taken from the reference\n",
        "    # image in this call to Resample\n",
        "    image = sitk.GetImageFromArray(img_array)\n",
        "    reference_image = image\n",
        "    interpolator = sitk.sitkCosineWindowedSinc\n",
        "    default_value = 100.0\n",
        "    resampled_img = sitk.Resample(image, reference_image, transform,\n",
        "                         interpolator, default_value)\n",
        "    resampled_array = sitk.GetArrayFromImage(resampled_img)\n",
        "    return resampled_array\n",
        "\n",
        "def affine_rotate(transform, degrees):\n",
        "    parameters = np.array(transform.GetParameters())\n",
        "    new_transform = sitk.AffineTransform(transform)\n",
        "    dimension =3 \n",
        "    matrix = np.array(transform.GetMatrix()).reshape((dimension,dimension))\n",
        "    radians = -np.pi * degrees / 180.\n",
        "    rotation = np.array([[1  ,0,0], \n",
        "                         [0, np.cos(radians), -np.sin(radians)],\n",
        "                         [0, np.sin(radians), np.cos(radians)]]\n",
        "                        )\n",
        "    new_matrix = np.dot(rotation, matrix)\n",
        "    new_transform.SetMatrix(new_matrix.ravel())\n",
        "    return new_transform\n",
        "\n",
        "\n",
        "def imagePoint3DTransforms(img):\n",
        "    #print(\"imagePoint3DTransforms\")\n",
        "    images = []\n",
        "    # let's make 3 simple transformations\n",
        "    # Perform the rotation\n",
        "    # In SimpleITK resampling convention, the transformation maps points \n",
        "    # from the fixed image to the moving image,\n",
        "    # so inverse of the transform is applied\n",
        "\n",
        "    center = (img.shape[0] /2, img.shape[1] /2,img.shape[1] /2)\n",
        "    rotation_around_center = sitk.AffineTransform(3)\n",
        "    rotation_around_center.SetCenter(center)\n",
        "    \n",
        "    rotation_around_center = affine_rotate(rotation_around_center, -45)\n",
        "    img1 = resample(img, rotation_around_center)\n",
        "\n",
        "    rotation_around_center = affine_rotate(rotation_around_center, -90)\n",
        "    img2 = resample(img, rotation_around_center)\n",
        "\n",
        "    rotation_around_center = affine_rotate(rotation_around_center, -90)\n",
        "    img3 = resample(img, rotation_around_center)\n",
        "\n",
        "    images = np.array([img1,img2,img3])\n",
        "    # plt.figure() ;    plt.imshow(img)\n",
        "    # plt.figure() ;    plt.imshow(img1)\n",
        "    # plt.figure() ;    plt.imshow(img2)\n",
        "    # plt.figure() ;    plt.imshow(img3)    \n",
        "    #plt.figure() ;    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    # plt.figure() ;    plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n",
        "    return images\n",
        "\n",
        "def doAugmentation(images,labels,batch_size):\n",
        "    # input is an image or a batch e.g. list of images \n",
        "    # get numpy arrays from the tensor    \n",
        "    images = images.numpy()\n",
        "    labels = labels.numpy()\n",
        "    # if 1d convert back to 2d\n",
        "    #print(images.shape)\n",
        "    rgb = 0 ; is3d = 0\n",
        "    if len(images.shape) == 2:\n",
        "       try: \n",
        "          img2d_shape = int(math.sqrt(images.shape[1])) # gray or binary image\n",
        "          images =images.reshape(-1,img2d_shape,img2d_shape)\n",
        "       except:\n",
        "          try: \n",
        "            img2d_shape = int(math.sqrt(images.shape[1]/3)) # rgb image\n",
        "            images =images.reshape(-1,img2d_shape,img2d_shape,3)\n",
        "            rgb = 1  \n",
        "          except:\n",
        "            pass  \n",
        "            # img3d_shape = int(math.sqrt(images.shape[1]/3)) # rgb image\n",
        "            # images =images.reshape(-1,img2d_shape,img2d_shape,3)\n",
        "            # is3d = 1  \n",
        "\n",
        "\n",
        "\n",
        "    x_outputs = [] ; y_outputs = []\n",
        "    i = 0\n",
        "    for img in images:\n",
        "        #print(\"-------------------------\", i ,\"--------------------\")\n",
        "        if NNID==4:\n",
        "           img = img.squeeze() \n",
        "        # from each images we generate 6 images\n",
        "        # 64 batch will generate 448\n",
        "        x_outputs.extend([img])\n",
        "        imgs1 = imagePoint3DTransforms(img)\n",
        "        imgs2 = imagePixelTransforms(img)\n",
        "        #if not rgb:\n",
        "           #imgs1 = np.array( x[...,np.newaxis] for x in imgs1 if len(x.shape)<3) \n",
        "           #imgs2 = np.array( x[...,np.newaxis] for x in imgs2 if len(x.shape)<3)\n",
        "        x_outputs.extend(imgs1) # 3 images\n",
        "        x_outputs.extend(imgs2) # 3 images\n",
        "        # print(img.shape)\n",
        "        # print(imgs1[0].shape)\n",
        "        # print(imgs2[0].shape)\n",
        "        # assign the same label to all transformed images\n",
        "        for j in range ( len(imgs1) +len(imgs2)+1):\n",
        "            y_outputs.extend([labels[i]])\n",
        "\n",
        "        i = i +1\n",
        "    x_outputs = np.array(x_outputs)\n",
        "    if NNID==4:\n",
        "       x_outputs = np.array([x[...,np.newaxis] for x in x_outputs])\n",
        "    y_outputs = np.array(y_outputs)\n",
        "\n",
        "    if (not rgb) and (NNID==1):\n",
        "       x_outputs = np.reshape(x_outputs, (-1,img2d_shape*img2d_shape,1))\n",
        "    elif (rgb) and (NNID==1):\n",
        "       x_outputs = np.reshape(x_outputs, (-1,img2d_shape*img2d_shape*3))   \n",
        "\n",
        "    new_train_dataset = tf.data.Dataset.from_tensor_slices((x_outputs, y_outputs))\n",
        "    new_train_dataset = new_train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "    return new_train_dataset"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZY4NXWJ4Xoq"
      },
      "source": [
        "## Creating NN model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmSF08Oq4ae6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d902d77a-4d31-43ee-bbc7-1d97d968b3b3"
      },
      "source": [
        "# Tensorflow  ------------------\n",
        "#https://www.tensorflow.org/guide/keras/custom_layers_and_models\n",
        "class IALinear(keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(IALinear, self).__init__()\n",
        "\n",
        "    # initialise weights with unknown shape    \n",
        "    def build(self, input_shape):\n",
        "        # initialize the weights randomly\n",
        "        self.w = tf.Variable(\n",
        "            initial_value=tf.random_normal_initializer(\n",
        "                           shape=(input_shape, input_shape), dtype=\"float32\"),\n",
        "                           # non trainable are not use in backpropagation\n",
        "                           trainable=True,   ) \n",
        "        # initialize the bias with zeros\n",
        "        self.b = tf.Variable(\n",
        "            initial_value=tf.zeros_initializer(\n",
        "                   shape=(input_shape,), dtype=\"float32\"), trainable=True)\n",
        "\n",
        "    # forward call:   output =  X*W + b \n",
        "    def call(self, inputs):\n",
        "        return tf.matmul(inputs, self.w) + self.b\n",
        "    # backward ?\n",
        "\n",
        "\n",
        "# NN TensorFlow\n",
        "def get_NNModel(number_of_pixels,number_of_classes):\n",
        "    inputs = keras.Input(shape=(number_of_pixels,), name=\"digits\")\n",
        "    x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
        "    x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
        "    #outputs = layers.Dense(number_of_classes, name=\"predictions\")(x)\n",
        "    outputs = layers.Dense(number_of_classes, name=\"predictions\")(x) # try with one class\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# NN TensorFlow Detailed\n",
        "def getNNModel(number_of_pixels,number_of_classes):\n",
        "    class NN_Class(keras.layers.Layer):\n",
        "        def __init__(self):\n",
        "            super(NN_Class, self).__init__()\n",
        "            self.number_of_pixels  = number_of_pixels\n",
        "            self.number_of_classes = number_of_classes\n",
        "            #self.number_of_classes = number_of_classes\n",
        "        #def build(self, number_of_pixels ):\n",
        "            self.inputs  = keras.Input(shape=(self.number_of_pixels,), name=\"digits\")\n",
        "            self.dense_1 = layers.Dense(64, activation=\"relu\", name=\"dense_1\")\n",
        "            self.dense_2 = layers.Dense(64, activation=\"relu\", name=\"dense_2\")\n",
        "            self.outputs = layers.Dense(self.number_of_classes, name=\"predictions\")\n",
        "\n",
        "        def call(self, inputs):                \n",
        "            x       = self.inputs(inputs)\n",
        "            x       = self.dense_1(x)\n",
        "            outputs = self.dense_2(x)\n",
        "            return outputs\n",
        "    model =  NN_Class()\n",
        "    return model\n",
        "\n",
        "    \n",
        "print(\"NN model is defined ...\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NN model is defined ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpxH1ntsqfuZ"
      },
      "source": [
        "# TODO\n",
        "# NN pytorch\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtEO2ORyBFeu"
      },
      "source": [
        "## Define optimiser and loss function for NN and CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2CBVAaABKU4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b212a66a-dbef-4108-f55b-b959d22e2302"
      },
      "source": [
        "# Instantiate an optimizer to train the model.\n",
        "\n",
        "optimiserID = 1 # SGD by default for ADAM use 2 \n",
        "optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n",
        "if optimiserID ==2:\n",
        "   optimizer = keras.optimizers.Adam()#learning_rate=0.0001\n",
        "\n",
        "# Instantiate a loss function.\n",
        "lossFunctionID = 1 # SparseCategoricalCrossentropy by default for MSE use 2 \n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# Prepare the metrics.\n",
        "train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
        "val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
        "tst_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "if lossFunctionID==2:\n",
        "   loss_fn = keras.losses.MeanSquaredError()\n",
        "   # Prepare the metrics.\n",
        "   train_acc_metric = keras.metrics.MeanSquaredError()\n",
        "   val_acc_metric   = keras.metrics.MeanSquaredError()\n",
        "   tst_acc_metric   = keras.metrics.MeanSquaredError()\n",
        "\n",
        "elif  lossFunctionID==3:\n",
        "   loss_fn = keras.losses.CategoricalCrossentropy()\n",
        "   # Prepare the metrics.\n",
        "   train_acc_metric = keras.metrics.CategoricalCrossentropy()\n",
        "   val_acc_metric   = keras.metrics.CategoricalCrossentropy()\n",
        "   tst_acc_metric   = keras.metrics.CategoricalCrossentropy()\n",
        "\n",
        "print(\"optimiser, loss, and metrics are defined .... \")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "optimiser, loss, and metrics are defined .... \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmAbPxuDqrVV"
      },
      "source": [
        "# TODO\n",
        "# Pytorch\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dxyj5W7P4d2M"
      },
      "source": [
        "\n",
        "## Define training functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8dFra_t4i8d"
      },
      "source": [
        "\n",
        "# define training parameters and file paths \n",
        "\n",
        "# model log files path\n",
        "modelPath   = \"./modelClassification.h5\"\n",
        "logFilePath = \"./training_log.csv\"\n",
        "figPath     = \"./training_log.png\"\n",
        "\n",
        "logFile = open(logFilePath,'w')\n",
        "logFile.write(\"epoch \\t trnLoss \\t valLoss \\t trnAcc \\t valAcc \\t time \\n\" )\n",
        "logFile.close()\n",
        "# Using optimised tensorflow functions provides more speed\n",
        "\n",
        "@tf.function\n",
        "def train_step(model,x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        #print(\"get result\")\n",
        "        logits = model(x, training=True)\n",
        "        #print(\"get training loss value \")\n",
        "        #y = keras.utils.to_categorical(y)\n",
        "        #logits = (number_of_classes-1.0) * tf.sigmoid(logits)\n",
        "        #print(logits,y)\n",
        "        loss_value = loss_fn(y, logits)\n",
        "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    train_acc_metric.update_state(y, logits)\n",
        "    return loss_value\n",
        "\n",
        "@tf.function\n",
        "def val_step(model,x, y):\n",
        "    val_logits = model(x, training=False)\n",
        "    #y = keras.utils.to_categorical(y)\n",
        "    #val_logits = (number_of_classes-1.0) * tf.sigmoid(val_logits)\n",
        "    loss_value = loss_fn(y, val_logits)\n",
        "    val_acc_metric.update_state(y, val_logits)\n",
        "    return loss_value\n",
        "\n",
        "# plotting function to monitor the curves\n",
        "def iaPlotLoss(logPath,figPath=None):\n",
        "    f = open(logPath,'r')\n",
        "    lst = f.readlines()\n",
        "    # first line is labels:\n",
        "    labels = lst[0].split()[1:-2]\n",
        "    x  = [ int(  ln.split()[0]) for ln in lst[1:]] # epoch\n",
        "    y1 = [ float(ln.split()[1]) for ln in lst[1:]] # lossTrain\n",
        "    y2 = [ float(ln.split()[2]) for ln in lst[1:]] # lossValidation\n",
        "    y3 = [ float(ln.split()[3]) for ln in lst[1:]] # accTrain\n",
        "    y4 = [ float(ln.split()[4]) for ln in lst[1:]] # accValidation\n",
        "    #plotting    \n",
        "    plt.clf()\n",
        "    fig, ax = plt.subplots()    \n",
        "    l1, = ax.plot(x, y1) ;     l2, = ax.plot(x, y2) ;\n",
        "    l3, = ax.plot(x, y3) ;     l4, = ax.plot(x, y4) ;\n",
        "    ax.legend((l1, l2,l3,l4), labels, loc='upper right', shadow=True)\n",
        "    plt.xlabel('epoch')\n",
        "    if figPath:\n",
        "        plt.savefig(figPath, bbox_inches='tight')\n",
        "    else:\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8q6L-lY4GN2"
      },
      "source": [
        "## Training NN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbudB2v04GbI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "02e94b0c-5262-4f57-e00d-28645075c6ac"
      },
      "source": [
        "epochs = 50 # number of iterations \n",
        "\n",
        "\n",
        "if NNID==1:\n",
        "    model = getNNModel(number_of_pixels,number_of_classes)\n",
        "    print(\"===================================================\")\n",
        "    print(\"               Training Loop           \")\n",
        "    print(\"===================================================\")\n",
        "\n",
        "    total_time_start = time.time()\n",
        "    # we loop number of iterations\n",
        "    # for each iteration, we loop through all the training samples\n",
        "    for epoch in range(epochs):\n",
        "        #print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "        start_time = time.time()\n",
        "\n",
        "        #TODO:\n",
        "        # replace this part\n",
        "        \n",
        "        # Iterate over the batches of the dataset.\n",
        "        for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "            #print(train_dataset.shape)\n",
        "            #print(x_batch_train.shape,y_batch_train.shape)\n",
        "            if doAug: \n",
        "                #do augmentation\n",
        "                new_train_batch = doAugmentation(x_batch_train , y_batch_train , batch_size)\n",
        "                for stp, (new_x_batch_train, new_y_batch_train) in enumerate(new_train_batch):\n",
        "                    #print(new_train_batch.shape)\n",
        "                    #print(new_x_batch_train.shape,new_y_batch_train.shape)\n",
        "                    #model.summary()\n",
        "                    loss_value = train_step(model,new_x_batch_train, new_y_batch_train)\n",
        "                    train_acc = train_acc_metric.result()\n",
        "                    train_acc_metric.reset_states()\n",
        "            else:                    \n",
        "                loss_value = train_step(model,x_batch_train, y_batch_train)                    \n",
        "                train_acc = train_acc_metric.result()\n",
        "                train_acc_metric.reset_states()\n",
        "\n",
        "        # Run a validation loop at the end of each epoch.\n",
        "        for x_batch_val, y_batch_val in val_dataset:\n",
        "            val_loss_value = val_step(model,x_batch_val, y_batch_val)\n",
        "\n",
        "        val_acc = val_acc_metric.result()\n",
        "        val_acc_metric.reset_states()\n",
        "        \n",
        "        # compute time required for each epoch\n",
        "        end_time = time.time() - start_time\n",
        "\n",
        "        print(\"epoch:%d \\t trnLoss: %.4f \\t valLoss: %.4f \\t trnAcc: %.4f \\t valAcc: %.4f \\t time:  %.2f\" % (epoch, float(loss_value),float(val_loss_value), float(train_acc), float(val_acc), end_time))\n",
        "        logFile = open(logFilePath,'a')\n",
        "        logFile.write(\"%d \\t %.4f \\t  %.4f \\t %.4f \\t  %.4f \\t  %.2f \\n\" % (epoch, float(loss_value),float(val_loss_value), float(train_acc), float(val_acc), end_time))\n",
        "        logFile.close()\n",
        "        # plot the result\n",
        "        if epoch % 10 ==0:\n",
        "           # plot the result        \n",
        "           iaPlotLoss(logFilePath)\n",
        "\n",
        "    # save the final model\n",
        "    model.save(modelPath)     \n",
        "\n",
        "    # plot the result        \n",
        "    iaPlotLoss(logFilePath)\n",
        "    total_time_end = time.time() - total_time_start\n",
        "    print(\"Training this dataset took \", total_time_end,\" seconds!\") \n",
        "    print(\"Training this dataset took \", total_time_end/60.0,\" minutes!\")   "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===================================================\n",
            "               Training Loop           \n",
            "===================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-be6e8c5cb460>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0mtrain_acc_metric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                 \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_acc_metric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mtrain_acc_metric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    759\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 760\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    <ipython-input-8-6f48e8bc4dd6>:18 train_step  *\n        logits = model(x, training=True)\n    <ipython-input-4-ac3fb8cd3598>:51 call  *\n        x       = self.inputs(inputs)\n\n    TypeError: 'KerasTensor' object is not callable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mox2km11qyqY"
      },
      "source": [
        "##TODO pytorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKk2JgFo4lgd"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlx1hVMQGAbR"
      },
      "source": [
        "if NNID==1:\n",
        "    # Load the saved model \n",
        "    model = keras.models.load_model(modelPath, compile=False)\n",
        "\n",
        "    start_time = time.time() \n",
        "    # Run a validation loop at the end of each epoch.\n",
        "    for x_batch_tst, y_batch_tst in tst_dataset:\n",
        "        output = model.predict(x_batch_tst)\n",
        "        #y = keras.utils.to_categorical(y_batch_tst)\n",
        "        tst_acc_metric.update_state(y_batch_tst, output)\n",
        "\n",
        "    tst_acc = tst_acc_metric.result()\n",
        "\n",
        "    # compute time required for each epoch\n",
        "    end_time = time.time() - start_time\n",
        "\n",
        "    print(\"test accuracy : %.4f \\t time:  %.2f\" % (  float(tst_acc), end_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpZmXOUfrDho"
      },
      "source": [
        "# TODO Pytorch\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8X6Da244p-r"
      },
      "source": [
        "# Image classification using CNN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPkWBAJP47f1"
      },
      "source": [
        "## Creating CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2a1zuKu4_ZR"
      },
      "source": [
        "# Simple DNN\n",
        "# just two conolution layers followed by dense layer\n",
        "def getSimpleDNNModel(input_shape,number_of_pixels,number_of_classes):\n",
        "    nF        = 16 # number of filters\n",
        "    inputs = keras.Input(shape=input_shape, name=\"images\") \n",
        "    # Create CNN model\n",
        "    x11  = layers.Conv2D(nF, (3, 3), activation='relu', input_shape=input_shape) (inputs)\n",
        "    x13  = layers.MaxPooling2D((2, 2)) (x11)\n",
        "    x21  = layers.Conv2D(2*nF, (3, 3), activation='relu') (x13)\n",
        "    x23  = layers.MaxPooling2D((2, 2))(x21)\n",
        "    #dense layer for classification\n",
        "    x31 = layers.Flatten()(x23)# convert from 3d to 1d\n",
        "    outputs = layers.Dense(number_of_classes, name=\"predictions\")(x31)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# this is a better model for CIFAR10\n",
        "def getDNNModel(input_shape,number_of_pixels,number_of_classes):\n",
        "    nF        = 64 # number of filters\n",
        "    inputs = keras.Input(shape=input_shape, name=\"images\") \n",
        "    # Create CNN model\n",
        "    x11  = layers.Conv2D(nF, (3, 3), activation='relu', input_shape=input_shape) (inputs)\n",
        "    x12  = layers.BatchNormalization()(x11)\n",
        "    x13  = layers.MaxPooling2D((2, 2)) (x12)\n",
        "    x14  = layers.Dropout(0.25)(x13)\n",
        "    x21  = layers.Conv2D(2*nF, (3, 3), activation='relu') (x14)\n",
        "    x22  = layers.BatchNormalization()(x21)\n",
        "    x23  = layers.MaxPooling2D((2, 2))(x22)\n",
        "    x24  = layers.Dropout(0.25)(x23)\n",
        "    x31  = layers.Conv2D(2*nF, (3, 3), activation='relu')(x24)\n",
        "    #dense layer for classification\n",
        "    x41 = layers.Flatten()(x31)# convert from 3d to 1d\n",
        "    #x7 = layers.Dense(2*nF, activation='relu')(x6)\n",
        "    #x8 = layers.Dense(2*nF, activation='relu')(x7)\n",
        "    x42  = layers.Dropout(0.50)(x41)\n",
        "    outputs = layers.Dense(number_of_classes, name=\"predictions\")(x42)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "print(\"DNN model is defined ...\")    \n",
        "\n",
        "def getSimpleDNN3DModel(input_shape,number_of_pixels,number_of_classes):\n",
        "    nF        = 16 # number of filters\n",
        "    inputs = keras.Input(shape=input_shape, name=\"images\") \n",
        "    # Create CNN model\n",
        "    x11  = layers.Conv3D(nF, (3, 3, 3), activation='relu', input_shape=input_shape) (inputs)\n",
        "    x13  = layers.MaxPooling3D((2, 2, 2)) (x11)\n",
        "    x21  = layers.Conv3D(2*nF, (3, 3, 3), activation='relu') (x13)\n",
        "    x23  = layers.MaxPooling3D((2, 2 ,2))(x21)\n",
        "    #dense layer for classification\n",
        "    x31 = layers.Flatten()(x23)# convert from 3d to 1d\n",
        "    outputs = layers.Dense(number_of_classes, name=\"predictions\")(x31)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oD_BI-0C4_kr"
      },
      "source": [
        "## Training CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKpCUhIT5EWp"
      },
      "source": [
        "# Same code as above \n",
        "\n",
        "epochs = 500 # number of iterations \n",
        "\n",
        "if NNID>=2:\n",
        "    input_shape = [h,w,c] \n",
        "\n",
        "    if NNID==2:\n",
        "       model = getSimpleDNNModel(input_shape, number_of_pixels,number_of_classes)\n",
        "    elif NNID==3: # advanced \n",
        "       model = getDNNModel(input_shape, number_of_pixels,number_of_classes)\n",
        "    elif NNID==4: # 3D \n",
        "       input_shape = [h,w,c,1] \n",
        "       model = getSimpleDNN3DModel(input_shape, number_of_pixels,number_of_classes)\n",
        "\n",
        "    print(\"===================================================\")\n",
        "    print(\"               Training Loop           \")\n",
        "    print(\"===================================================\")\n",
        "    total_time_start = time.time()\n",
        "    # we loop number of iterations\n",
        "    # for each iteration, we loop through all the training samples\n",
        "    for epoch in range(epochs):\n",
        "        #print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Iterate over the batches of the dataset.\n",
        "        for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "            #print(train_dataset.shape)\n",
        "            #print(x_batch_train.shape,y_batch_train.shape)\n",
        "            if doAug: \n",
        "                #do augmentation\n",
        "                new_train_batch = doAugmentation(x_batch_train , y_batch_train , batch_size)                \n",
        "                for stp, (new_x_batch_train, new_y_batch_train) in enumerate(new_train_batch):\n",
        "                    #print(stp)\n",
        "                    #print(new_train_batch.shape)\n",
        "                    #print(new_x_batch_train.shape,new_y_batch_train.shape)\n",
        "                    #model.summary()\n",
        "                    loss_value = train_step(model,new_x_batch_train, new_y_batch_train)\n",
        "                    train_acc = train_acc_metric.result()\n",
        "                    train_acc_metric.reset_states()\n",
        "                    print(\"   epoch:%d \\t stp %d trnLoss: %.4f \" % (epoch, stp, float(loss_value)))\n",
        "            else:                    \n",
        "                loss_value = train_step(model,x_batch_train, y_batch_train)                    \n",
        "                train_acc = train_acc_metric.result()\n",
        "                train_acc_metric.reset_states()\n",
        "\n",
        "        # Run a validation loop at the end of each epoch.\n",
        "        for x_batch_val, y_batch_val in val_dataset:\n",
        "            val_loss_value = val_step(model,x_batch_val, y_batch_val)\n",
        "\n",
        "        val_acc = val_acc_metric.result()\n",
        "        val_acc_metric.reset_states()\n",
        "        \n",
        "        # compute time required for each epoch\n",
        "        end_time = time.time() - start_time\n",
        "\n",
        "        print(\"epoch:%d \\t trnLoss: %.4f \\t valLoss: %.4f \\t trnAcc: %.4f \\t valAcc: %.4f \\t time:  %.2f\" % (epoch, float(loss_value),float(val_loss_value), float(train_acc), float(val_acc), end_time))\n",
        "        logFile = open(logFilePath,'a')\n",
        "        logFile.write(\"%d \\t %.4f \\t  %.4f \\t %.4f \\t  %.4f \\t  %.2f \\n\" % (epoch, float(loss_value),float(val_loss_value), float(train_acc), float(val_acc), end_time))\n",
        "        logFile.close()\n",
        "        if epoch % 5 ==0:\n",
        "           # plot the result        \n",
        "           iaPlotLoss(logFilePath)\n",
        "           model.save(modelPath)      \n",
        "    # save the final model\n",
        "    model.save(modelPath)     \n",
        "\n",
        "    # plot the result        \n",
        "    iaPlotLoss(logFilePath)\n",
        "    total_time_end = time.time() - total_time_start\n",
        "    print(\"Training this dataset took \", total_time_end,\" seconds!\") \n",
        "    print(\"Training this dataset took \", total_time_end/60.0,\" minutes!\") \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deIAKC2E5HcT"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwUVTMeg5Ks5"
      },
      "source": [
        "if NNID==2:\n",
        "    # Load the saved model \n",
        "    model = keras.models.load_model(modelPath, compile=False)\n",
        "\n",
        "    start_time = time.time() \n",
        "    # Run a validation loop at the end of each epoch.\n",
        "    for x_batch_tst, y_batch_tst in tst_dataset:\n",
        "        output = model.predict(x_batch_tst)\n",
        "        #y = keras.utils.to_categorical(y_batch_tst)\n",
        "        tst_acc_metric.update_state(y_batch_tst, output)\n",
        "\n",
        "    tst_acc = tst_acc_metric.result()\n",
        "\n",
        "    # compute time required for each epoch\n",
        "    end_time = time.time() - start_time\n",
        "\n",
        "    print(\"test accuracy : %.4f \\t time:  %.2f\" % (  float(tst_acc), end_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dne9y6mbMW0V"
      },
      "source": [
        "# Understanding traning curves\n",
        "\n",
        "Training large datsets takes hours. It is good to check the [training curves](https://en.wikipedia.org/wiki/Learning_curve) and stop the training if it is a waste of time and resources. To do this one should check the training curves and identify specific problems.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-YaiYcJP028"
      },
      "source": [
        "#TODO: show examples using the above datasets\n",
        "# https://machinelearningmastery.com/diagnose-overfitting-underfitting-lstm-models/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-j-OqIpdOlJf"
      },
      "source": [
        "## Model underfitting, overfitting, and good fitting:\n",
        "\n",
        "\n",
        "Source for this part is taken from [here](https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/).\n",
        "\n",
        "**Underfitting:**\n",
        "\n",
        "* No learning: Training loss is a line or a noisy line\n",
        "* Need more training: Traning loss is decreasing.\n",
        "\n",
        "<div>\n",
        "<img src=\"\" width=\"500\"/>\n",
        "</div>\n",
        "\n",
        "<div>\n",
        "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2019/02/Example-of-Training-Learning-Curve-Showing-An-Underfit-Model-That-Does-Not-Have-Sufficient-Capacity.png\" width=\"500\"/>\n",
        "</div>\n",
        "\n",
        "<!-- ![](https://machinelearningmastery.com/wp-content/uploads/2019/02/Example-of-Training-Learning-Curve-Showing-An-Underfit-Model-That-Does-Not-Have-Sufficient-Capacity.png) -->\n",
        "\n",
        "<div>\n",
        "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2018/12/Example-of-Training-Learning-Curve-Showing-An-Underfit-Model-That-Requires-Further-Training.png\" width=\"500\"/>\n",
        "</div>\n",
        "\n",
        "\n",
        "<!-- ![](https://machinelearningmastery.com/wp-content/uploads/2018/12/Example-of-Training-Learning-Curve-Showing-An-Underfit-Model-That-Requires-Further-Training.png) -->\n",
        "\n",
        "**Overfitting:**\n",
        "\n",
        "* Training loss is decreasing \n",
        "* Validation loss is decreasing then increasing.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2018/12/Example-of-Train-and-Validation-Learning-Curves-Showing-An-Overfit-Model.png\" width=\"500\"/>\n",
        "</div>\n",
        "\n",
        "<!-- ![](https://machinelearningmastery.com/wp-content/uploads/2018/12/Example-of-Train-and-Validation-Learning-Curves-Showing-An-Overfit-Model.png) -->\n",
        "\n",
        "**Good fitting:**\n",
        "\n",
        "* Training loss is decreasing to a point of stability.\n",
        "* Validation loss is decreasing to a point of stability and has a small gap with the training loss.\n",
        "\n",
        "\n",
        "<div>\n",
        "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2018/12/Example-of-Train-and-Validation-Learning-Curves-Showing-A-Good-Fit.png\" width=\"500\"/>\n",
        "</div>\n",
        "\n",
        "<!-- ![](https://machinelearningmastery.com/wp-content/uploads/2018/12/Example-of-Train-and-Validation-Learning-Curves-Showing-A-Good-Fit.png) -->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ojw1-BrOrzb"
      },
      "source": [
        "## Bad Datasets\n",
        "\n",
        "**Bad Training Dataset:**\n",
        "\n",
        "* Training dataset has too few examples as compared to the validation dataset.\n",
        "* Training loss is decreasing and validation loss is decreasing with a large gap.\n",
        "\n",
        "\n",
        "<div>\n",
        "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2018/12/Example-of-Train-and-Validation-Learning-Curves-Showing-a-Training-Dataset-the-May-be-too-Small-Relative-to-the-Validation-Dataset.png\" width=\"500\"/>\n",
        "</div>\n",
        "\n",
        "<!-- ![](https://machinelearningmastery.com/wp-content/uploads/2018/12/Example-of-Train-and-Validation-Learning-Curves-Showing-a-Training-Dataset-the-May-be-too-Small-Relative-to-the-Validation-Dataset.png) -->\n",
        "\n",
        "\n",
        "**Bad validation Dataset:**\n",
        "\n",
        "* Training loss is decreasing and validation loss with noisy movements around the training loss.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2018/12/Example-of-Train-and-Validation-Learning-Curves-Showing-a-Validation-Dataset-the-May-be-too-Small-Relative-to-the-Training-Dataset.png\" width=\"500\"/>\n",
        "</div>\n",
        "\n",
        "\n",
        "* Validation loss is lower than the training loss (Use validation dataset for training)\n",
        "\n",
        "<div>\n",
        "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2018/12/Example-of-Train-and-Validation-Learning-Curves-Showing-a-Validation-Dataset-that-is-Easier-to-Predict-than-the-Training-Dataset.png\" width=\"500\"/>\n",
        "</div>\n",
        "\n",
        "\n",
        "<!-- ![](https://machinelearningmastery.com/wp-content/uploads/2018/12/Example-of-Train-and-Validation-Learning-Curves-Showing-a-Validation-Dataset-the-May-be-too-Small-Relative-to-the-Training-Dataset.png)\n",
        "![](https://machinelearningmastery.com/wp-content/uploads/2018/12/Example-of-Train-and-Validation-Learning-Curves-Showing-a-Validation-Dataset-that-is-Easier-to-Predict-than-the-Training-Dataset.png) -->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeRdRNJF2kwU"
      },
      "source": [
        "# More resources:\n",
        "\n",
        "* 3Blue1Brown Neural Network [video tutorials](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) \n",
        "* Deep Learning Video Lectures by Prof. Andreas Maier [Winter 20/21](https://www.youtube.com/watch?v=SCFToE1vM2U&list=PLpOGQvPCDQzvJEPFUQ3mJz72GJ95jyZTh)\n",
        "* Some of the code in this notebook is taken from [here](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch)\n",
        "* Calculating number of parameters in [CNN](https://towardsdatascience.com/understanding-and-calculating-the-number-of-parameters-in-convolution-neural-networks-cnns-fc88790d530d)\n",
        "* Some of the code in this notebook is taken from [here](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/cnn.ipynb)\n",
        "* https://imerit.net/blog/top-13-machine-learning-image-classification-datasets-all-pbm/\n",
        "* https://nihcc.app.box.com/v/ChestXray-NIHCC\n",
        "* https://www.kaggle.com/xhlulu/recursion-cellular-image-classification-224-jpg\n",
        "* https://www.tensorflow.org/datasets/catalog/patch_camelyon\n"
      ]
    }
  ]
}