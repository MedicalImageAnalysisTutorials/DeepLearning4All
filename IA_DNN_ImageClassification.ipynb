{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IA_DNN_ImageClassification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOZLwm5I0onRu60WdTYnNFO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MedicalImageAnalysisTutorials/DeepLearning4All/blob/main/IA_DNN_ImageClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NooQ5tm85ZDb"
      },
      "source": [
        "         "
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7WAn3WH3Lpr"
      },
      "source": [
        "# Image classification using NN\n",
        "\n",
        "\n",
        "Important note: These tutorials are collected from different sources (all original source links are provided). Correction and feedback are welcomed!  \n",
        "\n",
        "**The classification problem** is a problem of separating a data samples into different groups (classes) based on some similarity factors. It has many applications in real life. One can find more information about classification in [An Introduction to Statistical Learning](https://www.statlearning.com/) free book. \n",
        "\n",
        "An example can be separating data of animals into fish and birds. Another example is separating data of clothes based on their materials. \n",
        "\n",
        "In image classification, the goal is to classify an input image to a specific group e.g. in MINST dataset, the images represent numbers from 0 to 10 and the goal is to classify the input image to the number that it represents. In CIFAR10 dataset, each image represent one of these classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck. \n",
        "\n",
        "There are many methods available for solving different classification problems. They are divided usually into 3 groups: supervised, semi-supervised, and un-supervised. \n",
        "\n",
        "* Supervised: The class of each data sample is known.  \n",
        "* Semi-supervised: Only classes of a few data samples are known.\n",
        "* Un-supervised: No information about the classes is available. \n",
        "\n",
        "First let's try a simple [Neural Network (NN)](https://towardsdatascience.com/coding-neural-network-forward-propagation-and-backpropagtion-ccf8cf369f76) with two hidden layers. It looks similar to this:  \n",
        "\n",
        "![](https://miro.medium.com/max/2400/0*hzIQ5Fs-g8iBpVWq.jpg)\n",
        "\n",
        "The input layer is our image sample (after converted to 1D), each pixel is represented by a neuron. The output layer contains neurons represent the classes (in our case 10 neurons) \n",
        "\n",
        "\n",
        "I will use two popular public datasets [MINST](http://yann.lecun.com/exdb/mnist/) and [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html). Both have 10 classes. \n",
        "\n",
        "\n",
        "Usually number of the classes , i.e. 10 neurons, is used for the outoutput but one can used one neuron which is [not a good idea](https://stackoverflow.com/questions/45861547/neural-network-predict-mnist-digits-only-with-one-neuron-in-the-output-layer).. Digit recognition is a classification problem. By only using a single output neuron we are proposing to treat it as a regression problem. The implicit assumption we are making is that numbers that are close to each other numerically also look similar. This is obviously not the case. For instance, 3 and 5 look more similar than 3 and 4 as the bottom part is the same. Also, regression models assume that the input is ordered (one can use any order, for example 1,2,3.... or 1,3,2,5,4 or any other and the model will have different parameters). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0daZiCDKespI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e587c2be-4d1d-4b44-92cf-55bdc0bc75f6"
      },
      "source": [
        "# Setup \n",
        "doInstall =1\n",
        "if doInstall:\n",
        "  !pip install SimpleITK\n",
        "\n",
        "import os, random, time, math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 \n",
        "\n",
        "try:   \n",
        "  import SimpleITK as sitk \n",
        "except:\n",
        "  print(\"please install simpleitk\") \n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "# to reproduce the same results given same input\n",
        "np.random.seed(1)      "
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SimpleITK in /usr/local/lib/python3.7/dist-packages (2.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoTv78FC4P_J"
      },
      "source": [
        "## Reading and exploring the datasets\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 792
        },
        "id": "Dzj-Tvek4V8s",
        "outputId": "1056f0bf-a735-4f1d-8455-eae8aaa3f542"
      },
      "source": [
        "datasetID = 1  # 1:minst is selected by default, for cifar10 use 2\n",
        "NNID      = 1  # 1:NN is by default, for DNN use 2,or 3, for 3D use 4  \n",
        "number_of_classes = 10  # each datasets have 10 classes\n",
        "showSamples = 1\n",
        "# if you have large GPU memory you can combine the images to batches \n",
        "# for faster training.\n",
        "# It is good to try different values\n",
        "batch_size = 2 # you can try larger batch size e.g. 1024 * 6\n",
        "\n",
        "# no augmentation by default\n",
        "doAug = 0\n",
        "\n",
        "# minst dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "class_names = range(10)\n",
        "if datasetID==2:\n",
        "    # cifar10 dataset\n",
        "    # The CIFAR10 dataset contains 60,000 color images in 10 classes, \n",
        "    # with 6,000 images in each class.\n",
        "    # The dataset is divided into 50,000 training images and 10,000 testing images.\n",
        "    # The classes are mutually exclusive and there is no overlap between them.\n",
        "\n",
        "    (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "    if NNID==4:\n",
        "        # example of 3D dataset\n",
        "        #TODO: fix this \n",
        "        showSamples =0\n",
        "        \n",
        "        x_train = x_train.reshape(-1,32*32*3) # (32 * 32 * 3)        \n",
        "        x_train = np.resize(x_train,(x_train.shape[0],15,15,15))        \n",
        "        x_train = x_train.reshape(-1,15,15,15)\n",
        "        x_test = x_test.reshape(-1,32*32*3) # (32 * 32 * 3)\n",
        "        x_test = np.resize(x_test,(x_test.shape[0],15,15,15))\n",
        "        x_test = x_test.reshape(-1,15,15,15)\n",
        "        x_train  =  x_train[..., np.newaxis] # np.reshape(x_train, (-1, h,w,1))\n",
        "        y_train  =  y_train[..., np.newaxis] # np.reshape(y_train, (-1, h,w,1))\n",
        "        x_test   =  x_test[..., np.newaxis]  # np.reshape(x_test,  (-1, h,w,1))\n",
        "        y_test   =  y_test[..., np.newaxis]  # np.reshape(y_test,  (-1, h,w,1))\n",
        "\n",
        "\n",
        "        print(x_train.shape)\n",
        "        print(x_test.shape)\n",
        "\n",
        "\n",
        "# get size \n",
        "h = x_train.shape[1] # image height\n",
        "w = x_train.shape[2] # image width\n",
        "\n",
        "# check for rgb \n",
        "try:\n",
        "    # number of channels\n",
        "    c =  x_train.shape[3]\n",
        "except:\n",
        "    # number of channels\n",
        "    c =  1\n",
        "    # if there is no number of channels, add 1\n",
        "    x_train  =  x_train[..., np.newaxis] # np.reshape(x_train, (-1, h,w,1))\n",
        "    y_train  =  y_train[..., np.newaxis] # np.reshape(y_train, (-1, h,w,1))\n",
        "    x_test   =  x_test[..., np.newaxis]  # np.reshape(x_test,  (-1, h,w,1))\n",
        "    y_test   =  y_test[..., np.newaxis]  # np.reshape(y_test,  (-1, h,w,1))\n",
        "\n",
        "\n",
        "# Reserve 10,000 samples for validation.\n",
        "x_val = x_train[-10000:]\n",
        "y_val = y_train[-10000:]\n",
        "x_train = x_train[:-10000]\n",
        "y_train = y_train[:-10000]\n",
        "\n",
        "number_of_pixels = h * w * c\n",
        "\n",
        "\n",
        "print(\"dataset shape   : \",x_train.shape)\n",
        "print(\"number of images: \",x_train.shape[0])\n",
        "print(\"image size      : \",x_train[0].shape)\n",
        "print(\"image data type : \",type(x_train[0][0][0][0]))\n",
        "print(\"image max  value: \",np.max(x_train[0]))\n",
        "print(\"image min  value: \",np.min(x_train[0]))\n",
        "if c==1:\n",
        "   print(\"gray or binary image (not color image)\")\n",
        "elif c==3:\n",
        "   print(\"rgb color image (or probably non-color image represented with 3 channels)\")\n",
        "\n",
        "\n",
        "# display sample images \n",
        "if showSamples:\n",
        "    plt.figure(figsize=(10,10))\n",
        "    for i in range(25):\n",
        "        plt.subplot(5,5,i+1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "        #plt.imshow(x_train[i])\n",
        "        plt.imshow(cv2.cvtColor(x_train[i], cv2.COLOR_BGR2RGB))\n",
        "\n",
        "        # The CIFAR labels happen to be arrays, \n",
        "        # which is why you need the extra index\n",
        "        if datasetID==1:\n",
        "            plt.xlabel(y_train[i])\n",
        "        elif datasetID==2:\n",
        "            plt.xlabel(class_names[y_train[i][0]])\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# normalisation (map from [0,255] to [0,1])\n",
        "x_train = np.array([ x/255.0 for x in x_train])\n",
        "x_val   = np.array([ x/255.0 for x in x_val])\n",
        "x_test  = np.array([ x/255.0 for x in x_test])\n",
        "#y_train = y_train.astype(np.float32)\n",
        "\n",
        "# for NN we need 1D \n",
        "if NNID ==1:\n",
        "   x_train = np.reshape(x_train, (-1, number_of_pixels))\n",
        "   x_val   = np.reshape(x_val,  (-1, number_of_pixels))\n",
        "   x_test  = np.reshape(x_test , (-1, number_of_pixels))\n",
        "\n",
        "# Prepare the training dataset.\n",
        "print(x_train.shape,y_train.shape)\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "#train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n",
        "\n",
        "# Prepare the validation dataset.\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "val_dataset = val_dataset.batch(batch_size)\n",
        "\n",
        "# Prepare the test dataset.\n",
        "tst_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "tst_dataset = tst_dataset.batch(batch_size)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset shape   :  (50000, 28, 28, 1)\n",
            "number of images:  50000\n",
            "image size      :  (28, 28, 1)\n",
            "image data type :  <class 'numpy.uint8'>\n",
            "image max  value:  255\n",
            "image min  value:  0\n",
            "gray or binary image (not color image)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/matplotlib/text.py:1165: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  if s != self._text:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 25 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 784) (50000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bP0E_Pzs04y_"
      },
      "source": [
        "## Dataset augmentation\n",
        "\n",
        "It is important to train the model on different variations of the dataset. It is also important to have large datset for training.\n",
        "\n",
        "Using dataset augmentation helps to achieve both of the above goals. From one image, one can generate hundred thousands of images using image transformation.\n",
        "\n",
        "The image transformation could be [spatial transform]() or point transform where we move the points of the image to new locations e.g. shifting, flipping, and/or rotating the imag. \n",
        "\n",
        "Another type of transformation is intensity transform or pixel transform where we change the color values of the pixels in the image e.g. invert the color, add more brightness or darkness. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb2KdoTR07L2"
      },
      "source": [
        "# very simple image augmentation examples\n",
        "\n",
        "# intensity based \n",
        "def imagePixelTransforms(img):    \n",
        "    images = []\n",
        "    # let's make 3 simple transformations\n",
        "    img1   = 1.0- img # invert color\n",
        "    img2   = img +0.3 # more brightness\n",
        "    img3   = img -0.3 # more darkness\n",
        "    images = np.array([img1,img2,img3])\n",
        "    images = [ img.reshape(img.shape) for img in images]\n",
        "\n",
        "    # plt.figure() ;    plt.imshow(img)\n",
        "    # plt.figure() ;    plt.imshow(img1)\n",
        "    # plt.figure() ;    plt.imshow(img2)\n",
        "    # plt.figure() ;    plt.imshow(img3)    \n",
        "    return images\n",
        "\n",
        "# geometric based \n",
        "def imagePointTransforms(img):\n",
        "    images = []\n",
        "    # let's make 3 simple transformations\n",
        "    # Perform the rotation\n",
        "    center  = (img.shape[0] / 2, img.shape[1] / 2)\n",
        "    sz      = (img.shape[1], img.shape[0])\n",
        "    tMatrix = cv2.getRotationMatrix2D(center, 45, 1)\n",
        "    img1 = cv2.warpAffine(img, tMatrix, sz)\n",
        "    img1 = img1[...,np.newaxis] if img1.shape !=img.shape else img1\n",
        "    tMatrix = cv2.getRotationMatrix2D(center, 90, 1)\n",
        "    img2 = cv2.warpAffine(img, tMatrix, sz)\n",
        "    img2 = img2[...,np.newaxis] if img2.shape !=img.shape else img2\n",
        "    tMatrix = cv2.getRotationMatrix2D(center, 270, 1)\n",
        "    img3 = cv2.warpAffine(img, tMatrix, sz)\n",
        "    img3 = img3[...,np.newaxis] if img3.shape !=img.shape else img3\n",
        "\n",
        "    images = np.array([img1,img2,img3])\n",
        "    # plt.figure() ;    plt.imshow(img)\n",
        "    # plt.figure() ;    plt.imshow(img1)\n",
        "    # plt.figure() ;    plt.imshow(img2)\n",
        "    # plt.figure() ;    plt.imshow(img3)    \n",
        "    #plt.figure() ;    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    # plt.figure() ;    plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n",
        "    return images\n",
        "\n",
        "\n",
        "# define a function for sitk transform\n",
        "def resample(img_array, transform):\n",
        "    # Output image Origin, Spacing, Size, Direction are taken from the reference\n",
        "    # image in this call to Resample\n",
        "    image = sitk.GetImageFromArray(img_array)\n",
        "    reference_image = image\n",
        "    interpolator = sitk.sitkCosineWindowedSinc\n",
        "    default_value = 100.0\n",
        "    resampled_img = sitk.Resample(image, reference_image, transform,\n",
        "                         interpolator, default_value)\n",
        "    resampled_array = sitk.GetArrayFromImage(resampled_img)\n",
        "    return resampled_array\n",
        "\n",
        "def affine_rotate(transform, degrees):\n",
        "    parameters = np.array(transform.GetParameters())\n",
        "    new_transform = sitk.AffineTransform(transform)\n",
        "    dimension =3 \n",
        "    matrix = np.array(transform.GetMatrix()).reshape((dimension,dimension))\n",
        "    radians = -np.pi * degrees / 180.\n",
        "    rotation = np.array([[1  ,0,0], \n",
        "                         [0, np.cos(radians), -np.sin(radians)],\n",
        "                         [0, np.sin(radians), np.cos(radians)]]\n",
        "                        )\n",
        "    new_matrix = np.dot(rotation, matrix)\n",
        "    new_transform.SetMatrix(new_matrix.ravel())\n",
        "    return new_transform\n",
        "\n",
        "\n",
        "def imagePoint3DTransforms(img):\n",
        "    #print(\"imagePoint3DTransforms\")\n",
        "    images = []\n",
        "    # let's make 3 simple transformations\n",
        "    # Perform the rotation\n",
        "    # In SimpleITK resampling convention, the transformation maps points \n",
        "    # from the fixed image to the moving image,\n",
        "    # so inverse of the transform is applied\n",
        "\n",
        "    center = (img.shape[0] /2, img.shape[1] /2,img.shape[1] /2)\n",
        "    rotation_around_center = sitk.AffineTransform(3)\n",
        "    rotation_around_center.SetCenter(center)\n",
        "    \n",
        "    rotation_around_center = affine_rotate(rotation_around_center, -45)\n",
        "    img1 = resample(img, rotation_around_center)\n",
        "\n",
        "    rotation_around_center = affine_rotate(rotation_around_center, -90)\n",
        "    img2 = resample(img, rotation_around_center)\n",
        "\n",
        "    rotation_around_center = affine_rotate(rotation_around_center, -90)\n",
        "    img3 = resample(img, rotation_around_center)\n",
        "\n",
        "    images = np.array([img1,img2,img3])\n",
        "    # plt.figure() ;    plt.imshow(img)\n",
        "    # plt.figure() ;    plt.imshow(img1)\n",
        "    # plt.figure() ;    plt.imshow(img2)\n",
        "    # plt.figure() ;    plt.imshow(img3)    \n",
        "    #plt.figure() ;    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    # plt.figure() ;    plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n",
        "    return images\n",
        "\n",
        "def doAugmentation(images,labels,batch_size):\n",
        "    # input is an image or a batch e.g. list of images \n",
        "    # get numpy arrays from the tensor    \n",
        "    images = images.numpy()\n",
        "    labels = labels.numpy()\n",
        "    # if 1d convert back to 2d\n",
        "    #print(images.shape)\n",
        "    rgb = 0 ; is3d = 0\n",
        "    if len(images.shape) == 2:\n",
        "       try: \n",
        "          img2d_shape = int(math.sqrt(images.shape[1])) # gray or binary image\n",
        "          images =images.reshape(-1,img2d_shape,img2d_shape)\n",
        "       except:\n",
        "          try: \n",
        "            img2d_shape = int(math.sqrt(images.shape[1]/3)) # rgb image\n",
        "            images =images.reshape(-1,img2d_shape,img2d_shape,3)\n",
        "            rgb = 1  \n",
        "          except:\n",
        "            pass  \n",
        "            # img3d_shape = int(math.sqrt(images.shape[1]/3)) # rgb image\n",
        "            # images =images.reshape(-1,img2d_shape,img2d_shape,3)\n",
        "            # is3d = 1  \n",
        "\n",
        "\n",
        "\n",
        "    x_outputs = [] ; y_outputs = []\n",
        "    i = 0\n",
        "    for img in images:\n",
        "        #print(\"-------------------------\", i ,\"--------------------\")\n",
        "        if NNID==4:\n",
        "           img = img.squeeze() \n",
        "        # from each images we generate 6 images\n",
        "        # 64 batch will generate 448\n",
        "        x_outputs.extend([img])\n",
        "        imgs1 = imagePoint3DTransforms(img)\n",
        "        imgs2 = imagePixelTransforms(img)\n",
        "        #if not rgb:\n",
        "           #imgs1 = np.array( x[...,np.newaxis] for x in imgs1 if len(x.shape)<3) \n",
        "           #imgs2 = np.array( x[...,np.newaxis] for x in imgs2 if len(x.shape)<3)\n",
        "        x_outputs.extend(imgs1) # 3 images\n",
        "        x_outputs.extend(imgs2) # 3 images\n",
        "        # print(img.shape)\n",
        "        # print(imgs1[0].shape)\n",
        "        # print(imgs2[0].shape)\n",
        "        # assign the same label to all transformed images\n",
        "        for j in range ( len(imgs1) +len(imgs2)+1):\n",
        "            y_outputs.extend([labels[i]])\n",
        "\n",
        "        i = i +1\n",
        "    x_outputs = np.array(x_outputs)\n",
        "    if NNID==4:\n",
        "       x_outputs = np.array([x[...,np.newaxis] for x in x_outputs])\n",
        "    y_outputs = np.array(y_outputs)\n",
        "\n",
        "    if (not rgb) and (NNID==1):\n",
        "       x_outputs = np.reshape(x_outputs, (-1,img2d_shape*img2d_shape,1))\n",
        "    elif (rgb) and (NNID==1):\n",
        "       x_outputs = np.reshape(x_outputs, (-1,img2d_shape*img2d_shape*3))   \n",
        "\n",
        "    new_train_dataset = tf.data.Dataset.from_tensor_slices((x_outputs, y_outputs))\n",
        "    new_train_dataset = new_train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "    return new_train_dataset"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZY4NXWJ4Xoq"
      },
      "source": [
        "## Creating NN model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmSF08Oq4ae6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38cc56fa-a9ab-46d3-db3c-ae2da12a78ee"
      },
      "source": [
        "# Tensorflow  ------------------\n",
        "#https://www.tensorflow.org/guide/keras/custom_layers_and_models\n",
        "class IALinear(keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(IALinear, self).__init__()\n",
        "\n",
        "    # initialise weights with unknown shape    \n",
        "    def build(self, input_shape):\n",
        "        # initialize the weights randomly\n",
        "        self.w = tf.Variable(\n",
        "            initial_value=tf.random_normal_initializer(\n",
        "                           shape=(input_shape, input_shape), dtype=\"float32\"),\n",
        "                           # non trainable are not use in backpropagation\n",
        "                           trainable=True,   ) \n",
        "        # initialize the bias with zeros\n",
        "        self.b = tf.Variable(\n",
        "            initial_value=tf.zeros_initializer(\n",
        "                   shape=(input_shape,), dtype=\"float32\"), trainable=True)\n",
        "\n",
        "    # forward call:   output =  X*W + b \n",
        "    def call(self, inputs):\n",
        "        return tf.matmul(inputs, self.w) + self.b\n",
        "    # backward ?\n",
        "\n",
        "\n",
        "# NN TensorFlow\n",
        "def getNNModel(number_of_pixels,number_of_classes):\n",
        "    inputs = keras.Input(shape=(number_of_pixels,), name=\"digits\")\n",
        "    x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
        "    x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
        "    #outputs = layers.Dense(number_of_classes, name=\"predictions\")(x)\n",
        "    outputs = layers.Dense(number_of_classes, name=\"predictions\")(x) # try with one class\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# NN TensorFlow Detailed\n",
        "def get_NNModel(number_of_pixels,number_of_classes):\n",
        "    class NN_Class(keras.layers.Layer):\n",
        "        def __init__(self):\n",
        "            super(NN_Class, self).__init__()\n",
        "            self.number_of_pixels  = number_of_pixels\n",
        "            self.number_of_classes = number_of_classes\n",
        "            #self.number_of_classes = number_of_classes\n",
        "        #def build(self, number_of_pixels ):\n",
        "            self.inputs  = keras.Input(shape=(self.number_of_pixels,), name=\"digits\")\n",
        "            self.dense_1 = layers.Dense(64, activation=\"relu\", name=\"dense_1\")\n",
        "            self.dense_2 = layers.Dense(64, activation=\"relu\", name=\"dense_2\")\n",
        "            self.outputs = layers.Dense(self.number_of_classes, name=\"predictions\")\n",
        "\n",
        "        def call(self, inputs):                \n",
        "            x       = self.inputs(inputs)\n",
        "            x       = self.dense_1(x)\n",
        "            outputs = self.dense_2(x)\n",
        "            return outputs\n",
        "    model =  NN_Class()\n",
        "    return model\n",
        "\n",
        "    \n",
        "print(\"NN model is defined ...\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NN model is defined ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpxH1ntsqfuZ"
      },
      "source": [
        "# TODO\n",
        "# NN pytorch\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtEO2ORyBFeu"
      },
      "source": [
        "## Define optimiser and loss function for NN and CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2CBVAaABKU4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a261690-648f-4f42-b24d-11c689861fe1"
      },
      "source": [
        "# Instantiate an optimizer to train the model.\n",
        "\n",
        "optimiserID = 1 # SGD by default for ADAM use 2 \n",
        "optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n",
        "if optimiserID ==2:\n",
        "   optimizer = keras.optimizers.Adam()#learning_rate=0.0001\n",
        "\n",
        "# Instantiate a loss function.\n",
        "lossFunctionID = 1 # SparseCategoricalCrossentropy by default for MSE use 2 \n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# Prepare the metrics.\n",
        "train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
        "val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
        "tst_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "if lossFunctionID==2:\n",
        "   loss_fn = keras.losses.MeanSquaredError()\n",
        "   # Prepare the metrics.\n",
        "   train_acc_metric = keras.metrics.MeanSquaredError()\n",
        "   val_acc_metric   = keras.metrics.MeanSquaredError()\n",
        "   tst_acc_metric   = keras.metrics.MeanSquaredError()\n",
        "\n",
        "elif  lossFunctionID==3:\n",
        "   loss_fn = keras.losses.CategoricalCrossentropy()\n",
        "   # Prepare the metrics.\n",
        "   train_acc_metric = keras.metrics.CategoricalCrossentropy()\n",
        "   val_acc_metric   = keras.metrics.CategoricalCrossentropy()\n",
        "   tst_acc_metric   = keras.metrics.CategoricalCrossentropy()\n",
        "\n",
        "print(\"optimiser, loss, and metrics are defined .... \")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "optimiser, loss, and metrics are defined .... \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmAbPxuDqrVV"
      },
      "source": [
        "# TODO\n",
        "# Pytorch\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dxyj5W7P4d2M"
      },
      "source": [
        "\n",
        "## Define training functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8dFra_t4i8d"
      },
      "source": [
        "\n",
        "# define training parameters and file paths \n",
        "\n",
        "# model log files path\n",
        "modelPath   = \"./modelClassification.h5\"\n",
        "logFilePath = \"./training_log.csv\"\n",
        "figPath     = \"./training_log.png\"\n",
        "\n",
        "logFile = open(logFilePath,'w')\n",
        "logFile.write(\"epoch \\t trnLoss \\t valLoss \\t trnAcc \\t valAcc \\t time \\n\" )\n",
        "logFile.close()\n",
        "# Using optimised tensorflow functions provides more speed\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def train_step(model,x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        # print(model.summary())\n",
        "        logits = model(x, training=True)\n",
        "        # print(\"get training loss value \")\n",
        "        #y = keras.utils.to_categorical(y)\n",
        "        #logits = (number_of_classes-1.0) * tf.sigmoid(logits)\n",
        "        # print(logits,y)\n",
        "        loss_value = loss_fn(y, logits)\n",
        "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    train_acc_metric.update_state(y, logits)\n",
        "    return loss_value\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def val_step(model,x, y):\n",
        "    val_logits = model(x, training=False)\n",
        "    #y = keras.utils.to_categorical(y)\n",
        "    #val_logits = (number_of_classes-1.0) * tf.sigmoid(val_logits)\n",
        "    loss_value = loss_fn(y, val_logits)\n",
        "    val_acc_metric.update_state(y, val_logits)\n",
        "    return loss_value\n",
        "\n",
        "# plotting function to monitor the curves\n",
        "def iaPlotLoss(logPath,figPath=None):\n",
        "    f = open(logPath,'r')\n",
        "    lst = f.readlines()\n",
        "    # first line is labels:\n",
        "    labels = lst[0].split()[1:-2]\n",
        "    x  = [ int(  ln.split()[0]) for ln in lst[1:]] # epoch\n",
        "    y1 = [ float(ln.split()[1]) for ln in lst[1:]] # lossTrain\n",
        "    y2 = [ float(ln.split()[2]) for ln in lst[1:]] # lossValidation\n",
        "    y3 = [ float(ln.split()[3]) for ln in lst[1:]] # accTrain\n",
        "    y4 = [ float(ln.split()[4]) for ln in lst[1:]] # accValidation\n",
        "    #plotting    \n",
        "    plt.clf()\n",
        "    fig, ax = plt.subplots()    \n",
        "    l1, = ax.plot(x, y1) ;     l2, = ax.plot(x, y2) ;\n",
        "    l3, = ax.plot(x, y3) ;     l4, = ax.plot(x, y4) ;\n",
        "    ax.legend((l1, l2,l3,l4), labels, loc='upper right', shadow=True)\n",
        "    plt.xlabel('epoch')\n",
        "    if figPath:\n",
        "        plt.savefig(figPath, bbox_inches='tight')\n",
        "    else:\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8q6L-lY4GN2"
      },
      "source": [
        "## Training NN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbudB2v04GbI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a511aacb-9809-4dac-a217-2253b37e2db3"
      },
      "source": [
        "epochs = 50 # number of iterations \n",
        "\n",
        "\n",
        "if NNID==1:\n",
        "    model = getNNModel(number_of_pixels,number_of_classes)\n",
        "    print(\"===================================================\")\n",
        "    print(\"               Training Loop           \")\n",
        "    print(\"===================================================\")\n",
        "\n",
        "    total_time_start = time.time()\n",
        "    # we loop number of iterations\n",
        "    # for each iteration, we loop through all the training samples\n",
        "    for epoch in range(epochs):\n",
        "        #print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "        start_time = time.time()\n",
        "\n",
        "        #TODO:\n",
        "        # replace this part\n",
        "        \n",
        "        # Iterate over the batches of the dataset.\n",
        "        for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "            #print(train_dataset.shape)\n",
        "            #print(x_batch_train.shape,y_batch_train.shape)\n",
        "            if doAug: \n",
        "                #do augmentation\n",
        "                new_train_batch = doAugmentation(x_batch_train , y_batch_train , batch_size)\n",
        "                for stp, (new_x_batch_train, new_y_batch_train) in enumerate(new_train_batch):\n",
        "                    #print(new_train_batch.shape)\n",
        "                    #print(new_x_batch_train.shape,new_y_batch_train.shape)\n",
        "                    #model.summary()\n",
        "                    loss_value = train_step(model,new_x_batch_train, new_y_batch_train)\n",
        "                    train_acc = train_acc_metric.result()\n",
        "                    train_acc_metric.reset_states()\n",
        "            else:                    \n",
        "                loss_value = train_step(model,x_batch_train, y_batch_train)                    \n",
        "                train_acc = train_acc_metric.result()\n",
        "                train_acc_metric.reset_states()\n",
        "\n",
        "        # Run a validation loop at the end of each epoch.\n",
        "        for x_batch_val, y_batch_val in val_dataset:\n",
        "            val_loss_value = val_step(model,x_batch_val, y_batch_val)\n",
        "\n",
        "        val_acc = val_acc_metric.result()\n",
        "        val_acc_metric.reset_states()\n",
        "        \n",
        "        # compute time required for each epoch\n",
        "        end_time = time.time() - start_time\n",
        "\n",
        "        print(\"epoch:%d \\t trnLoss: %.4f \\t valLoss: %.4f \\t trnAcc: %.4f \\t valAcc: %.4f \\t time:  %.2f\" % (epoch, float(loss_value),float(val_loss_value), float(train_acc), float(val_acc), end_time))\n",
        "        logFile = open(logFilePath,'a')\n",
        "        logFile.write(\"%d \\t %.4f \\t  %.4f \\t %.4f \\t  %.4f \\t  %.2f \\n\" % (epoch, float(loss_value),float(val_loss_value), float(train_acc), float(val_acc), end_time))\n",
        "        logFile.close()\n",
        "        # plot the result\n",
        "        if epoch % 10 ==0:\n",
        "           # plot the result        \n",
        "           iaPlotLoss(logFilePath)\n",
        "\n",
        "    # save the final model\n",
        "    model.save(modelPath)     \n",
        "\n",
        "    # plot the result        \n",
        "    iaPlotLoss(logFilePath)\n",
        "    total_time_end = time.time() - total_time_start\n",
        "    print(\"Training this dataset took \", total_time_end,\" seconds!\") \n",
        "    print(\"Training this dataset took \", total_time_end/60.0,\" minutes!\")   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===================================================\n",
            "               Training Loop           \n",
            "===================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mox2km11qyqY"
      },
      "source": [
        "##TODO pytorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKk2JgFo4lgd"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlx1hVMQGAbR"
      },
      "source": [
        "if NNID==1:\n",
        "    # Load the saved model \n",
        "    model = keras.models.load_model(modelPath, compile=False)\n",
        "\n",
        "    start_time = time.time() \n",
        "    # Run a validation loop at the end of each epoch.\n",
        "    for x_batch_tst, y_batch_tst in tst_dataset:\n",
        "        output = model.predict(x_batch_tst)\n",
        "        #y = keras.utils.to_categorical(y_batch_tst)\n",
        "        tst_acc_metric.update_state(y_batch_tst, output)\n",
        "\n",
        "    tst_acc = tst_acc_metric.result()\n",
        "\n",
        "    # compute time required for each epoch\n",
        "    end_time = time.time() - start_time\n",
        "\n",
        "    print(\"test accuracy : %.4f \\t time:  %.2f\" % (  float(tst_acc), end_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpZmXOUfrDho"
      },
      "source": [
        "# TODO Pytorch\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8X6Da244p-r"
      },
      "source": [
        "# Image classification using CNN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPkWBAJP47f1"
      },
      "source": [
        "## Creating CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2a1zuKu4_ZR"
      },
      "source": [
        "# Simple DNN\n",
        "# just two conolution layers followed by dense layer\n",
        "def getSimpleDNNModel(input_shape,number_of_pixels,number_of_classes):\n",
        "    nF        = 16 # number of filters\n",
        "    inputs = keras.Input(shape=input_shape, name=\"images\") \n",
        "    # Create CNN model\n",
        "    x11  = layers.Conv2D(nF, (3, 3), activation='relu', input_shape=input_shape) (inputs)\n",
        "    x13  = layers.MaxPooling2D((2, 2)) (x11)\n",
        "    x21  = layers.Conv2D(2*nF, (3, 3), activation='relu') (x13)\n",
        "    x23  = layers.MaxPooling2D((2, 2))(x21)\n",
        "    #dense layer for classification\n",
        "    x31 = layers.Flatten()(x23)# convert from 3d to 1d\n",
        "    outputs = layers.Dense(number_of_classes, name=\"predictions\")(x31)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# this is a better model for CIFAR10\n",
        "def getDNNModel(input_shape,number_of_pixels,number_of_classes):\n",
        "    nF        = 64 # number of filters\n",
        "    inputs = keras.Input(shape=input_shape, name=\"images\") \n",
        "    # Create CNN model\n",
        "    x11  = layers.Conv2D(nF, (3, 3), activation='relu', input_shape=input_shape) (inputs)\n",
        "    x12  = layers.BatchNormalization()(x11)\n",
        "    x13  = layers.MaxPooling2D((2, 2)) (x12)\n",
        "    x14  = layers.Dropout(0.25)(x13)\n",
        "    x21  = layers.Conv2D(2*nF, (3, 3), activation='relu') (x14)\n",
        "    x22  = layers.BatchNormalization()(x21)\n",
        "    x23  = layers.MaxPooling2D((2, 2))(x22)\n",
        "    x24  = layers.Dropout(0.25)(x23)\n",
        "    x31  = layers.Conv2D(2*nF, (3, 3), activation='relu')(x24)\n",
        "    #dense layer for classification\n",
        "    x41 = layers.Flatten()(x31)# convert from 3d to 1d\n",
        "    #x7 = layers.Dense(2*nF, activation='relu')(x6)\n",
        "    #x8 = layers.Dense(2*nF, activation='relu')(x7)\n",
        "    x42  = layers.Dropout(0.50)(x41)\n",
        "    outputs = layers.Dense(number_of_classes, name=\"predictions\")(x42)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "print(\"DNN model is defined ...\")    \n",
        "\n",
        "def getSimpleDNN3DModel(input_shape,number_of_pixels,number_of_classes):\n",
        "    nF        = 16 # number of filters\n",
        "    inputs = keras.Input(shape=input_shape, name=\"images\") \n",
        "    # Create CNN model\n",
        "    x11  = layers.Conv3D(nF, (3, 3, 3), activation='relu', input_shape=input_shape) (inputs)\n",
        "    x13  = layers.MaxPooling3D((2, 2, 2)) (x11)\n",
        "    x21  = layers.Conv3D(2*nF, (3, 3, 3), activation='relu') (x13)\n",
        "    x23  = layers.MaxPooling3D((2, 2 ,2))(x21)\n",
        "    #dense layer for classification\n",
        "    x31 = layers.Flatten()(x23)# convert from 3d to 1d\n",
        "    outputs = layers.Dense(number_of_classes, name=\"predictions\")(x31)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oD_BI-0C4_kr"
      },
      "source": [
        "## Training CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKpCUhIT5EWp"
      },
      "source": [
        "# Same code as above \n",
        "\n",
        "epochs = 500 # number of iterations \n",
        "\n",
        "if NNID>=2:\n",
        "    input_shape = [h,w,c] \n",
        "\n",
        "    if NNID==2:\n",
        "       model = getSimpleDNNModel(input_shape, number_of_pixels,number_of_classes)\n",
        "    elif NNID==3: # advanced \n",
        "       model = getDNNModel(input_shape, number_of_pixels,number_of_classes)\n",
        "    elif NNID==4: # 3D \n",
        "       input_shape = [h,w,c,1] \n",
        "       model = getSimpleDNN3DModel(input_shape, number_of_pixels,number_of_classes)\n",
        "\n",
        "    print(\"===================================================\")\n",
        "    print(\"               Training Loop           \")\n",
        "    print(\"===================================================\")\n",
        "    total_time_start = time.time()\n",
        "    # we loop number of iterations\n",
        "    # for each iteration, we loop through all the training samples\n",
        "    for epoch in range(epochs):\n",
        "        #print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Iterate over the batches of the dataset.\n",
        "        for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "            #print(train_dataset.shape)\n",
        "            #print(x_batch_train.shape,y_batch_train.shape)\n",
        "            if doAug: \n",
        "                #do augmentation\n",
        "                new_train_batch = doAugmentation(x_batch_train , y_batch_train , batch_size)                \n",
        "                for stp, (new_x_batch_train, new_y_batch_train) in enumerate(new_train_batch):\n",
        "                    #print(stp)\n",
        "                    #print(new_train_batch.shape)\n",
        "                    #print(new_x_batch_train.shape,new_y_batch_train.shape)\n",
        "                    #model.summary()\n",
        "                    loss_value = train_step(model,new_x_batch_train, new_y_batch_train)\n",
        "                    train_acc = train_acc_metric.result()\n",
        "                    train_acc_metric.reset_states()\n",
        "                    print(\"   epoch:%d \\t stp %d trnLoss: %.4f \" % (epoch, stp, float(loss_value)))\n",
        "            else:                    \n",
        "                loss_value = train_step(model,x_batch_train, y_batch_train)                    \n",
        "                train_acc = train_acc_metric.result()\n",
        "                train_acc_metric.reset_states()\n",
        "\n",
        "        # Run a validation loop at the end of each epoch.\n",
        "        for x_batch_val, y_batch_val in val_dataset:\n",
        "            val_loss_value = val_step(model,x_batch_val, y_batch_val)\n",
        "\n",
        "        val_acc = val_acc_metric.result()\n",
        "        val_acc_metric.reset_states()\n",
        "        \n",
        "        # compute time required for each epoch\n",
        "        end_time = time.time() - start_time\n",
        "\n",
        "        print(\"epoch:%d \\t trnLoss: %.4f \\t valLoss: %.4f \\t trnAcc: %.4f \\t valAcc: %.4f \\t time:  %.2f\" % (epoch, float(loss_value),float(val_loss_value), float(train_acc), float(val_acc), end_time))\n",
        "        logFile = open(logFilePath,'a')\n",
        "        logFile.write(\"%d \\t %.4f \\t  %.4f \\t %.4f \\t  %.4f \\t  %.2f \\n\" % (epoch, float(loss_value),float(val_loss_value), float(train_acc), float(val_acc), end_time))\n",
        "        logFile.close()\n",
        "        if epoch % 5 ==0:\n",
        "           # plot the result        \n",
        "           iaPlotLoss(logFilePath)\n",
        "           model.save(modelPath)      \n",
        "    # save the final model\n",
        "    model.save(modelPath)     \n",
        "\n",
        "    # plot the result        \n",
        "    iaPlotLoss(logFilePath)\n",
        "    total_time_end = time.time() - total_time_start\n",
        "    print(\"Training this dataset took \", total_time_end,\" seconds!\") \n",
        "    print(\"Training this dataset took \", total_time_end/60.0,\" minutes!\") \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deIAKC2E5HcT"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwUVTMeg5Ks5"
      },
      "source": [
        "if NNID==2:\n",
        "    # Load the saved model \n",
        "    model = keras.models.load_model(modelPath, compile=False)\n",
        "\n",
        "    start_time = time.time() \n",
        "    # Run a validation loop at the end of each epoch.\n",
        "    for x_batch_tst, y_batch_tst in tst_dataset:\n",
        "        output = model.predict(x_batch_tst)\n",
        "        #y = keras.utils.to_categorical(y_batch_tst)\n",
        "        tst_acc_metric.update_state(y_batch_tst, output)\n",
        "\n",
        "    tst_acc = tst_acc_metric.result()\n",
        "\n",
        "    # compute time required for each epoch\n",
        "    end_time = time.time() - start_time\n",
        "\n",
        "    print(\"test accuracy : %.4f \\t time:  %.2f\" % (  float(tst_acc), end_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dne9y6mbMW0V"
      },
      "source": [
        "# Understanding traning curves\n",
        "\n",
        "Training large datsets takes hours. It is good to check the [training curves](https://en.wikipedia.org/wiki/Learning_curve) and stop the training if it is a waste of time and resources. To do this one should check the training curves and identify specific problems.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-YaiYcJP028"
      },
      "source": [
        "#TODO: show examples using the above datasets\n",
        "# https://machinelearningmastery.com/diagnose-overfitting-underfitting-lstm-models/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-j-OqIpdOlJf"
      },
      "source": [
        "## Model underfitting, overfitting, and good fitting:\n",
        "\n",
        "\n",
        "Source for this part is taken from [here](https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/).\n",
        "\n",
        "**Underfitting:**\n",
        "\n",
        "* No learning: Training loss is a line or a noisy line\n",
        "* Need more training: Traning loss is decreasing.\n",
        "\n",
        "<div>\n",
        "<img src=\"\" width=\"500\"/>\n",
        "</div>\n",
        "\n",
        "<div>\n",
        "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2019/02/Example-of-Training-Learning-Curve-Showing-An-Underfit-Model-That-Does-Not-Have-Sufficient-Capacity.png\" width=\"500\"/>\n",
        "</div>\n",
        "\n",
        "<!-- ![](https://machinelearningmastery.com/wp-content/uploads/2019/02/Example-of-Training-Learning-Curve-Showing-An-Underfit-Model-That-Does-Not-Have-Sufficient-Capacity.png) -->\n",
        "\n",
        "<div>\n",
        "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2018/12/Example-of-Training-Learning-Curve-Showing-An-Underfit-Model-That-Requires-Further-Training.png\" width=\"500\"/>\n",
        "</div>\n",
        "\n",
        "\n",
        "<!-- ![](https://machinelearningmastery.com/wp-content/uploads/2018/12/Example-of-Training-Learning-Curve-Showing-An-Underfit-Model-That-Requires-Further-Training.png) -->\n",
        "\n",
        "**Overfitting:**\n",
        "\n",
        "* Training loss is decreasing \n",
        "* Validation loss is decreasing then increasing.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2018/12/Example-of-Train-and-Validation-Learning-Curves-Showing-An-Overfit-Model.png\" width=\"500\"/>\n",
        "</div>\n",
        "\n",
        "<!-- ![](https://machinelearningmastery.com/wp-content/uploads/2018/12/Example-of-Train-and-Validation-Learning-Curves-Showing-An-Overfit-Model.png) -->\n",
        "\n",
        "**Good fitting:**\n",
        "\n",
        "* Training loss is decreasing to a point of stability.\n",
        "* Validation loss is decreasing to a point of stability and has a small gap with the training loss.\n",
        "\n",
        "\n",
        "<div>\n",
        "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2018/12/Example-of-Train-and-Validation-Learning-Curves-Showing-A-Good-Fit.png\" width=\"500\"/>\n",
        "</div>\n",
        "\n",
        "<!-- ![](https://machinelearningmastery.com/wp-content/uploads/2018/12/Example-of-Train-and-Validation-Learning-Curves-Showing-A-Good-Fit.png) -->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ojw1-BrOrzb"
      },
      "source": [
        "## Bad Datasets\n",
        "\n",
        "**Bad Training Dataset:**\n",
        "\n",
        "* Training dataset has too few examples as compared to the validation dataset.\n",
        "* Training loss is decreasing and validation loss is decreasing with a large gap.\n",
        "\n",
        "\n",
        "<div>\n",
        "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2018/12/Example-of-Train-and-Validation-Learning-Curves-Showing-a-Training-Dataset-the-May-be-too-Small-Relative-to-the-Validation-Dataset.png\" width=\"500\"/>\n",
        "</div>\n",
        "\n",
        "<!-- ![](https://machinelearningmastery.com/wp-content/uploads/2018/12/Example-of-Train-and-Validation-Learning-Curves-Showing-a-Training-Dataset-the-May-be-too-Small-Relative-to-the-Validation-Dataset.png) -->\n",
        "\n",
        "\n",
        "**Bad validation Dataset:**\n",
        "\n",
        "* Training loss is decreasing and validation loss with noisy movements around the training loss.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2018/12/Example-of-Train-and-Validation-Learning-Curves-Showing-a-Validation-Dataset-the-May-be-too-Small-Relative-to-the-Training-Dataset.png\" width=\"500\"/>\n",
        "</div>\n",
        "\n",
        "\n",
        "* Validation loss is lower than the training loss (Use validation dataset for training)\n",
        "\n",
        "<div>\n",
        "<img src=\"https://machinelearningmastery.com/wp-content/uploads/2018/12/Example-of-Train-and-Validation-Learning-Curves-Showing-a-Validation-Dataset-that-is-Easier-to-Predict-than-the-Training-Dataset.png\" width=\"500\"/>\n",
        "</div>\n",
        "\n",
        "\n",
        "<!-- ![](https://machinelearningmastery.com/wp-content/uploads/2018/12/Example-of-Train-and-Validation-Learning-Curves-Showing-a-Validation-Dataset-the-May-be-too-Small-Relative-to-the-Training-Dataset.png)\n",
        "![](https://machinelearningmastery.com/wp-content/uploads/2018/12/Example-of-Train-and-Validation-Learning-Curves-Showing-a-Validation-Dataset-that-is-Easier-to-Predict-than-the-Training-Dataset.png) -->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeRdRNJF2kwU"
      },
      "source": [
        "# More resources:\n",
        "\n",
        "* 3Blue1Brown Neural Network [video tutorials](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) \n",
        "* Deep Learning Video Lectures by Prof. Andreas Maier [Winter 20/21](https://www.youtube.com/watch?v=SCFToE1vM2U&list=PLpOGQvPCDQzvJEPFUQ3mJz72GJ95jyZTh)\n",
        "* Some of the code in this notebook is taken from [here](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch)\n",
        "* Calculating number of parameters in [CNN](https://towardsdatascience.com/understanding-and-calculating-the-number-of-parameters-in-convolution-neural-networks-cnns-fc88790d530d)\n",
        "* Some of the code in this notebook is taken from [here](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/cnn.ipynb)\n",
        "* https://imerit.net/blog/top-13-machine-learning-image-classification-datasets-all-pbm/\n",
        "* https://nihcc.app.box.com/v/ChestXray-NIHCC\n",
        "* https://www.kaggle.com/xhlulu/recursion-cellular-image-classification-224-jpg\n",
        "* https://www.tensorflow.org/datasets/catalog/patch_camelyon\n"
      ]
    }
  ]
}